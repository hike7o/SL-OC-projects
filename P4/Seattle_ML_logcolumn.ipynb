{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b51e2588",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: top;\"> <img align=middle src=\"https://mmo.aiircdn.com/141/5ed59862e602f.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:1rem;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf8708",
   "metadata": {},
   "source": [
    "## BUILDING ENERGY CONSUMPTION & GHG EMISSIONS ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e579261c",
   "metadata": {},
   "source": [
    "Climate change is a global challenge and carbon pollution knows no boundaries.<br>\n",
    "\n",
    "In 2011, Seattle adopted the goal to become carbon neutral by 2050. The overall approach to carbon reductions in the buildings is to provide information, financial and other incentives, and technical assistance, while establishing strong standards for efficiency and emissions. <br>\n",
    "\n",
    "As part of the City of Seattle, our team will focus on our primary target: Estimate Green House Gas Emissions .<br>\n",
    "\n",
    "We will first try to predict the Total Energy Use from Seattle buildings that do not have yet any measurements to build on GHG Emissions.  <br>\n",
    "\n",
    "To achieve this from the data we have, we are going to run few algorithms that can predict the Energy consumption and then establish a relationship with GHG Emissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e85fa92",
   "metadata": {},
   "source": [
    "__IMPORT OF ALL MODULES NEEDED TO PERFORM OUR ANALYSIS__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b57bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! usr/bin/env python 3\n",
    "# coding: utf-8\n",
    "\n",
    "# Importing librairies\n",
    "\n",
    "import numpy as np                # numerical data processing\n",
    "import pandas as pd               # numerical tables & time series\n",
    "import scipy as sp                # numerical integration, interpolation, optimization, linear algebra, and statistics\n",
    "import scipy.stats as st          # statistical functions\n",
    "import seaborn as sns             # statistical data visualization\n",
    "import matplotlib.pyplot as plt   # static, animated, and interactive visualizations in Python\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.inspection import permutation_importance\n",
    "from IPython.display import HTML\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a8166",
   "metadata": {},
   "source": [
    "__IMPORTING OUR - AFTER CLEANING - DATA SOURCE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d227a01f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSEBuildingID</th>\n",
       "      <th>DataYear</th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>PropertyName</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>...</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Address</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>AgeofBuilding</th>\n",
       "      <th>MeanBuildingGFA</th>\n",
       "      <th>MeanFloorGFA</th>\n",
       "      <th>BuildingGFApct</th>\n",
       "      <th>ParkingGFApct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>Mayflower Park Hotel</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88434</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.337997</td>\n",
       "      <td>405 Olive Way</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>88</td>\n",
       "      <td>88434.0</td>\n",
       "      <td>7369.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>Mayflower Park Hotel</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88434</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>...</td>\n",
       "      <td>-122.337990</td>\n",
       "      <td>405 Olive Way</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>WA</td>\n",
       "      <td>98101.0</td>\n",
       "      <td>89</td>\n",
       "      <td>88434.0</td>\n",
       "      <td>7369.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   OSEBuildingID  DataYear    BuildingType PrimaryPropertyType  \\\n",
       "0              1      2015  NonResidential               Hotel   \n",
       "1              1      2016  NonResidential               Hotel   \n",
       "\n",
       "           PropertyName Neighborhood  NumberofBuildings  NumberofFloors  \\\n",
       "0  Mayflower Park Hotel     Downtown                1.0            12.0   \n",
       "1  Mayflower Park Hotel     Downtown                1.0            12.0   \n",
       "\n",
       "   PropertyGFATotal LargestPropertyUseType  ...   Longitude         Address  \\\n",
       "0             88434                  Hotel  ... -122.337997   405 Olive Way   \n",
       "1             88434                  Hotel  ... -122.337990   405 Olive Way   \n",
       "\n",
       "       City  State  ZipCode  AgeofBuilding  MeanBuildingGFA MeanFloorGFA  \\\n",
       "0   Seattle     WA  98101.0             88          88434.0       7369.5   \n",
       "1   Seattle     WA  98101.0             89          88434.0       7369.5   \n",
       "\n",
       "  BuildingGFApct ParkingGFApct  \n",
       "0            1.0           0.0  \n",
       "1            1.0           0.0  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforming our input files.csv from the cleaning phase to dataframe\n",
    "\n",
    "df_data = pd.read_csv(\"data_cleaned.csv\")\n",
    "df_data = df_data.drop(['Unnamed: 0'], axis=1)\n",
    "df_data.head(2)\n",
    "#hide_content()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506d9695",
   "metadata": {},
   "source": [
    "###  1) PREPARATION OF DATA FOR MACHINE LEARNING ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffee20af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OSEBuildingID</th>\n",
       "      <th>DataYear</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>GHGEmissions(MetricTonsCO2e)</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>AgeofBuilding</th>\n",
       "      <th>MeanBuildingGFA</th>\n",
       "      <th>MeanFloorGFA</th>\n",
       "      <th>BuildingGFApct</th>\n",
       "      <th>ParkingGFApct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3.141000e+03</td>\n",
       "      <td>2086.000000</td>\n",
       "      <td>3.141000e+03</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3128.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3.141000e+03</td>\n",
       "      <td>3.141000e+03</td>\n",
       "      <td>3141.000000</td>\n",
       "      <td>3141.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15957.544413</td>\n",
       "      <td>2015.487424</td>\n",
       "      <td>1.080548</td>\n",
       "      <td>4.184336</td>\n",
       "      <td>1.105510e+05</td>\n",
       "      <td>63.892138</td>\n",
       "      <td>6.927902e+06</td>\n",
       "      <td>143.456237</td>\n",
       "      <td>47.616319</td>\n",
       "      <td>-122.333421</td>\n",
       "      <td>98116.512788</td>\n",
       "      <td>54.078637</td>\n",
       "      <td>1.078988e+05</td>\n",
       "      <td>3.547954e+04</td>\n",
       "      <td>0.935906</td>\n",
       "      <td>0.064094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13316.934457</td>\n",
       "      <td>0.499921</td>\n",
       "      <td>0.899862</td>\n",
       "      <td>6.658510</td>\n",
       "      <td>1.846814e+05</td>\n",
       "      <td>28.648358</td>\n",
       "      <td>1.184251e+07</td>\n",
       "      <td>300.682201</td>\n",
       "      <td>0.047563</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>17.212711</td>\n",
       "      <td>32.735310</td>\n",
       "      <td>1.828486e+05</td>\n",
       "      <td>5.843071e+04</td>\n",
       "      <td>0.140543</td>\n",
       "      <td>0.140543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.128500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.069180e+05</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>47.499331</td>\n",
       "      <td>-122.411820</td>\n",
       "      <td>98006.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.300000e+03</td>\n",
       "      <td>2.216970e+02</td>\n",
       "      <td>0.104977</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>586.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.908400e+04</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.242764e+06</td>\n",
       "      <td>20.160000</td>\n",
       "      <td>47.586961</td>\n",
       "      <td>-122.343369</td>\n",
       "      <td>98104.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.880000e+04</td>\n",
       "      <td>1.311200e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>21125.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.866000e+04</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>2.602214e+06</td>\n",
       "      <td>49.280000</td>\n",
       "      <td>47.612465</td>\n",
       "      <td>-122.333228</td>\n",
       "      <td>98109.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>4.783600e+04</td>\n",
       "      <td>2.258500e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24538.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.041970e+05</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>7.004126e+06</td>\n",
       "      <td>139.340000</td>\n",
       "      <td>47.649090</td>\n",
       "      <td>-122.322620</td>\n",
       "      <td>98125.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>1.022350e+05</td>\n",
       "      <td>3.745455e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50226.000000</td>\n",
       "      <td>2016.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>2.200000e+06</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.146485e+08</td>\n",
       "      <td>3894.010000</td>\n",
       "      <td>47.733870</td>\n",
       "      <td>-122.258795</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>2.200000e+06</td>\n",
       "      <td>1.100000e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       OSEBuildingID     DataYear  NumberofBuildings  NumberofFloors  \\\n",
       "count    3141.000000  3141.000000        3141.000000     3141.000000   \n",
       "mean    15957.544413  2015.487424           1.080548        4.184336   \n",
       "std     13316.934457     0.499921           0.899862        6.658510   \n",
       "min         1.000000  2015.000000           1.000000        1.000000   \n",
       "25%       586.000000  2015.000000           1.000000        1.000000   \n",
       "50%     21125.000000  2015.000000           1.000000        2.000000   \n",
       "75%     24538.000000  2016.000000           1.000000        4.000000   \n",
       "max     50226.000000  2016.000000          27.000000       99.000000   \n",
       "\n",
       "       PropertyGFATotal  ENERGYSTARScore  SiteEnergyUse(kBtu)  \\\n",
       "count      3.141000e+03      2086.000000         3.141000e+03   \n",
       "mean       1.105510e+05        63.892138         6.927902e+06   \n",
       "std        1.846814e+05        28.648358         1.184251e+07   \n",
       "min        1.128500e+04         1.000000         1.069180e+05   \n",
       "25%        2.908400e+04        45.000000         1.242764e+06   \n",
       "50%        4.866000e+04        71.000000         2.602214e+06   \n",
       "75%        1.041970e+05        88.000000         7.004126e+06   \n",
       "max        2.200000e+06       100.000000         1.146485e+08   \n",
       "\n",
       "       GHGEmissions(MetricTonsCO2e)     Latitude    Longitude       ZipCode  \\\n",
       "count                   3141.000000  3141.000000  3141.000000   3128.000000   \n",
       "mean                     143.456237    47.616319  -122.333421  98116.512788   \n",
       "std                      300.682201     0.047563     0.023836     17.212711   \n",
       "min                        0.750000    47.499331  -122.411820  98006.000000   \n",
       "25%                       20.160000    47.586961  -122.343369  98104.000000   \n",
       "50%                       49.280000    47.612465  -122.333228  98109.000000   \n",
       "75%                      139.340000    47.649090  -122.322620  98125.000000   \n",
       "max                     3894.010000    47.733870  -122.258795  98199.000000   \n",
       "\n",
       "       AgeofBuilding  MeanBuildingGFA  MeanFloorGFA  BuildingGFApct  \\\n",
       "count    3141.000000     3.141000e+03  3.141000e+03     3141.000000   \n",
       "mean       54.078637     1.078988e+05  3.547954e+04        0.935906   \n",
       "std        32.735310     1.828486e+05  5.843071e+04        0.140543   \n",
       "min         1.000000     4.300000e+03  2.216970e+02        0.104977   \n",
       "25%        27.000000     2.880000e+04  1.311200e+04        1.000000   \n",
       "50%        50.000000     4.783600e+04  2.258500e+04        1.000000   \n",
       "75%        86.000000     1.022350e+05  3.745455e+04        1.000000   \n",
       "max       116.000000     2.200000e+06  1.100000e+06        1.000000   \n",
       "\n",
       "       ParkingGFApct  \n",
       "count    3141.000000  \n",
       "mean        0.064094  \n",
       "std         0.140543  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         0.895023  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833383ca",
   "metadata": {},
   "source": [
    "Amongst the 26 remaining columns, we first are going to drop the two least populated ones as they won't provide further information for our project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5333ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_reg = ['YearsENERGYSTARCertified', 'Outlier']\n",
    "df_data.drop(non_reg, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7125e33",
   "metadata": {},
   "source": [
    "Description of the buildings are important but the Property Name, adress (related to ZipCode), City & State (always the same one as far as we focus on the city of Seattle) are not relevant to us as long as we kept Latitude and Longitude data. Geographical data could be relevant for our targets. BuildingID can be skipped as we'll make a OHE on the DataYear after concatening both files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31ea24ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_features = ['OSEBuildingID', 'PropertyName', 'Address', 'City', 'State', 'ZipCode']\n",
    "df_data_loc = df_data[loc_features]\n",
    "df_data.drop(loc_features, axis=1, inplace = True)\n",
    "\n",
    "# After concatening both files, we differientiate the same buildings by passing the category \"DataYear\" as an object\n",
    "# to consider it as a category and to encode it later\n",
    "\n",
    "df_data['DataYear'] = df_data['DataYear'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943206f7",
   "metadata": {},
   "source": [
    "We create additional columns for our Log targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4022ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DataYear</th>\n",
       "      <th>BuildingType</th>\n",
       "      <th>PrimaryPropertyType</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>NumberofBuildings</th>\n",
       "      <th>NumberofFloors</th>\n",
       "      <th>PropertyGFATotal</th>\n",
       "      <th>LargestPropertyUseType</th>\n",
       "      <th>ENERGYSTARScore</th>\n",
       "      <th>SiteEnergyUse(kBtu)</th>\n",
       "      <th>GHGEmissions(MetricTonsCO2e)</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>AgeofBuilding</th>\n",
       "      <th>MeanBuildingGFA</th>\n",
       "      <th>MeanFloorGFA</th>\n",
       "      <th>BuildingGFApct</th>\n",
       "      <th>ParkingGFApct</th>\n",
       "      <th>LogSEU</th>\n",
       "      <th>LogGHG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88434</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6981428.0</td>\n",
       "      <td>249.43</td>\n",
       "      <td>47.612190</td>\n",
       "      <td>-122.337997</td>\n",
       "      <td>88</td>\n",
       "      <td>88434.0</td>\n",
       "      <td>7369.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.758764</td>\n",
       "      <td>5.523179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>88434</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>60.0</td>\n",
       "      <td>7226362.5</td>\n",
       "      <td>249.98</td>\n",
       "      <td>47.612200</td>\n",
       "      <td>-122.337990</td>\n",
       "      <td>89</td>\n",
       "      <td>88434.0</td>\n",
       "      <td>7369.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.793246</td>\n",
       "      <td>5.525373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>NonResidential</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>103566</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>51.0</td>\n",
       "      <td>8354235.0</td>\n",
       "      <td>263.51</td>\n",
       "      <td>47.613106</td>\n",
       "      <td>-122.333358</td>\n",
       "      <td>19</td>\n",
       "      <td>103566.0</td>\n",
       "      <td>9415.090909</td>\n",
       "      <td>0.854547</td>\n",
       "      <td>0.145453</td>\n",
       "      <td>15.938279</td>\n",
       "      <td>5.577879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DataYear    BuildingType PrimaryPropertyType Neighborhood  \\\n",
       "0     2015  NonResidential               Hotel     Downtown   \n",
       "1     2016  NonResidential               Hotel     Downtown   \n",
       "2     2015  NonResidential               Hotel     Downtown   \n",
       "\n",
       "   NumberofBuildings  NumberofFloors  PropertyGFATotal LargestPropertyUseType  \\\n",
       "0                1.0            12.0             88434                  Hotel   \n",
       "1                1.0            12.0             88434                  Hotel   \n",
       "2                1.0            11.0            103566                  Hotel   \n",
       "\n",
       "   ENERGYSTARScore  SiteEnergyUse(kBtu)  GHGEmissions(MetricTonsCO2e)  \\\n",
       "0             65.0            6981428.0                        249.43   \n",
       "1             60.0            7226362.5                        249.98   \n",
       "2             51.0            8354235.0                        263.51   \n",
       "\n",
       "    Latitude   Longitude  AgeofBuilding  MeanBuildingGFA  MeanFloorGFA  \\\n",
       "0  47.612190 -122.337997             88          88434.0   7369.500000   \n",
       "1  47.612200 -122.337990             89          88434.0   7369.500000   \n",
       "2  47.613106 -122.333358             19         103566.0   9415.090909   \n",
       "\n",
       "   BuildingGFApct  ParkingGFApct     LogSEU    LogGHG  \n",
       "0        1.000000       0.000000  15.758764  5.523179  \n",
       "1        1.000000       0.000000  15.793246  5.525373  \n",
       "2        0.854547       0.145453  15.938279  5.577879  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a log column on the last position and delete the normal one\n",
    "df_data['LogSEU'] = np.log1p(df_data['SiteEnergyUse(kBtu)'])\n",
    "df_data['LogGHG'] = np.log1p(df_data['GHGEmissions(MetricTonsCO2e)'])\n",
    "\n",
    "df_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da000a9c",
   "metadata": {},
   "source": [
    "We create a data frame where we don't take ENERGYSTARScore into account for a first phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd3066e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3141, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_non_ener = df_data.drop(['ENERGYSTARScore'], axis=1)\n",
    "df_data_non_ener.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531863f3",
   "metadata": {},
   "source": [
    "Final information from which we'll run our algorithms. All regression models will take these information as input data.\n",
    "If predictions aren't good enough to a standard point of view, it might mean:\n",
    "* The cleaning phase was not good enough - we got rid of important information (i.e. without knowing it)\n",
    "* The featuring engineering we created in the last cleaning phase was not optimized\n",
    "* Real data are impossible to predict precisely for any reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96adc53c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3141 entries, 0 to 3140\n",
      "Data columns (total 19 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   DataYear                      3141 non-null   object \n",
      " 1   BuildingType                  3141 non-null   object \n",
      " 2   PrimaryPropertyType           3141 non-null   object \n",
      " 3   Neighborhood                  3141 non-null   object \n",
      " 4   NumberofBuildings             3141 non-null   float64\n",
      " 5   NumberofFloors                3141 non-null   float64\n",
      " 6   PropertyGFATotal              3141 non-null   int64  \n",
      " 7   LargestPropertyUseType        3074 non-null   object \n",
      " 8   SiteEnergyUse(kBtu)           3141 non-null   float64\n",
      " 9   GHGEmissions(MetricTonsCO2e)  3141 non-null   float64\n",
      " 10  Latitude                      3141 non-null   float64\n",
      " 11  Longitude                     3141 non-null   float64\n",
      " 12  AgeofBuilding                 3141 non-null   int64  \n",
      " 13  MeanBuildingGFA               3141 non-null   float64\n",
      " 14  MeanFloorGFA                  3141 non-null   float64\n",
      " 15  BuildingGFApct                3141 non-null   float64\n",
      " 16  ParkingGFApct                 3141 non-null   float64\n",
      " 17  LogSEU                        3141 non-null   float64\n",
      " 18  LogGHG                        3141 non-null   float64\n",
      "dtypes: float64(12), int64(2), object(5)\n",
      "memory usage: 466.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_data_non_ener.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c437ef",
   "metadata": {},
   "source": [
    "The base of our analysis: 5 categorical columns = object & 14 numerical columns = int or float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "656cb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = df_data_non_ener.select_dtypes(include=['int64','float64'])\n",
    "categorical_features = df_data_non_ener.select_dtypes(exclude=['int64','float64']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fd222f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_features = ['SiteEnergyUse(kBtu)','GHGEmissions(MetricTonsCO2e)', 'LogSEU', 'LogGHG']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc14798",
   "metadata": {},
   "source": [
    "The target features we want to predict will obviously not be part of the data from which we build our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bac3fd83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerical_features.drop(target_features, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37484236",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_stars = df_data.select_dtypes(include=['int64','float64'])\n",
    "numerical_features_stars.drop(target_features, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124fc95",
   "metadata": {},
   "source": [
    "### 2) MACHINE LEARNING ALGORITHMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3110a",
   "metadata": {},
   "source": [
    "We are going to perform few regression models and compare them to each other in order to be able to predict our best match for our targets: Energy consumption (SiteEnergyUse) and for the GHG Emissions. The following regressions will be tested:\n",
    "\n",
    "* Dummy\n",
    "* Linear \n",
    "* Lasso \n",
    "* Ridge \n",
    "* ElasticNet \n",
    "* SVM \n",
    "* KNN \n",
    "* RandomForest \n",
    "* XGBoost\n",
    "\n",
    "On top of that, when displaying our target features, we noticed that both Site Energy Use and GHG Emissions are severely skewed. \n",
    "The log transformation can be used to make highly skewed distributions less skewed. This can be valuable both for making patterns in the data more interpretable and for helping to meet the assumptions of inferential statistics. This is not always the case and we are going to assess the impact of such a transformation on our results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4a291",
   "metadata": {},
   "source": [
    "__Overview of linear and log transformed targets__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c60e8f99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(20,10))\n",
    "fig.suptitle(\"Distribution of Site Energy Use & GHG Emissions\", fontsize=18, weight = 'bold', size = 20)\n",
    "\n",
    "sns.histplot(data=df_data_non_ener, x='SiteEnergyUse(kBtu)', ax=axes[0,0] ) \n",
    "axes[0,0].set_xlabel(\"SiteEnergyUse(kBtu)\")\n",
    "axes[0,0].set_ylabel(\"Number of records\")\n",
    "\n",
    "sns.histplot(data=df_data_non_ener, x='SiteEnergyUse(kBtu)', ax=axes[1,0] , log_scale=True) \n",
    "axes[1,0].set_xlabel(\"Log {SiteEnergyUse(kBtu)}\")\n",
    "axes[1,0].set_ylabel(\"Number of records\")\n",
    "\n",
    "sns.histplot(data=df_data_non_ener, x='GHGEmissions(MetricTonsCO2e)', ax=axes[0,1] ) \n",
    "axes[0,1].set_xlabel(\"GHG Emissions (MetricTonsCO2e)\")\n",
    "axes[0,1].set_ylabel(\"Number of records\")\n",
    "\n",
    "sns.histplot(data=df_data_non_ener, x='GHGEmissions(MetricTonsCO2e)', ax=axes[1,1] , log_scale=True) \n",
    "axes[1,1].set_xlabel(\"Log {GHG Emissions (MetricTonsCO2e)}\")\n",
    "axes[1,1].set_ylabel(\"Number of records\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb676366",
   "metadata": {},
   "source": [
    "Step 1: __DATA SELECTION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39625d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_data_non_ener.drop(['SiteEnergyUse(kBtu)', 'GHGEmissions(MetricTonsCO2e)', 'LogSEU', 'LogGHG'], axis=1)\n",
    "Y = df_data_non_ener[['SiteEnergyUse(kBtu)','GHGEmissions(MetricTonsCO2e)', 'LogSEU', 'LogGHG']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f028b",
   "metadata": {},
   "source": [
    "Step 2: __STANDARDIZATION & CATEGORICAL ENCODING__<br>\n",
    "\n",
    "StandardScaler standardizes a feature by subtracting the mean and then scaling to unit variance. Unit variance means dividing all the values by the standard deviation. StandardScaler results in a distribution with a standard deviation equal to 1. <br>\n",
    "\n",
    "Few Standardization are available in the Scikit-learn library. RobustScaler was tested (not shown here for clarity) on our cleaned data file to compare with StandardScaler but no significant outcome resulted.<br>\n",
    "\n",
    "In addition to that, categorical data must be converted to numbers. A One Hot Encoding (OHE) is a representation of categorical variables as binary vectors.\n",
    "It requires that the categorical values be mapped to integer values.\n",
    "Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1. <br> \n",
    "As we determined that our chosen categorical variables were not ordinal, we decided to go for OHE rather than Label encoding. No further sensitivity analysis were made for this project to compare impact from both encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5934f0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "scaler = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "cat_data = list(categorical_features.columns)\n",
    "num_data = list(numerical_features.columns)\n",
    "num_data_stars = list(numerical_features_stars.columns)\n",
    "preprocessor = ColumnTransformer(transformers=\n",
    "                                 [('num', scaler, num_data ),\n",
    "                                  ('cat', categorical_transformer, cat_data)])\n",
    "preprocessor1 = ColumnTransformer(transformers=\n",
    "                                 [('num1', scaler, num_data_stars ),\n",
    "                                  ('cat', categorical_transformer, cat_data)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361993c",
   "metadata": {},
   "source": [
    "Step 3: __TRAIN-TEST SPLIT EVALUATION__<br>\n",
    "\n",
    "The procedure involves taking a dataset and dividing it into two subsets. The first subset is used to fit the model and is referred to as the training dataset. The second subset is not used to train the model; instead, the input element of the dataset is provided to the model, then predictions are made and compared to the expected values. This second dataset is referred to as the test dataset.<br>\n",
    "The objective is to estimate the performance of the machine learning model on new data: data not used to train the model.\n",
    "We'll keep 80% of the data set for training and 20% for test. Sensitivity analysis was not performed neither on the split size nor on the random state in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e832a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be21d16",
   "metadata": {},
   "source": [
    "Step 4: __BASELINE CREATION__<br>\n",
    "\n",
    "The Dummy Regressor is a kind of Regressor that gives prediction based on simple strategies without paying any attention to the input Data. The sklearn library provides Dummy Regressor which is used to set up a baseline for comparing different regressions. Training the dummy model is similar to training any regular regression model, except for the strategies. The main role of strategy is to predict target values without any influence of the training data.<br> We are here using the strategy \"mean\" which is the default strategy used by the Dummy Regressor. It always predicts the mean of the training target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48936585",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "#Baseline for Site Energy Use\n",
    "start_time0a = time.time()\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_SEU = dummy_reg.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "dummy_train_SEU = dummy_SEU.predict(X_train)\n",
    "dummy_pred_SEU = dummy_SEU.predict(X_test)\n",
    "tm0a = time.time() - start_time0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a65488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline for GHG Emissions\n",
    "start_time0b = time.time()\n",
    "\n",
    "dummy_GHG = dummy_reg.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "dummy_train_GHG = dummy_GHG.predict(X_train)\n",
    "dummy_pred_GHG = dummy_GHG.predict(X_test)\n",
    "tm0b = time.time() - start_time0b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42fd16d",
   "metadata": {},
   "source": [
    "To evaluate our regression model, we compute few meaningful parameters to estimate how far our predictions are from the actual data:\n",
    "\n",
    "MAE (Mean Absolute Error) is the sum of absolute differences between our target and predicted variables. MAE is a common and simple metric that has the advantage of being in the same unit as our target, which means it can be compared to target values and easily interpreted.<br>\n",
    "\n",
    "MSE (Mean Square Error) measures the average squared difference between the estimated values and the actual value.<br>\n",
    "\n",
    "RMSE (Root Mean Square Error) is the standard deviation of the residuals.<br>\n",
    "\n",
    "RÂ² is the coefficient of determination and evaluates the scatter of the data points around the fitted regression line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bde766",
   "metadata": {},
   "source": [
    "__Defining a function to see results better__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0f90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def algo_model(y_actual, y_forecast):\n",
    "    \"\"\"Return metrics for model evaluation in regression\"\"\"\n",
    "    \n",
    "    start_time = time.time()\n",
    "    y_actual, y_forecast = np.array(y_actual), np.array(y_forecast)\n",
    "    \n",
    "    mse = mean_squared_error(y_actual, y_forecast)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_actual, y_forecast)\n",
    "    tm = time.time() - start_time\n",
    "    \n",
    "    functions = {\"Functions\":[\"Root Mean Squared Error (RMSE)\",\n",
    "                              \"Mean Absolute Error (MAE)\", \"Coefficient of determination (RÂ²)\", \"Running Time(s)\"],\n",
    "                              \"Results\":[rmse, mae, r2_score(y_actual, y_forecast), tm]}\n",
    "    \n",
    "    df_functions = pd.DataFrame(functions) \n",
    "\n",
    "    return df_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaef0a4",
   "metadata": {},
   "source": [
    "__A Baseline is set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_metrics = algo_model(Y_test['SiteEnergyUse(kBtu)'], dummy_pred_SEU).rename(columns={'Results':'Baseline'})\n",
    "dummy_metrics.index = np.arange(1, len(dummy_metrics)+1)\n",
    "dummy_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site SEU metrics\n",
    "MAE_train0a = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], dummy_train_SEU)\n",
    "r2_train0a = r2_score(Y_train['SiteEnergyUse(kBtu)'], dummy_train_SEU)\n",
    "RMSE_train0a = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], dummy_train_SEU))\n",
    "\n",
    "MAE_test0a = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], dummy_pred_SEU)\n",
    "r2_test0a = r2_score(Y_test['SiteEnergyUse(kBtu)'], dummy_pred_SEU)\n",
    "RMSE_test0a = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], dummy_pred_SEU))\n",
    "\n",
    "# GHG Emissions\n",
    "MAE_train_00 = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], dummy_train_GHG)\n",
    "r2_train_00 = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], dummy_train_GHG)\n",
    "RMSE_train_00 = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], dummy_train_GHG))\n",
    "\n",
    "MAE_test_00 = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], dummy_pred_GHG)\n",
    "r2_test_00 = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], dummy_pred_GHG)\n",
    "RMSE_test_00 = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], dummy_pred_GHG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27be1738",
   "metadata": {},
   "source": [
    "### 2-1) LINEAR REGRESSION MODELS - LINEAR & LOG SCALE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54ae142",
   "metadata": {},
   "source": [
    "While running the multiple regressions - listed above - on train et test data respectively, we'll plot the targeted values v the predicted ones just to have a graphic visualization of our fits and we'll display the metrics we have chosen. At the end, we'll create a dataframe and discuss the associated results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16412905",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - LINEAR REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ad87a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use linear model & linear scale\n",
    "start_time1 = time.time()\n",
    "\n",
    "pipe_lin = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', LinearRegression())])\n",
    "\n",
    "X = df_data_non_ener[num_data + cat_data]\n",
    "\n",
    "pipe_lin.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm1 = time.time() - start_time1\n",
    "Y_pred = pipe_lin.predict(X_train)\n",
    "\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Linear regression \\n without target transformation', size = 22)\n",
    "\n",
    "r2_train1 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train1 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train1 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train1, MAE_train1, RMSE_train1), fontsize = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# Transform targets and use same linear model\n",
    "\n",
    "start_time_1 = time.time()\n",
    "pipe_lin.fit(X_train, Y_train['LogSEU'])\n",
    "tm_1 = time.time() - start_time_1\n",
    "\n",
    "Y_pred = pipe_lin.predict(X_train)\n",
    "\n",
    "# # Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Linear regression \\n with log target transformation', size = 22)\n",
    "\n",
    "r2_train_1 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_1 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_1 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_1, MAE_train_1, RMSE_train_1), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085014d1",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - LINEAR REGRESSION ON TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea2e7fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use linear model & linear scale\n",
    "start_time11 = time.time()\n",
    "\n",
    "pipe_lin = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', LinearRegression())])\n",
    "\n",
    "X = df_data_non_ener[num_data + cat_data]\n",
    "\n",
    "pipe_lin.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "Y_pred = pipe_lin.predict(X_test)\n",
    "tm11 = time.time() - start_time11\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Linear regression \\n without target transformation', size = 22)\n",
    "r2_test11 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test11 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test11 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 8.8e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test11, MAE_test11, RMSE_test11), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# Transform targets and use same linear model\n",
    "\n",
    "start_time_11 = time.time()\n",
    "pipe_lin.fit(X_train, Y_train['LogSEU'])\n",
    "\n",
    "Y_pred = pipe_lin.predict(X_test)\n",
    "tm_11 = time.time() - start_time_11\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Linear regression \\n with log target transformation', size = 22)\n",
    "r2_test_11 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_11 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_11 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 8.8e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_11, MAE_test_11, RMSE_test_11), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e163c2a",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - LINEAR REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use linear model\n",
    "start_time1b = time.time()\n",
    "\n",
    "pipe_lin.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "\n",
    "Y_pred = pipe_lin.predict(X_train)\n",
    "tm1b = time.time() - start_time1b\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Linear regression \\n without target transformation', size = 22)\n",
    "r2_train1b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train1b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train1b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train1b, MAE_train1b, RMSE_train1b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# #######################################################################################\n",
    "# Transform targets and use same linear model\n",
    "start_time_1b = time.time()\n",
    "\n",
    "pipe_lin.fit(X_train, Y_train['LogGHG'])\n",
    "Y_pred = pipe_lin.predict(X_train)\n",
    "tm_1b = time.time() - start_time_1b\n",
    "\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Linear regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_1b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_1b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_1b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_1b, MAE_train_1b, RMSE_train_1b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions (MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d12eb",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - LINEAR REGRESSION ON TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51bb1c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use linear model\n",
    "start_time11b = time.time()\n",
    "\n",
    "pipe_lin.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "\n",
    "Y_pred = pipe_lin.predict(X_test)\n",
    "tm11b = time.time() - start_time11b\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Linear regression \\n without target transformation', size = 22)\n",
    "r2_test11b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test11b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test11b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test11b, MAE_test11b, RMSE_test11b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ######################################################################################\n",
    "# Transform targets and use same linear model\n",
    "start_time_11b = time.time()\n",
    "\n",
    "pipe_lin.fit(X_train, Y_train['LogGHG'])\n",
    "Y_pred = pipe_lin.predict(X_test)\n",
    "tm_11b = time.time() - start_time_11b\n",
    "\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Linear regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_11b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_11b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_11b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_11b, MAE_test_11b, RMSE_test_11b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions (MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a647c22f",
   "metadata": {},
   "source": [
    "### 2-2) LASSO REGRESSION - LINEAR & LOG SCALE COMPARISON<br>\n",
    "\n",
    "Lasso regression, or the Least Absolute Shrinkage and Selection Operator, is also a modification of linear regression. In Lasso, the loss function is modified to minimize the complexity of the model by limiting the sum of the absolute values of the model coefficients (also called the l1-norm).\n",
    "GridSearchCV is a library function that is a member of sklearn's model_selection package. It helps to loop through predefined hyperparameters and fit our estimator (model) on our training set. So, in the end, we can select the best parameters from the listed hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120c287",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - LASSO REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be6d821",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Lasso model\n",
    "\n",
    "pipe_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', Lasso())])\n",
    "\n",
    "# Hyperparameters to tune\n",
    "params_lasso = {\"regressor__alpha\": np.logspace(-4, 1, num=6), # Constant that multiplies the L1 term (default=1)\n",
    "               \"regressor__max_iter\": [10, 50, 100, 1000]} # maximum number of iterations.\n",
    "\n",
    "lasso_grid_cv = GridSearchCV(pipe_lasso, \n",
    "                       param_grid=params_lasso, # Dictionary with parameters names\n",
    "                       cv=5, # Determines the cross-validation splitting strategy\n",
    "                       scoring=('r2','neg_mean_absolute_error'), # Strategy to evaluate the performance of the cross-validated model on the train set\n",
    "                       return_train_score = True, # If False, the cv_results_ attribute will not include training scores\n",
    "                       refit='neg_mean_absolute_error', #Refit an estimator using the best found parameters on the whole dataset\n",
    "                       n_jobs = -1) # Number of jobs to run in parallel\n",
    "\n",
    "start_time2 = time.time()\n",
    "lasso_SEU = lasso_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm2 = time.time() - start_time2\n",
    "\n",
    "Y_pred = lasso_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Lasso regression \\n without target transformation', size = 22)\n",
    "r2_train2 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train2 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train2 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train2, MAE_train2, RMSE_train2), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ##########################################################################################\n",
    "# Transform targets and use same Lasso model\n",
    "\n",
    "\n",
    "lasso_grid_cvlog = GridSearchCV(pipe_lasso, \n",
    "                       param_grid=params_lasso, \n",
    "                       cv=5, \n",
    "                       scoring=('r2','neg_mean_absolute_error'), \n",
    "                       return_train_score = True, \n",
    "                       refit='neg_mean_absolute_error', \n",
    "                       n_jobs = -1) \n",
    "\n",
    "start_time_2 = time.time()\n",
    "lasso_SEU_log = lasso_grid_cvlog.fit(X_train, Y_train['LogSEU'])\n",
    "tm_2 = time.time() - start_time_2\n",
    "\n",
    "Y_pred = lasso_SEU_log.predict(X_train)\n",
    "\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Lasso regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_2 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_2 = mean_absolute_error(np.expm1(Y_train['LogSEU']),np.expm1(Y_pred))\n",
    "RMSE_train_2 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_2, MAE_train_2, RMSE_train_2), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', lasso_SEU.best_params_)\n",
    "print('Best parameters log scale:', lasso_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc4a82b",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - LASSO REGRESSION ON TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e017bd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Lasso model\n",
    "\n",
    "pipe_lasso = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', Lasso())])\n",
    "\n",
    "# Hyperparameters to tune\n",
    "params_lasso = {\"regressor__alpha\": np.logspace(-4, 1, num=6), # Constant that multiplies the L1 term (default=1)\n",
    "               \"regressor__max_iter\": [10, 50, 100, 1000]} # maximum number of iterations.\n",
    "\n",
    "lasso_grid_cv = GridSearchCV(pipe_lasso, \n",
    "                       param_grid=params_lasso, # Dictionary with parameters names\n",
    "                       cv=5, # Determines the cross-validation splitting strategy\n",
    "                       scoring=('r2','neg_mean_absolute_error'), # Strategy to evaluate the performance of the cross-validated model on the test set\n",
    "                       return_train_score = True, # If False, the cv_results_ attribute will not include training scores\n",
    "                       refit='neg_mean_absolute_error', #Refit an estimator using the best found parameters on the whole dataset\n",
    "                       n_jobs = -1) # Number of jobs to run in parallel\n",
    "\n",
    "start_time22 = time.time()\n",
    "lasso_SEU = lasso_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm22 = time.time() - start_time22\n",
    "\n",
    "Y_pred = lasso_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Lasso regression \\n without target transformation', size = 22)\n",
    "r2_test22 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test22 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test22 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test22, MAE_test22, RMSE_test22), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #########################################################################################\n",
    "# Transform targets and use same Lasso model\n",
    "\n",
    "\n",
    "lasso_grid_cvlog = GridSearchCV(pipe_lasso, \n",
    "                       param_grid=params_lasso, # Dictionary with parameters names\n",
    "                       cv=5, # Determines the cross-validation splitting strategy\n",
    "                       scoring=('r2','neg_mean_absolute_error'), # Strategy to evaluate the performance of the cross-validated model on the train set\n",
    "                       return_train_score = True, # If False, the cv_results_ attribute will not include training scores\n",
    "                       refit='neg_mean_absolute_error', #Refit an estimator using the best found parameters on the whole dataset\n",
    "                       n_jobs = -1) # Number of jobs to run in parallel\n",
    "\n",
    "start_time_22 = time.time()\n",
    "lasso_SEU_log = lasso_grid_cvlog.fit(X_train, Y_train['LogSEU'])\n",
    "tm_22 = time.time() - start_time_22\n",
    "\n",
    "Y_pred = lasso_SEU_log.predict(X_test)\n",
    "\n",
    "# Plot\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Lasso regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_22 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_22 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_22 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_22, MAE_test_22, RMSE_test_22), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.15, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', lasso_SEU.best_params_)\n",
    "print('Best parameters log scale:', lasso_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31161d",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - LASSO REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0410d357",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Lasso model\n",
    "start_time2b = time.time()\n",
    "lasso_GHG = lasso_grid_cv.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm2b = time.time() - start_time2b\n",
    "\n",
    "Y_pred = lasso_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Lasso regression \\n without target transformation', size = 22)\n",
    "r2_train2b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train2b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train2b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train2b, MAE_train2b, RMSE_train2b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ###################################################################################\n",
    "# Transform targets and use same Lasso model\n",
    "start_time_2b = time.time()\n",
    "lasso_GHG_log = lasso_grid_cvlog.fit(X_train, Y_train['LogGHG'])\n",
    "tm_2b = time.time() - start_time_2b\n",
    "\n",
    "Y_pred = lasso_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Lasso regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_2b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_2b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_2b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_2b, MAE_train_2b, RMSE_train_2b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', lasso_GHG.best_params_)\n",
    "print('Best parameters log scale:', lasso_GHG_log.best_params_)\n",
    "#print('Best parameters log scale : {}'.format(lasso_GHG_log.named_steps['grid_lasso'].best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277e7d4",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - LASSO REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254376e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Lasso model\n",
    "start_time22b = time.time()\n",
    "lasso_GHG = lasso_grid_cv.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm22b = time.time() - start_time22b\n",
    "\n",
    "Y_pred = lasso_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Lasso regression \\n without target transformation', size = 22)\n",
    "r2_test22b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test22b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test22b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test22b, MAE_test22b, RMSE_test22b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ####################################################################################\n",
    "# Transform targets and use same Lasso model\n",
    "start_time_22b = time.time()\n",
    "lasso_GHG_log = lasso_grid_cvlog.fit(X_train, Y_train['LogGHG'])\n",
    "tm_22b = time.time() - start_time_22b\n",
    "\n",
    "Y_pred = lasso_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Lasso regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_22b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_22b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_22b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_22b, MAE_test_22b, RMSE_test_22b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', lasso_GHG.best_params_)\n",
    "print('Best parameters log scale:', lasso_GHG_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a17f28",
   "metadata": {},
   "source": [
    "### 2-3) RIDGE REGRESSION\n",
    "\n",
    "Ridge regression is an extension of linear regression where the loss function is modified to minimize the complexity of the model. This modification is done by adding a penalty parameter that is equivalent to the square of the magnitude of the coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdae726",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - RIDGE REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0396c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Ridge model\n",
    "\n",
    "pipe_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', Ridge())])\n",
    "\n",
    "params_ridge = {\"regressor__alpha\": np.logspace(-4, 1, num=6), # Regularization strength; must be a positive float (default=1)\n",
    "                \"regressor__max_iter\": [10, 50, 100, 1000]} # Max number of iterations\n",
    "             \n",
    "\n",
    "grid_ridge = GridSearchCV(pipe_ridge, param_grid=params_ridge, cv=5,\n",
    "                            scoring=('r2','neg_mean_absolute_error'),\n",
    "                            return_train_score = True,\n",
    "                            refit='neg_mean_absolute_error',\n",
    "                            n_jobs = -1)\n",
    "\n",
    "start_time3 = time.time()\n",
    "ridge_SEU = grid_ridge.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm3 = time.time() - start_time3\n",
    "\n",
    "Y_pred = ridge_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Ridge regression \\n without target transformation', size = 22)\n",
    "r2_train3 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train3 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train3 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9.5e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train3, MAE_train3, RMSE_train3), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #####################################################################################\n",
    "# Transform targets and use same Ridge model\n",
    "\n",
    "grid_ridge_log = GridSearchCV(pipe_ridge, param_grid=params_ridge, cv=5,\n",
    "                            scoring=('r2','neg_mean_absolute_error'),\n",
    "                            return_train_score = True,\n",
    "                            refit='neg_mean_absolute_error',\n",
    "                            n_jobs = -1)\n",
    "\n",
    "start_time_3 = time.time()\n",
    "ridge_SEU_log = grid_ridge_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_3 = time.time() - start_time_3\n",
    "\n",
    "Y_pred = ridge_SEU_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Ridge regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_3 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_3 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_3 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_3, MAE_train_3, RMSE_train_3), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', ridge_SEU.best_params_)\n",
    "print('Best parameters log scale:', ridge_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a0e7f5",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - RIDGE REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16abdea2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Ridge model\n",
    "\n",
    "pipe_ridge = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('regressor', Ridge())])\n",
    "\n",
    "params_ridge = {\"regressor__alpha\": np.logspace(-4, 1, num=6), # Regularization strength; must be a positive float (default=1)\n",
    "                \"regressor__max_iter\": [10, 50, 100, 1000]} # Max number of iterations\n",
    "             \n",
    "\n",
    "grid_ridge = GridSearchCV(pipe_ridge, param_grid=params_ridge, cv=5,\n",
    "                            scoring=('r2','neg_mean_absolute_error'),\n",
    "                            return_train_score = True,\n",
    "                            refit='neg_mean_absolute_error',\n",
    "                            n_jobs = -1)\n",
    "start_time33 = time.time()\n",
    "ridge_SEU = grid_ridge.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm33 = time.time() - start_time33\n",
    "\n",
    "Y_pred = ridge_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Ridge regression \\n without target transformation', size = 22)\n",
    "r2_test33 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test33 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test33 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test33, MAE_test33, RMSE_test33), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #####################################################################################\n",
    "# Transform targets and use same Ridge model\n",
    "\n",
    "grid_ridge_log = GridSearchCV(pipe_ridge, param_grid=params_ridge, cv=5,\n",
    "                            scoring=('r2','neg_mean_absolute_error'),\n",
    "                            return_train_score = True,\n",
    "                            refit='neg_mean_absolute_error',\n",
    "                            n_jobs = -1)\n",
    "\n",
    "start_time_33 = time.time()\n",
    "ridge_SEU_log = grid_ridge_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_33 = time.time() - start_time_33\n",
    "\n",
    "Y_pred = ridge_SEU_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0 , 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Ridge regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_33 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_33 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_33 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_33, MAE_test_33, RMSE_test_33), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', ridge_SEU.best_params_)\n",
    "print('Best parameters log scale:', ridge_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9084bf7",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - RIDGE REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5ea4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Ridge model\n",
    "\n",
    "start_time3b = time.time()\n",
    "ridge_GHG = grid_ridge.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm3b = time.time() - start_time3b\n",
    "\n",
    "Y_pred = ridge_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Ridge regression \\n without target transformation', size = 22)\n",
    "r2_train3b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train3b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train3b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train3b, MAE_train3b, RMSE_train3b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ####################################################################################\n",
    "# Transform targets and use same Ridge model\n",
    "\n",
    "start_time_3b = time.time()\n",
    "ridge_GHG_log = grid_ridge_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_3b = time.time() - start_time_3b\n",
    "\n",
    "Y_pred = ridge_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Ridge regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_3b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_3b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_3b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_3b, MAE_train_3b, RMSE_train_3b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', ridge_GHG.best_params_)\n",
    "print('Best parameters log scale:', ridge_GHG_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2177ddae",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - RIDGE REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ed8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use Ridge model\n",
    "\n",
    "start_time33b = time.time()\n",
    "ridge_GHG = grid_ridge.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm33b = time.time() - start_time33b\n",
    "\n",
    "Y_pred = ridge_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 6e3], [0, 6e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('Ridge regression \\n without target transformation', size = 22)\n",
    "r2_test33b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test33b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test33b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 5000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test33b, MAE_test33b, RMSE_test33b), size = 16)\n",
    "ax0.set_xlim([0, 6e3])\n",
    "ax0.set_ylim([0, 6e3])\n",
    "\n",
    "# #####################################################################################\n",
    "# Transform targets and use same Ridge model\n",
    "\n",
    "start_time_33b = time.time()\n",
    "ridge_GHG_log = grid_ridge_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_33b = time.time() - start_time_33b\n",
    "\n",
    "Y_pred = ridge_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 6e3], [0, 6e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('Ridge regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_33b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_33b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_33b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1000, 5000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_33b, MAE_test_33b, RMSE_test_33b), size = 16)\n",
    "ax1.set_xlim([0, 6e3])\n",
    "ax1.set_ylim([0, 6e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', ridge_GHG.best_params_)\n",
    "print('Best parameters log scale:', ridge_GHG_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c190b",
   "metadata": {},
   "source": [
    "### 2-4) ELASTICNET REGRESSION \n",
    "\n",
    "While Lasso eliminates many features and reduce overfitting in our linear model, Ridge reduces the impact of features that are not important in predicting our y values. Elastic Net combines feature elimination from Lasso and feature coefficient reduction from the Ridge model to improve your model's predictions. It works by penalizing the model using both the l2-norm and the l1-norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3a08c9",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - ELASTICNET REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1313674",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use ElasticNet model\n",
    "\n",
    "pipe_eNet = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', ElasticNet())])\n",
    "\n",
    "params_eNet = {\"regressor__alpha\": np.logspace(-4, 0, num=5), # Constant that multiplies the penalty terms. Defaults to 1.0\n",
    "                                                  # alpha=0 the penalty function reduces to the L1 (ridge) term\n",
    "                                                  # alpha=1, we get the L2 (lasso) term.\n",
    "              \"regressor__l1_ratio\": [.001, .01, .1, .5, .7, .9, .95, .99, 1], # The ElasticNet mixing parameter,\n",
    "                                                                    # with 0 <= l1_ratio <= 1. \n",
    "                                                                    # For l1_ratio = 0 the penalty is an L2 penalty.\n",
    "                                                                    # For l1_ratio = 1 it is an L1 penalty. \n",
    "                                                                    # For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n",
    "              \"regressor__max_iter\": [10, 50, 100, 1000, 10000]} # The maximum number of iterations (default = 1000)\n",
    "             \n",
    "grid_cvnet = GridSearchCV(pipe_eNet, \n",
    "                          param_grid=params_eNet, \n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time4 = time.time()\n",
    "eNet_SEU = grid_cvnet.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm4 = time.time() - start_time4\n",
    "\n",
    "Y_pred = eNet_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('ElasticNet regression \\n without target transformation', size = 22)\n",
    "r2_train4 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train4 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train4 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9.5e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train4, MAE_train4, RMSE_train4), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ###############################################################################\n",
    "# Transform targets and use same ElasticNet model\n",
    "\n",
    "grid_cvnet_log = GridSearchCV(pipe_eNet, \n",
    "                          param_grid=params_eNet, \n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time_4 = time.time()\n",
    "eNet_SEU_log = grid_cvnet_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_4 = time.time() - start_time_4\n",
    "\n",
    "Y_pred = eNet_SEU_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('ElasticNet regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_4 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_4 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_4 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_4 , MAE_train_4, RMSE_train_4 ), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', eNet_SEU.best_params_)\n",
    "print('Best parameters log scale:', eNet_SEU_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdf6ff",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - ELASTICNET REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b958c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use ElasticNet model\n",
    "\n",
    "pipe_eNet = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', ElasticNet())])\n",
    "\n",
    "params_eNet = {\"regressor__alpha\": np.logspace(-4, 0, num=5), # Constant that multiplies the penalty terms. Defaults to 1.0\n",
    "                                                  # alpha=0 the penalty function reduces to the L1 (ridge) term\n",
    "                                                  # alpha=1, we get the L2 (lasso) term.\n",
    "              \"regressor__l1_ratio\": [.001, .01, .1, .5, .7, .9, .95, .99, 1], # The ElasticNet mixing parameter,\n",
    "                                                                    # with 0 <= l1_ratio <= 1. \n",
    "                                                                    # For l1_ratio = 0 the penalty is an L2 penalty.\n",
    "                                                                    # For l1_ratio = 1 it is an L1 penalty. \n",
    "                                                                    # For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n",
    "              \"regressor__max_iter\": [10, 50, 100, 1000, 10000]} # The maximum number of iterations (default = 1000)\n",
    "             \n",
    "grid_cvnet = GridSearchCV(pipe_eNet, \n",
    "                          param_grid=params_eNet, \n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time44 = time.time()\n",
    "eNet_SEU = grid_cvnet.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm44 = time.time() - start_time44\n",
    "\n",
    "Y_pred = eNet_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('ElasticNet regression \\n without target transformation', size = 22)\n",
    "r2_test44 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test44 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test44 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test44, MAE_test44, RMSE_test44), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ####################################################################################\n",
    "# Transform targets and use same ElasticNet model\n",
    "\n",
    "grid_cvnet_log = GridSearchCV(pipe_eNet, \n",
    "                          param_grid=params_eNet, \n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time_44 = time.time()\n",
    "eNet_SEU_log = grid_cvnet_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_44 = time.time() - start_time_44\n",
    "\n",
    "Y_pred = eNet_SEU_log.predict(X_test)\n",
    "\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('ElasticNet regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_44 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_44 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_44 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_44 , MAE_test_44, RMSE_test_44 ), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', eNet_SEU.best_params_)\n",
    "print('Best parameters log scale:', eNet_SEU_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bb8b2b",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - ELASTICNET REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911162ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use ElasticNet model\n",
    "\n",
    "start_time4b = time.time()\n",
    "eNet_GHG = grid_cvnet.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm4b = time.time() - start_time4b\n",
    "\n",
    "Y_pred = eNet_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('ElasticNet regression \\n without target transformation', size = 22)\n",
    "r2_train4b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train4b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train4b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train4b, MAE_train4b, RMSE_train4b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# #############################################################################\n",
    "# Transform targets and use same ElasticNet model\n",
    "\n",
    "start_time_4b = time.time()\n",
    "eNet_GHG_log = grid_cvnet_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_4b = time.time() - start_time_4b\n",
    "\n",
    "Y_pred = eNet_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('ElasticNet regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_4b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_4b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_4b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_4b , MAE_train_4b, RMSE_train_4b ), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e)\", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', eNet_GHG.best_params_)\n",
    "print('Best parameters log scale:', eNet_GHG_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bdb9a1",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - ELASTICNET REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e685f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use ElasticNet model\n",
    "\n",
    "start_time44b = time.time()\n",
    "eNet_GHG = grid_cvnet.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm44b = time.time() - start_time44b\n",
    "\n",
    "Y_pred = eNet_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('ElasticNet regression \\n without target transformation', size = 22)\n",
    "r2_test44b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test44b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test44b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test44b, MAE_test44b, RMSE_test44b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ###############################################################################\n",
    "# Transform targets and use same ElasticNet model\n",
    "\n",
    "start_time_44b = time.time()\n",
    "eNet_GHG_log = grid_cvnet_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_44b = time.time() - start_time_44b\n",
    "\n",
    "Y_pred = eNet_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('ElasticNet regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_44b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_44b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_44b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_44b , MAE_test_44b, RMSE_test_44b ), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e)\", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', eNet_GHG.best_params_)\n",
    "print('Best parameters log scale:', eNet_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebd0897",
   "metadata": {},
   "source": [
    "### 2-5) K-NEAREST NEIGHBORS (KNN) REGRESSION \n",
    "\n",
    "KNN regression is a non-parametric method that, in an intuitive manner, approximates the association between independent variables and the continuous outcome by averaging the observations in the same neighbourhood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb40511",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - KNN REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc556c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use KNN model\n",
    "\n",
    "pipe_knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('regressor', KNeighborsRegressor())])\n",
    "\n",
    "params_knn = {'regressor__n_neighbors':[3, 5, 7, 9, 11, 13, 15, 55]} # Number of neighbors\n",
    "\n",
    "knn_grid_cv = GridSearchCV(\n",
    "                    pipe_knn, # pipe with KNN regressor\n",
    "                    params_knn,     # hyperparameters to train\n",
    "                    cv=5,           # nombre of cross validation folds\n",
    "                    scoring=('r2','neg_mean_absolute_error'),   # scoring to optimize\n",
    "                    return_train_score = True,\n",
    "                    refit='neg_mean_absolute_error',\n",
    "                    n_jobs = -1)\n",
    "\n",
    "start_time5 = time.time()\n",
    "knn_SEU = knn_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm5 = time.time() - start_time5\n",
    "\n",
    "Y_pred = knn_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('KNN regression \\n without target transformation', size = 22)\n",
    "r2_train5 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train5 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train5 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train5, MAE_train5, RMSE_train5), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ########################################################################################\n",
    "# Transform targets in Log and use same KNN model\n",
    "\n",
    "knn_grid_cvlog = GridSearchCV(\n",
    "                    pipe_knn, # pipe with KNN regressor\n",
    "                    params_knn,     # hyperparameters to train\n",
    "                    cv=5,           # nombre of cross validation folds\n",
    "                    scoring=('r2','neg_mean_absolute_error'),   # scoring to optimize\n",
    "                    return_train_score = True,\n",
    "                    refit='neg_mean_absolute_error',\n",
    "                    n_jobs = -1)\n",
    "\n",
    "start_time_5 = time.time()\n",
    "knn_SEU_log = knn_grid_cvlog.fit(X_train, Y_train['LogSEU'])\n",
    "tm_5 = time.time() - start_time_5\n",
    "\n",
    "Y_pred = knn_SEU_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('KNN regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_5 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_5 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_5 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_5, MAE_train_5, RMSE_train_5), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', knn_SEU.best_params_)\n",
    "print('Best parameters log scale:', knn_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a438f7ce",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - KNN REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use KNN model\n",
    "\n",
    "pipe_knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('regressor', KNeighborsRegressor())])\n",
    "\n",
    "params_knn = {'regressor__n_neighbors':[3, 5, 7, 9, 11, 13, 15, 55]} # Number of neighbors\n",
    "\n",
    "knn_grid_cv = GridSearchCV(\n",
    "                    pipe_knn, # pipe with KNN regressor\n",
    "                    params_knn,     # hyperparameters to test\n",
    "                    cv=5,           # nombre of cross validation folds\n",
    "                    scoring=('r2','neg_mean_absolute_error'),   # scoring to optimize\n",
    "                    return_train_score = True,\n",
    "                    refit='neg_mean_absolute_error',\n",
    "                    n_jobs = -1)\n",
    "\n",
    "start_time55 = time.time()\n",
    "knn_SEU = knn_grid_cv.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm55 = time.time() - start_time55\n",
    "\n",
    "Y_pred = knn_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('KNN regression \\n without target transformation', size = 22)\n",
    "r2_test55 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test55 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test55 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test55, MAE_test55, RMSE_test55), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #################################################################################\n",
    "# Transform targets in Log and use same KNN model\n",
    "\n",
    "knn_grid_cvlog = GridSearchCV(\n",
    "                    pipe_knn, # pipe with KNN regressor\n",
    "                    params_knn,     # hyperparameters to test\n",
    "                    cv=5,           # nombre of cross validation folds\n",
    "                    scoring=('r2','neg_mean_absolute_error'),   # scoring to optimize\n",
    "                    return_train_score = True,\n",
    "                    refit='neg_mean_absolute_error',\n",
    "                    n_jobs = -1)\n",
    "\n",
    "start_time_55 = time.time()\n",
    "knn_SEU_log = knn_grid_cvlog.fit(X_train, Y_train['LogSEU'])\n",
    "tm_55 = time.time() - start_time_55\n",
    "\n",
    "Y_pred = knn_SEU_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('KNN regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_55 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_55 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_55 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_55, MAE_test_55, RMSE_test_55), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', knn_SEU.best_params_)\n",
    "print('Best parameters log scale:', knn_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a79edd",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - KNN REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e616d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use KNN model\n",
    "\n",
    "start_time5b = time.time()\n",
    "knn_GHG = knn_grid_cv.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm5b = time.time() - start_time5b\n",
    "\n",
    "Y_pred = knn_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('KNN regression \\n without target transformation', size = 22)\n",
    "r2_train5b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train5b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train5b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train5b, MAE_train5b, RMSE_train5b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ######################################################################################\n",
    "# Transform targets in Log and use same KNN model\n",
    "\n",
    "start_time_5b = time.time()\n",
    "knn_GHG_log = knn_grid_cvlog.fit(X_train, Y_train['LogGHG'])\n",
    "tm_5b = time.time() - start_time_5b\n",
    "\n",
    "Y_pred = knn_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('KNN regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_5b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_5b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_5b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_5b, MAE_train_5b, RMSE_train_5b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e)\", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', knn_GHG.best_params_)\n",
    "print('Best parameters log scale:', knn_GHG_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f9bfe",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - KNN REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c5eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use KNN model\n",
    "\n",
    "start_time55b = time.time()\n",
    "knn_GHG = knn_grid_cv.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm55b = time.time() - start_time55b\n",
    "\n",
    "Y_pred = knn_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('KNN regression \\n without target transformation', size = 22)\n",
    "r2_test55b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test55b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test55b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test55b, MAE_test55b, RMSE_test55b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# #################################################################################\n",
    "# Transform targets in Log and use same KNN model\n",
    "\n",
    "start_time_55b = time.time()\n",
    "knn_GHG_log = knn_grid_cvlog.fit(X_train, Y_train['LogGHG'])\n",
    "tm_55b = time.time() - start_time_55b\n",
    "\n",
    "Y_pred = knn_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('KNN regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_55b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_55b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_55b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_55b, MAE_test_55b, RMSE_test_55b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e)\", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', knn_GHG.best_params_)\n",
    "print('Best parameters log scale:', knn_GHG_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ef972",
   "metadata": {},
   "source": [
    "### 2-6) SVM REGRESSION \n",
    "\n",
    "Support Vector Regression is a supervised learning algorithm that is used to predict discrete values. Support Vector Regression uses the same principle as the SVMs. The basic idea behind SVR is to find the best fit line. In SVR, the best fit line is the hyperplane that has the maximum number of points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c71296",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - SVM REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef8d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use SVM model\n",
    "\n",
    "pipe_svr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', LinearSVR())])\n",
    "\n",
    "params_svr = {'regressor__epsilon' : [0.1, 1, 0.01 ], # Epsilon parameter in the epsilon-insensitive loss function (default=0)\n",
    "             'regressor__C' : [0.1, 1, 0.01], # Regularization parameter. The strength of the regularization is inversely proportional to C.\n",
    "             'regressor__loss' : [\"epsilon_insensitive\",\"squared_epsilon_insensitive\"], # Specifies the loss function \n",
    "             'regressor__max_iter': [10, 100, 1000, 2000]} # The maximum number of iterations to be run (default=1000)\n",
    "\n",
    "grid_cvsvr = GridSearchCV(pipe_svr, \n",
    "                          param_grid=params_svr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time6 = time.time()\n",
    "svr_SEU = grid_cvsvr.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm6 = time.time() - start_time6\n",
    "\n",
    "Y_pred = svr_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('SVM regression \\n without target transformation', size = 22)\n",
    "r2_train6 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train6 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train6 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 85e6, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train6, MAE_train6, RMSE_train6), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #########################################################################################\n",
    "# Transform targets and use same SVM model\n",
    "\n",
    "grid_cvsvr_log = GridSearchCV(pipe_svr, \n",
    "                          param_grid=params_svr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time_6 = time.time()\n",
    "svr_SEU_log = grid_cvsvr_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_6 = time.time() - start_time_6\n",
    "\n",
    "Y_pred = svr_SEU_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('SVM regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_6 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_6 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_6 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_6, MAE_train_6, RMSE_train_6), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', svr_SEU.best_params_)\n",
    "print('Best parameters log scale:', svr_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de72c4b",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - SVM REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c6617",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use SVM model\n",
    "\n",
    "pipe_svr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', LinearSVR())])\n",
    "\n",
    "start_time66 = time.time()\n",
    "svr_SEU = grid_cvsvr.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm66 = time.time() - start_time66\n",
    "\n",
    "Y_pred = svr_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('SVM regression \\n without target transformation', size = 22)\n",
    "r2_test66 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test66 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test66 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 85e6, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test66, MAE_test66, RMSE_test66), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ############################################################################\n",
    "# Transform targets and use same SVM model\n",
    "\n",
    "start_time_66 = time.time()\n",
    "svr_SEU_log = grid_cvsvr_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_66 = time.time() - start_time_66\n",
    "\n",
    "Y_pred = svr_SEU_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('SVM regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_66 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_66 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_66 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_66, MAE_test_66, RMSE_test_66), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', svr_SEU.best_params_)\n",
    "print('Best parameters log scale:', svr_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd2717",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - SVM REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d98c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use SVM model\n",
    "\n",
    "start_time6b = time.time()\n",
    "svr_GHG = grid_cvsvr.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm6b = time.time() - start_time6b\n",
    "\n",
    "Y_pred = svr_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('SVM regression \\n without target transformation', size = 22)\n",
    "r2_train6b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train6b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train6b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train6b, MAE_train6b, RMSE_train6b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ######################################################################################\n",
    "# Transform targets and use same SVM model\n",
    "\n",
    "start_time_6b = time.time()\n",
    "svr_GHG_log = grid_cvsvr_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_6b = time.time() - start_time_6b\n",
    "\n",
    "Y_pred = svr_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('SVM regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_6b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_6b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_6b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_6b, MAE_train_6b, RMSE_train_6b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', svr_GHG.best_params_)\n",
    "print('Best parameters log scale:', svr_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0bf93",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - SVM REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use SVM model\n",
    "\n",
    "start_time66b = time.time()\n",
    "svr_GHG = grid_cvsvr.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm66b = time.time() - start_time66b\n",
    "\n",
    "Y_pred = svr_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('SVM regression \\n without target transformation', size = 22)\n",
    "r2_test66b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test66b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test66b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test66b, MAE_test66b, RMSE_test66b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ######################################################################################\n",
    "# Transform targets and use same SVM model\n",
    "\n",
    "start_time_66b = time.time()\n",
    "svr_GHG_log = grid_cvsvr_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_66b = time.time() - start_time_66b\n",
    "\n",
    "Y_pred = svr_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('SVM regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_66b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_66b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_66b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_66b, MAE_test_66b, RMSE_test_66b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', svr_GHG.best_params_)\n",
    "print('Best parameters log scale:', svr_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28104ad7",
   "metadata": {},
   "source": [
    "### 2-7) RANDOMFOREST REGRESSION\n",
    "\n",
    "Random Forest Regression is a supervised learning algorithm that uses ensemble learning method for regression. Ensemble learning method is a technique that combines predictions from multiple machine learning algorithms to make a more accurate prediction than a single model.<br> A Random Forest operates by constructing several decision trees during training time and outputting the mean of the classes as the prediction of all the trees.<br>\n",
    "The hyperparameters we considered here include the number of features, number of trees, maximum depth of trees, whether to bootstrap samples, the minimum number of samples left in a node before a split and the minimum number of samples left in the final leaf node.\n",
    "https://www.researchgate.net/publication/268509189_Sentiment_Mining_of_Movie_Reviews_using_Random_Forest_with_Tuned_Hyperparameters\n",
    "https://arxiv.org/pdf/1706.09865.pdf<br>\n",
    "https://arxiv.org/pdf/1710.04725.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990ca582",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - RANDOMFOREST REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03841575",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use RandomForest model\n",
    "\n",
    "pipe_rfr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', RandomForestRegressor())])\n",
    "\n",
    "params_rfr = {'regressor__max_features' : ['auto', 'sqrt', 'log2'], # The number of features to consider when looking for the best split\n",
    "             'regressor__max_depth': [5, 15, 25, 50, 100], # The maximum depth of the tree\n",
    "             'regressor__min_samples_split': [2, 5, 10], # The minimum number of samples required to split an internal node (default=2)\n",
    "             'regressor__bootstrap' : [True, False], # Whether bootstrap samples are used when building trees\n",
    "             'regressor__min_samples_leaf': [1,2,5,10]} # The minimum number of samples required to be at a leaf node (default=1)\n",
    "\n",
    "\n",
    "grid_cvrfr = GridSearchCV(pipe_rfr,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time7 = time.time()\n",
    "rfr_SEU = grid_cvrfr.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm7 = time.time() - start_time7\n",
    "\n",
    "Y_pred = rfr_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('RandomForest regression \\n without target transformation', size = 22)\n",
    "r2_train7 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train7 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train7 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train7, MAE_train7, RMSE_train7), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ##################################################################################\n",
    "# Transform targets and use same RandomForest model\n",
    "\n",
    "pipe_rfr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', RandomForestRegressor())])\n",
    "\n",
    "grid_cvrfr_log = GridSearchCV(pipe_rfr,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time_7 = time.time()\n",
    "rfr_SEU_log = grid_cvrfr_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_7 = time.time() - start_time_7\n",
    "\n",
    "Y_pred = rfr_SEU_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('RandomForest regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_7 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_7 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_7 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_7, MAE_train_7, RMSE_train_7), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', rfr_SEU.best_params_)\n",
    "print('Best parameters log scale:', rfr_SEU_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c935c",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - RANDOMFOREST REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use RandomForest model\n",
    "\n",
    "pipe_rfr = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', RandomForestRegressor())])\n",
    "\n",
    "params_rfr = {'regressor__max_features' : ['auto', 'sqrt', 'log2'], # The number of features to consider when looking for the best split\n",
    "             'regressor__max_depth': [5, 15, 25, 50, 100], # The maximum depth of the tree\n",
    "             'regressor__min_samples_split': [2, 5, 10], # The minimum number of samples required to split an internal node (default=2)\n",
    "             'regressor__bootstrap' : [True, False], # Whether bootstrap samples are used when building trees\n",
    "             'regressor__min_samples_leaf': [1,2,5,10]} # The minimum number of samples required to be at a leaf node (default=1)\n",
    "\n",
    "\n",
    "grid_cvrfr = GridSearchCV(pipe_rfr,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time77 = time.time()\n",
    "rfr_SEU = grid_cvrfr.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm77 = time.time() - start_time77\n",
    "\n",
    "Y_pred = rfr_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('RandomForest regression \\n without target transformation', size = 22)\n",
    "r2_test77 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test77 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test77 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test77, MAE_test77, RMSE_test77), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #######################################################################################\n",
    "# Transform targets and use same RandomForest model\n",
    "\n",
    "start_time_77 = time.time()\n",
    "rfr_SEU_log = grid_cvrfr_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_77 = time.time() - start_time_77\n",
    "\n",
    "Y_pred = rfr_SEU_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('RandomForest regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_77 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_77 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_77 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_77, MAE_test_77, RMSE_test_77), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', rfr_SEU.best_params_)\n",
    "print('Best parameters log scale:', rfr_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781163b0",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - RANDOMFOREST REGRESSION ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use RandomForest model\n",
    "\n",
    "start_time7b = time.time()\n",
    "rfr_GHG = grid_cvrfr.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm7b = time.time() - start_time7b\n",
    "\n",
    "Y_pred = rfr_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('RandomForest regression \\n without target transformation', size = 22)\n",
    "r2_train7b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train7b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train7b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train7b, MAE_train7b, RMSE_train7b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ####################################################################################\n",
    "# Transform targets and use same RandomForest model\n",
    "\n",
    "start_time_7b = time.time()\n",
    "rfr_GHG_log = grid_cvrfr_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_7b = time.time() - start_time_7b\n",
    "\n",
    "Y_pred = rfr_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('RandomForest regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_7b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_7b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_7b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_7b, MAE_train_7b, RMSE_train_7b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHG Emissions (MetricsTon) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', rfr_GHG.best_params_)\n",
    "print('Best parameters log scale:', rfr_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbad6acc",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - RANDOMFOREST REGRESSION ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ef175",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use RandomForest model\n",
    "\n",
    "start_time77b = time.time()\n",
    "rfr_GHG = grid_cvrfr.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm77b = time.time() - start_time77b\n",
    "\n",
    "Y_pred = rfr_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('RandomForest regression \\n without target transformation', size = 22)\n",
    "r2_test77b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test77b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test77b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test77b, MAE_test77b, RMSE_test77b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ##################################################################################\n",
    "# Transform targets and use same RandomForest model\n",
    "\n",
    "start_time_77b = time.time()\n",
    "rfr_GHG_log = grid_cvrfr_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_77b = time.time() - start_time_77b\n",
    "\n",
    "Y_pred = rfr_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('RandomForest regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_77b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_77b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_77b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_77b, MAE_test_77b, RMSE_test_77b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHG Emissions (MetricsTon) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', rfr_GHG.best_params_)\n",
    "print('Best parameters log scale:', rfr_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e158a1",
   "metadata": {},
   "source": [
    "### 2-8) XGBOOST REGRESSION\n",
    "\n",
    "XGBoost was developed to increase speed and performance, while introducing regularization parameters to reduce overfitting. Gradient boosted trees use regression trees in a sequential learning process as weak learners. These regression trees are similar to decision trees, however, they use a continuous score assigned to each leaf (i.e. the last node once the tree has finished growing) which is summed up and provides the final prediction.<br>\n",
    "The hyperparameters we consider here are the learning rate, maximum depth of trees, minimum weights in child notes for splitting and number of estimators (trees). While higher values for the number of estimators and weights in child notes are associated with decreased overfitting, the learning rate and maximum depth need to have lower values to achieve reduced overfitting. Yet, extreme values will lead to underfitting of the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae19e8e",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - XGBOOST ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eddb59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use XGBoost model\n",
    "\n",
    "pipe_xgb = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('regressor', xgb.XGBRegressor())])\n",
    "\n",
    "params_xgb = {'regressor__n_estimators': [0, 1000, 100], # Number of trees in XGBoost (default=100)\n",
    "             'regressor__min_child_weight' : [1.0, 10.0, 1.0], # Minimum sum of instance weight needed in a child (default=1)\n",
    "             'regressor__max_depth': [6, 20, 1], # Maximum depth of a tree (default=6). Increasing this value will make\n",
    "                                                 # the model more complex and more likely to overfit.\n",
    "             'regressor__learning_rate' : [0.001, 0.01, 0.1, 0.2, 0.3], # Weight factor for the corrections by new trees\n",
    "                                                                        # to slow down the learning\n",
    "             'regressor__gamma': [0, 10, 0.1]} # Minimum loss reduction required to make a further partition \n",
    "                                               # on a leaf node of the tree (default=0)\n",
    "                     \n",
    "grid_cvxgb = GridSearchCV(pipe_xgb,\n",
    "                          param_grid = params_xgb,\n",
    "                          cv = 5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit = 'neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time8 = time.time()\n",
    "xgb_SEU = grid_cvxgb.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm8 = time.time() - start_time8\n",
    "\n",
    "Y_pred = xgb_SEU.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('XGBoost regression \\n without target transformation', size = 22)\n",
    "r2_train8 = r2_score(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_train8 = mean_absolute_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_train8 = np.sqrt(mean_squared_error(Y_train['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train8, MAE_train8, RMSE_train8), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# #################################################################################\n",
    "# Transform targets and use same XGBoost model\n",
    "\n",
    "grid_cvxgb_log = GridSearchCV(pipe_xgb,\n",
    "                          param_grid = params_xgb,\n",
    "                          cv = 5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit = 'neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time_8 = time.time()\n",
    "xgb_SEU_log = grid_cvxgb_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_8 = time.time() - start_time_8\n",
    "\n",
    "Y_pred = xgb_SEU_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('XGBoost regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_8 = r2_score(Y_train['LogSEU'], Y_pred)\n",
    "MAE_train_8 = mean_absolute_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_train_8 = np.sqrt(mean_squared_error(np.expm1(Y_train['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_8, MAE_train_8, RMSE_train_8), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', xgb_SEU.best_params_)\n",
    "print('Best parameters log scale:', xgb_SEU_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f00665",
   "metadata": {},
   "source": [
    "#### SITE ENERGY USE - XGBOOST ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43932f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use XGBoost model\n",
    "\n",
    "start_time88 = time.time()\n",
    "xgb_SEU = grid_cvxgb.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm88 = time.time() - start_time88\n",
    "\n",
    "Y_pred = xgb_SEU.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "ax0.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('XGBoost regression \\n without target transformation', size = 22)\n",
    "r2_test88 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test88 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test88 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "ax0.text(5e6, 8e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test88, MAE_test88, RMSE_test88), size = 16)\n",
    "ax0.set_xlim([0, 1e8])\n",
    "ax0.set_ylim([0, 1e8])\n",
    "\n",
    "# ############################################################################\n",
    "# Transform targets and use same XGBoost model\n",
    "\n",
    "start_time_88 = time.time()\n",
    "xgb_SEU_log = grid_cvxgb_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm_88 = time.time() - start_time_88\n",
    "\n",
    "Y_pred = xgb_SEU_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 1e8], [0, 1e8], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('XGBoost regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_88 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test_88 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test_88 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "ax1.text(5e6, 9e7, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_88, MAE_test_88, RMSE_test_88), size = 16)\n",
    "ax1.set_xlim([0, 1e8])\n",
    "ax1.set_ylim([0, 1e8])\n",
    "\n",
    "f.suptitle(\"Site Energy Use (kBtu) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', xgb_SEU.best_params_)\n",
    "print('Best parameters log scale:', xgb_SEU_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eff94c",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - XGBOOST ON TRAINING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use XGBoost model\n",
    "\n",
    "start_time8b = time.time()     \n",
    "xgb_GHG = grid_cvxgb.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm8b = time.time() - start_time8b\n",
    "\n",
    "Y_pred = xgb_GHG.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('XGBoost regression \\n without target transformation', size = 22)\n",
    "r2_train8b = r2_score(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_train8b = mean_absolute_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_train8b = np.sqrt(mean_squared_error(Y_train['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train8b, MAE_train8b, RMSE_train8b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ##############################################################################\n",
    "# Transform targets and use same XGBoost model\n",
    "\n",
    "start_time_8b = time.time()\n",
    "xgb_GHG_log = grid_cvxgb_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_8b = time.time() - start_time_8b\n",
    "\n",
    "Y_pred = xgb_GHG_log.predict(X_train)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('XGBoost regression \\n with LOG target transformation', size = 22)\n",
    "r2_train_8b = r2_score(Y_train['LogGHG'], Y_pred)\n",
    "MAE_train_8b = mean_absolute_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_train_8b = np.sqrt(mean_squared_error(np.expm1(Y_train['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_train_8b, MAE_train_8b, RMSE_train_8b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', xgb_GHG.best_params_)\n",
    "print('Best parameters log scale:', xgb_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8c0f0",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS - XGBOOST ON TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab4b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use XGBoost model\n",
    "\n",
    "start_time88b = time.time()                 \n",
    "xgb_GHG = grid_cvxgb.fit(X_train, Y_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm88b = time.time() - start_time88b\n",
    "\n",
    "Y_pred = xgb_GHG.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('XGBoost regression \\n without target transformation', size = 22)\n",
    "r2_test88b = r2_score(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "MAE_test88b = mean_absolute_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred)\n",
    "RMSE_test88b = np.sqrt(mean_squared_error(Y_test['GHGEmissions(MetricTonsCO2e)'], Y_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test88b, MAE_test88b, RMSE_test88b), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# #########################################################################################\n",
    "# Transform targets and use same XGBoost model\n",
    "\n",
    "start_time_88b = time.time()\n",
    "xgb_GHG_log = grid_cvxgb_log.fit(X_train, Y_train['LogGHG'])\n",
    "tm_88b = time.time() - start_time_88b\n",
    "\n",
    "Y_pred = xgb_GHG_log.predict(X_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('XGBoost regression \\n with LOG target transformation', size = 22)\n",
    "r2_test_88b = r2_score(Y_test['LogGHG'], Y_pred)\n",
    "MAE_test_88b = mean_absolute_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred))\n",
    "RMSE_test_88b = np.sqrt(mean_squared_error(np.expm1(Y_test['LogGHG']), np.expm1(Y_pred)))\n",
    "ax1.text(1e3, 1e4, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test_88b, MAE_test_88b, RMSE_test_88b), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHGEmissions(MetricTonsCO2e) \", x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', xgb_GHG.best_params_)\n",
    "print('Best parameters log scale:', xgb_GHG_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d97709",
   "metadata": {},
   "source": [
    "### 2-9) RESULTS DATAFRAME \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e9a540",
   "metadata": {},
   "source": [
    "#### 2-9-1) ENERGY CONSUMPTION RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b9fce6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = ['R2 Train', 'R2 Test', 'MAE Train', \"MAE Test\", \"RMSE Train\", \"RMSE Test\", 'Running time(s) Train', 'Running time(s) Test']\n",
    "reg_met_SEU = {\n",
    "           'dummy' : pd.Series([r2_train0a, r2_test0a, MAE_train0a, MAE_test0a, RMSE_train0a, RMSE_test0a, tm0a, tm0a],\n",
    "                        index = results),    \n",
    "           'Linear lin' : pd.Series([r2_train1, r2_test11, MAE_train1, MAE_test11, RMSE_train1, RMSE_test11, tm1, tm11],\n",
    "                        index = results),\n",
    "           'Linear Log' : pd.Series([r2_train_1, r2_test_11, MAE_train_1, MAE_test_11, RMSE_train_1, RMSE_test_11, tm_1, tm_11],\n",
    "                        index = results),    \n",
    "           'Lasso lin' : pd.Series([r2_train2, r2_test22, MAE_train2, MAE_test22, RMSE_train2, RMSE_test22, tm2, tm22],\n",
    "                        index = results),\n",
    "           'Lasso Log' : pd.Series([r2_train_2, r2_test_22, MAE_train_2, MAE_test_22, RMSE_train_2, RMSE_test_22, tm_2, tm_22],\n",
    "                        index = results),\n",
    "           'Ridge lin' : pd.Series([r2_train3, r2_test33, MAE_train3, MAE_test33, RMSE_train3, RMSE_test33, tm3, tm33],\n",
    "                        index = results),\n",
    "           'Ridge Log' : pd.Series([r2_train_3, r2_test_33, MAE_train_3, MAE_test_33, RMSE_train_3, RMSE_test_33, tm_3, tm_33],\n",
    "                        index = results),\n",
    "           'ElasticNet lin' : pd.Series([r2_train4, r2_test44, MAE_train4, MAE_test44, RMSE_train4, RMSE_test44, tm4, tm44],\n",
    "                         index = results),\n",
    "           'ElasticNet Log' : pd.Series([r2_train_4, r2_test_44, MAE_train_4, MAE_test_44, RMSE_train_4, RMSE_test_44, tm_4, tm_44],\n",
    "                         index = results),\n",
    "           'KNN lin' : pd.Series([r2_train5, r2_test55, MAE_train5, MAE_test55, RMSE_train5, RMSE_test55, tm5, tm55],\n",
    "                        index = results),\n",
    "           'KNN Log' : pd.Series([r2_train_5, r2_test_55, MAE_train_5, MAE_test_55, RMSE_train_5, RMSE_test_55, tm_5, tm_55],\n",
    "                        index = results),\n",
    "#SVM regression was left aside for plotting purposes             \n",
    "#          'SVM lin' : pd.Series([r2_train6, r2_test66, MAE_train6, MAE_test66, RMSE_train6, RMSE_test66 ,tm6, tm66],\n",
    "#                       index = results),\n",
    "#          'SVM Log' : pd.Series([r2_train_6, r2_test_66, MAE_train_6, MAE_test_66, RMSE_train_6, RMSE_test_66 ,tm_6, tm_66],\n",
    "#                       index = results),\n",
    "           'RandomForest lin' : pd.Series([r2_train7, r2_test77, MAE_train7, MAE_test77, RMSE_train7, RMSE_test77, tm7, tm77],\n",
    "                        index = results),\n",
    "           'RandomForest Log' : pd.Series([r2_train_7, r2_test_77, MAE_train_7, MAE_test_77, RMSE_train_7, RMSE_test_77, tm_7, tm_77],\n",
    "                        index = results),\n",
    "           'XGBoost lin' : pd.Series([r2_train8, r2_test88, MAE_train8, MAE_test88, RMSE_train8, RMSE_test88, tm8, tm88],\n",
    "                        index = results),\n",
    "           'XGBoost Log' : pd.Series([r2_train_8, r2_test_88, MAE_train_8, MAE_test_88, RMSE_train_8, RMSE_test_88, tm_8, tm_88],\n",
    "                        index = results)}\n",
    "\n",
    "# Creates Dataframe df_results_SEU for Site Energy Use\n",
    "\n",
    "df_results_SEU = pd.DataFrame(reg_met_SEU)\n",
    "index = df_results_SEU.index\n",
    "index. name = \"Metrics\"\n",
    "df_results_SEU.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2891caf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_SEU = df_results_SEU.T\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_SEU1 = df_SEU[[\"MAE Train\", \"MAE Test\"]].plot( y=[\"MAE Train\", \"MAE Test\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.title(\"Mean Absolute Error for the different models \\n Site Energy Use\", weight = 'bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837b072b",
   "metadata": {},
   "source": [
    "From the above chart, we can clearly see that the Mean Absolute Error differ quite significantly from the linear models to the non linear models. Transforming our targets to log scale also have an impact on the errors.<br>\n",
    "\n",
    "1) On a general basis and on a linear scale, the MAE remains quite constant between the train & the test. MAE on the test is slightly higher than on the train - the model has already seen the training set during training. So its easier to score high accuracy on training set. Test set on the other hand is unseen so we generally expect Test MAE to be higher as it more difficult to perform well on unseen data.<br>\n",
    "\n",
    "2) However, for the linear models, transforming our targets to log scale increases the MAE on the training set, which is quite unusual. Test MAE is lower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836eec5",
   "metadata": {},
   "source": [
    "RandomForest and XGBoost return the lowest MAE compared to the linear models. In addition, these models are quite insensitive to the log target transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937c108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_SEU22 = df_SEU.plot( y=[\"R2 Train\", \"R2 Test\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\")\n",
    "plt.ylabel(\"Running_time(s)\")\n",
    "plt.ylim([0.5, 1.1])\n",
    "plt.title('R2 comparison between the different models \\n Site Energy Use', weight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f06e6ef",
   "metadata": {},
   "source": [
    "The coefficient of determination R2 is also higher with non linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb2670",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_SEU22 = df_SEU.plot( y=[\"Running time(s) Train\", \"Running time(s) Test\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\")\n",
    "plt.ylabel(\"Running_time(s)\")\n",
    "plt.title('Running time comparison between the different models \\n Site Energy Use', weight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c821986",
   "metadata": {},
   "source": [
    "As for the running time, we can clearly see that XGBoost takes much more time than RandomForest. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16df853e",
   "metadata": {},
   "source": [
    "#### 2-9-2) GHG EMISSIONS RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bc1b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = ['R2 Train', 'R2 Test', 'MAE Train', \"MAE Test\", \"RMSE Train\", \"RMSE Test\", 'Running time(s) Train', 'Running time(s) Test']\n",
    "reg_met_GHG = {'dummy' : pd.Series([r2_train_00, r2_test_00, MAE_train_00, MAE_test_00, RMSE_train_00, RMSE_test_00, np.nan, tm0b],\n",
    "                        index = results),    \n",
    "           'Linear lin' : pd.Series([r2_train1b, r2_test11b, MAE_train1b, MAE_test11b, RMSE_train1b, RMSE_test11b, tm1b, tm11b],\n",
    "                        index = results),\n",
    "           'Linear Log' : pd.Series([r2_train_1b, r2_test_11b, MAE_train_1b, MAE_test_11b, RMSE_train_1b, RMSE_test_11b, tm_1b, tm_11b],\n",
    "                        index = results),    \n",
    "           'Lasso lin' : pd.Series([r2_train2b, r2_test22b, MAE_train2b, MAE_test22b, RMSE_train2b, RMSE_test22b, tm2b, tm22b],\n",
    "                        index = results),\n",
    "           'Lasso Log' : pd.Series([r2_train_2b, r2_test_22b, MAE_train_2b, MAE_test_22b, RMSE_train_2b, RMSE_test_22b, tm_2b, tm_22b],\n",
    "                        index = results),\n",
    "           'Ridge lin' : pd.Series([r2_train3b, r2_test33b, MAE_train3b, MAE_test33b, RMSE_train3b, RMSE_test33b, tm3b, tm33b],\n",
    "                        index = results),\n",
    "           'Ridge Log' : pd.Series([r2_train_3b, r2_test_33b, MAE_train_3b, MAE_test_33b, RMSE_train_3b, RMSE_test_33b, tm_3b, tm_33b],\n",
    "                        index = results),\n",
    "           'ElasticNet lin' : pd.Series([r2_train4b, r2_test44b, MAE_train4b, MAE_test44b, RMSE_train4b, RMSE_test44b, tm4b, tm44b],\n",
    "                        index = results),\n",
    "           'ElasticNet Log' : pd.Series([r2_train_4b, r2_test_44b, MAE_train_4b, MAE_test_44b, RMSE_train_4b, RMSE_test_44b, tm_4b, tm_44b],\n",
    "                        index = results),\n",
    "           'KNN lin' : pd.Series([r2_train5b, r2_test55b, MAE_train5b, MAE_test55b, RMSE_train5b, RMSE_test55b, tm5b, tm55b],\n",
    "                        index = results),\n",
    "           'KNN Log' : pd.Series([r2_train_5b, r2_test_55b, MAE_train_5b, MAE_test_55b, RMSE_train_5b, RMSE_test_55b, tm_5b, tm_55b],\n",
    "                        index = results),\n",
    "#           'SVM lin' : pd.Series([r2_train_6b, r2_test_66b, MAE_train_6b, MAE_test_66b, RMSE_train_6b, RMSE_test_66b, tm_6b, tm_66b],\n",
    "#                        index = results),\n",
    "#           'SVM Log' : pd.Series([r2_train_6b, r2_test_66b, MAE_train_6b, MAE_test_66b, RMSE_train_6b, RMSE_test_66b, tm_6b, tm_66b],\n",
    "#                        index = results),  \n",
    "           'RandomForest lin' : pd.Series([r2_train7b, r2_test77b, MAE_train7b, MAE_test77b, RMSE_train7b, RMSE_test77b, tm7b, tm77b],\n",
    "                        index = results),\n",
    "           'RandomForest Log' : pd.Series([r2_train_7b, r2_test_77b, MAE_train_7b, MAE_test_77b, RMSE_train_7b, RMSE_test_77b, tm_7b, tm_77b],\n",
    "                        index = results),\n",
    "           'XGBoost lin' : pd.Series([r2_train8b, r2_test88b, MAE_train8b, MAE_test88b, RMSE_train8b, RMSE_test88b, tm8b, tm88b],\n",
    "                        index = results),\n",
    "           'XGBoost Log' : pd.Series([r2_train_8b, r2_test_88b, MAE_train_8b, MAE_test_88b, RMSE_train_8b, RMSE_test_88b, tm_8b, tm_88b],\n",
    "                        index = results)}\n",
    "\n",
    "# Creates Dataframe df_results_GHG for GHG Emissions\n",
    "\n",
    "df_results_GHG = pd.DataFrame(reg_met_GHG)\n",
    "index = df_results_GHG.index\n",
    "index. name = \"Metrics\"\n",
    "df_results_GHG.round(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59edde23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_GHG = df_results_GHG.T\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_SEU1 = df_SEU[[\"MAE Train\", \"MAE Test\"]].plot( y=[\"MAE Train\", \"MAE Test\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\")\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.title(\"Mean Absolute Error for the different models \\n GHG Emissions\", weight = 'bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe52ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_GHG22 = df_GHG.plot( y=[\"R2 Train\", \"R2 Test\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\")\n",
    "plt.ylabel(\"Running_time(s)\")\n",
    "plt.ylim([0.3, 1.1])\n",
    "plt.title('R2 comparison between the different models \\n GHG Emissions', weight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_GHG22 = df_GHG.plot( y=[\"Running time(s) Train\", \"Running time(s) Test\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\")\n",
    "plt.ylabel(\"Running_time(s)\")\n",
    "plt.title('Running time comparison between the different models \\n GHG Emissions', weight = \"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d67b963",
   "metadata": {},
   "source": [
    "Based on these results, ensemble methods proved to be more efficient than linear regressions. The lowest MAE were generated by XGBoost & RandomForest regression.\n",
    "\n",
    "Like random forests, XGBoost is a set of decision trees. The two main differences are:\n",
    "\n",
    "__How trees are built:__ random forests builds each tree independently while gradient boosting builds one tree at a time. This additive model (ensemble) works in a forward stage-wise manner, introducing a weak learner to improve the shortcomings of existing weak learners.<br> \n",
    "__Combining results:__ random forests combine results at the end of the process (by averaging or \"majority rules\") while gradient boosting combines results along the way.<br>\n",
    "\n",
    "One of the striking difference between our Random Forest and XGBoost regressions is the computational time which is almost 10 times higher for the XGBoost on the Energy Consumption and X4 for the GHG Emissions. <br>\n",
    "This can be partly explained by the number of trees in the hyperparameters.<br>\n",
    "In our RandomForest regression, we decided not to tune the number of trees as few studies have shown that (sic) \"although we claim that increasing the number of trees cannot harm noticeably as far as measures based on average loss are considered, our empirical results show that for most of the examined datasets, the biggest performance gain is achieved when training the first 100 trees\".(ref: https://www.jmlr.org/papers/volume18/17-269/17-269.pdf)<br>\n",
    "\n",
    "Based on this paper, we decided to keep a default value of 100 for the number of trees in the Random Forest regression as opposed to a range of [0-1000] for XGBoost parameters.<br>\n",
    "\n",
    "A quick sensitivity study was performed to check the impact of integrating the number of trees as an hyperparameter in the Random Forest regression. Running time and scoring parameter (MAE) were then compared on Site Energy Use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb95afa7",
   "metadata": {},
   "source": [
    "__SENSITIVITY ON THE HYPERPARAMETER: NUMBER OF TREES IN RANDOMFOREST REGRESSION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c5fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RandomForest model\n",
    "\n",
    "params_rfr = {'regressor__n_estimators': [0, 1000, 100], # We allow the creation of 1000 trees\n",
    "             'regressor__max_features' : ['auto', 'sqrt', 'log2'], \n",
    "             'regressor__max_depth': [5, 15, 25, 50, 100], \n",
    "             'regressor__min_samples_split': [2, 5, 10], \n",
    "             'regressor__bootstrap' : [True, False], \n",
    "             'regressor__min_samples_leaf': [1,2,5,10]} \n",
    "\n",
    "\n",
    "grid_cvrfr = GridSearchCV(pipe_rfr,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time07 = time.time()\n",
    "rfr_SEU = grid_cvrfr.fit(X_train, Y_train['SiteEnergyUse(kBtu)'])\n",
    "tm07 = time.time() - start_time07\n",
    "\n",
    "Y_pred = rfr_SEU.predict(X_test)\n",
    "\n",
    "r2_test07 = r2_score(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "MAE_test07 = mean_absolute_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred)\n",
    "RMSE_test07 = np.sqrt(mean_squared_error(Y_test['SiteEnergyUse(kBtu)'], Y_pred))\n",
    "\n",
    "# #################################################################################\n",
    "# Transform targets and use same RandomForest model\n",
    "\n",
    "grid_cvrfr_log = GridSearchCV(pipe_rfr,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time071 = time.time()\n",
    "rfr_SEU_log = grid_cvrfr_log.fit(X_train, Y_train['LogSEU'])\n",
    "tm071 = time.time() - start_time071\n",
    "\n",
    "Y_pred = rfr_SEU_log.predict(X_test)\n",
    "\n",
    "r2_test071 = r2_score(Y_test['LogSEU'], Y_pred)\n",
    "MAE_test071 = mean_absolute_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred))\n",
    "RMSE_test071 = np.sqrt(mean_squared_error(np.expm1(Y_test['LogSEU']), np.expm1(Y_pred)))\n",
    "\n",
    "print('Best parameters lin scale:', rfr_SEU.best_params_)\n",
    "print('Best parameters log scale:', rfr_SEU_log.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05108eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = ['R2 Test', \"MAE Test\", \"RMSE Test\", 'Running time(s) Test']\n",
    "sens_rf = {'RandomForest nb trees no tuning (Linear)' : pd.Series([r2_test77, MAE_test77, RMSE_test77, tm77],\n",
    "                        index = results),\n",
    "           'RandomForest nb trees tuning (Linear)' : pd.Series([r2_test07, MAE_test07, RMSE_test07, tm07],\n",
    "                        index = results),\n",
    "           'RandomForest nb trees no tuning (Log)' : pd.Series([r2_test_77, MAE_test_77, RMSE_test_77, tm_77],\n",
    "                        index = results),\n",
    "           'RandomForest nb trees tuning (Log)' : pd.Series([r2_test071, MAE_test071, RMSE_test071,tm071],\n",
    "                        index = results)}\n",
    "\n",
    "# Creates Dataframe df_results_SEU for Site Energy Use\n",
    "\n",
    "df_results_sens_rf = pd.DataFrame(sens_rf)\n",
    "index = df_results_sens_rf.index\n",
    "index. name = \"Metrics\"\n",
    "df_results_sens_rf.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd97be17",
   "metadata": {},
   "source": [
    "As seen on the results above, a RandomForest regression with no tuning on the number of trees (default=100) almost returns the same score as if we incorporated the possibility to create 1000 trees.  By looking at the running time of both algorithms, a factor x10 can be observed. The linear & log scaled model created 1000 trees (instead of 100) for almost the same error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b15e1",
   "metadata": {},
   "source": [
    "__FEATURES IMPORTANCE__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2056600",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = (rfr_SEU.best_estimator_.named_steps['preprocessor']\n",
    "         .named_transformers_['cat'])\n",
    "feature_names = ohe.get_feature_names(cat_data)\n",
    "feature_names = np.r_[feature_names, num_data]\n",
    "\n",
    "tree_feature_importances = (\n",
    "     rfr_SEU.best_estimator_.named_steps['regressor'].feature_importances_)\n",
    "\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "#sorted_array = tree_feature_importances[sorted_idx]\n",
    "#rslt = sorted_array[-10 : ]\n",
    "\n",
    "y_ticks = np.arange(0, len(feature_names)) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 14))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx]) \n",
    "ax.set_yticks(y_ticks)\n",
    "#list = feature_names[sorted_idx]\n",
    "\n",
    "ax.set_yticklabels(feature_names[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\", weight='bold', size = 20)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df748c45",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SKLEARN METHOD\n",
    "\n",
    "ohe = (rfr_SEU.best_estimator_.named_steps['preprocessor']\n",
    "         .named_transformers_['cat'])\n",
    "feature_names = ohe.get_feature_names(cat_data)\n",
    "feature_names = np.r_[feature_names, num_data]\n",
    "\n",
    "tree_feature_importances = (\n",
    "     rfr_SEU.best_estimator_.named_steps['regressor'].feature_importances_)\n",
    "\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "sorted_array = tree_feature_importances[sorted_idx]\n",
    "rslt = sorted_array[-10 : ]\n",
    "\n",
    "y_ticks = np.arange(0, 10) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.barh(y_ticks, rslt) \n",
    "ax.set_yticks(y_ticks)\n",
    "list = feature_names[sorted_idx]\n",
    "\n",
    "ax.set_yticklabels(list[-10:]) \n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating a feature importance dataframe\n",
    "def feature_importance(column_names, importances):\n",
    "    df = pd.DataFrame({'feature': column_names,'feature_importance': importances}).sort_values('feature_importance', ascending = False).reset_index(drop = True)\n",
    "    return df\n",
    "\n",
    "# plotting a feature importance dataframe (horizontal barchart)\n",
    "def feature_importance_plot(feature_importance_df, title):\n",
    "    feature_importance_df.columns = ['feature', 'feature_importance']\n",
    "    sns.barplot(x = 'feature_importance', y = 'feature', data = feature_importance_df.head(8), orient = 'h', color = 'royalblue').set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb4442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rfr_SEU.best_estimator_.named_steps['regressor'].feature_importances_\n",
    "# base_importance = feature_importance(X_train.columns, best_random.feature_importances_)\n",
    "# base_importance\n",
    "X_train.columns\n",
    "best_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd056424",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(rfr_SEU, X_test, Y_test, n_repeats=10,\n",
    "                                random_state=42, n_jobs=2)\n",
    "result\n",
    "#sorted_idx = result.importances_mean.argsort()\n",
    "X_test\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.boxplot(result.importances[sorted_idx].T,\n",
    "#            vert=False, labels=X_test.columns[sorted_idx])\n",
    "# ax.set_title(\"Permutation Importances (test set)\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b77bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### KAGGLE METHOD\n",
    "\n",
    "#rfr_SEU.best_estimator_.named_steps['preprocessor'].transformers_[1][1].named_transformers_['cat']#.get_feature_names(categorical_features)\n",
    "# feature_importance = rfr_SEU.best_estimator_.steps[1][1].feature_importances_\n",
    "\n",
    "ohe = (rfr_SEU.best_estimator_.named_steps['preprocessor']\n",
    "             .named_transformers_['cat'])\n",
    "\n",
    "#features_names = get_feature_names(rfr_SEU.best_estimator_.named_steps['preprocessor'])\n",
    "feature_names = ohe.get_feature_names(cat_data)\n",
    "feature_names = np.r_[feature_names, num_data]\n",
    "#feature_names.shape\n",
    "std = np.std([\n",
    "         tree.feature_importances_ for tree in rfr_SEU_log.best_estimator_.steps[-1][1]], axis=0)\n",
    "std.shape\n",
    "df_feature_importance = pd.Series(feature_importance, index=feature_names)\n",
    "#importances = df_feature_importance.head(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "df_feature_importance.sort_values(ascending=False).plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances du modÃ¨le RandomForestRegressor sur les Ã©missions de CO2\")\n",
    "ax.set_ylabel(\"Diminution moyenne des impuretÃ©s\")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11902d4a",
   "metadata": {},
   "source": [
    "### 2-10) LINEAR REGRESSION FROM SITE ENERGY USE TO GHG EMISSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291cfa96",
   "metadata": {},
   "source": [
    "GHG Emissions are somehow related to to Site Energy Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9287e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax0 = plt.subplots()\n",
    "\n",
    "start_time_best = time.time()\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Test fitting best model (XGBoost) on Site Energy Use to GHG Emissions through a simple linear model\n",
    "xgb_SEU_new = grid_cvxgb_log.fit(X, Y['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "X_new = xgb_SEU_new.predict(X)\n",
    "Y_new = Y['GHGEmissions(MetricTonsCO2e)']\n",
    "\n",
    "X_new_df = pd.DataFrame(X_new)\n",
    "Y_new_df = pd.DataFrame(Y_new)\n",
    "\n",
    "X_new_df_train, X_new_df_test, Y_new_df_train, Y_new_df_test = train_test_split(X_new_df, Y_new_df, test_size=0.2, random_state=42)\n",
    "\n",
    "GHG_forecast = regr.fit(X_new_df_train, Y_new_df_train)\n",
    "tm_best = time.time() - start_time_best\n",
    "\n",
    "Y_pred_new = GHG_forecast.predict(X_new_df_train)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_new_df_train, Y_pred_new)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 12)\n",
    "ax0.set_xlabel('True Target', size = 12)\n",
    "r2_test = r2_score(Y_new_df_train, Y_pred_new)\n",
    "MAE_test = mean_absolute_error(Y_new_df_train, Y_pred_new)\n",
    "RMSE_test = np.sqrt(mean_squared_error(Y_new_df_train, Y_pred_new))\n",
    "ax0.text(1000, 11000, r'$R^2$ Train=%.2f, MAE Train=%.2f, RMSE Train=%.2f' % (r2_test, MAE_test, RMSE_test), size = 12)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# # Transform targets and use same linear model\n",
    "# start_timeb = time.time()\n",
    "\n",
    "Y_pred_new_test = GHG_forecast.predict(X_new_df_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_new_df_test, Y_pred_new_test)\n",
    "#ax0.set_xlabel('True Target', size = 12)\n",
    "ax0.set_title('Linear regression between best Site Energy Use model & GHG Emissions', weight = 'bold', size = 14)\n",
    "r2_test = r2_score(Y_new_df_test, Y_pred_new_test)\n",
    "MAE_test = mean_absolute_error(Y_new_df_test, Y_pred_new_test)\n",
    "RMSE_test = np.sqrt(mean_squared_error(Y_new_df_test, Y_pred_new_test))\n",
    "ax0.text(1000, 10000, r'$R^2$ Test=%.2f, MAE Test=%.2f, RMSE Test=%.2f' % (r2_test, MAE_test, RMSE_test), size = 12)\n",
    "#ax0.set_xlim([0, 12e3])\n",
    "#ax0.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHG Emissions (MetricTonsCO2e)\", x = 0.5, y=0.005, weight = 'bold', size = 14)\n",
    "f.tight_layout(rect=[0.005, 0.005, 1, 1.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ab4dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3587e88a",
   "metadata": {},
   "source": [
    "### 3) IMPACT OF ENERGYSTARScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd8c27",
   "metadata": {},
   "source": [
    "The Energy Star score of a building is a way to asses the energy usage performance of a building by comparing it with similar buildings. It assigns a number to the building in between 0-100 based on its performance. A score of 0 would mean that the building performs the worst among the similar buildings registered to the program and a score of 100 would mean that the building is the best performer. Similarly, a score of 75 or higher means the building is a top performer and may be eligible for ENERGY STAR certification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bc4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Selection \n",
    "\n",
    "df_data['LogSEU'] = np.log1p(df_data['SiteEnergyUse(kBtu)'])\n",
    "df_data['LogGHG'] = np.log1p(df_data['GHGEmissions(MetricTonsCO2e)'])\n",
    "df_energystar = df_data.dropna(subset = [\"ENERGYSTARScore\"])\n",
    "Xstar = df_energystar.drop(['SiteEnergyUse(kBtu)', 'GHGEmissions(MetricTonsCO2e)', 'LogSEU', 'LogGHG'], axis=1)\n",
    "Ystar = df_energystar[['SiteEnergyUse(kBtu)','GHGEmissions(MetricTonsCO2e)', 'LogSEU', 'LogGHG']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73978d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,8))\n",
    "sns.histplot(data=Xstar, x='ENERGYSTARScore', ax=axes[0])\n",
    "axes[0].set_title(\"Distribution of the ENERGYSTARScore\", weight = 'bold', size = 20)\n",
    "\n",
    "sns.scatterplot(data=df_energystar, y='GHGEmissions(MetricTonsCO2e)', x='ENERGYSTARScore', ax=axes[1])\n",
    "axes[1].set_title(\"GHG Emissions v ENERGYSTARScore\", weight = 'bold', size = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b15cea",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS with ENERGYSTARScore - RANDOMFOREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbaa3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "Xstar_train, Xstar_test, Ystar_train, Ystar_test = train_test_split(Xstar, Ystar, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use RandomForest model\n",
    "\n",
    "pipe_rfr_stars = Pipeline(steps=[('preprocessor1', preprocessor1),\n",
    "                           ('regressor', RandomForestRegressor())])\n",
    "\n",
    "grid_cvrfr_stars = GridSearchCV(pipe_rfr_stars,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "#Xstar_train\n",
    "start_time12 = time.time()\n",
    "stars_rfr = grid_cvrfr.fit(Xstar_train, Ystar_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm12 = time.time() - start_time12\n",
    "\n",
    "Ystar_pred = stars_rfr.predict(Xstar_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('RandomForest regression \\n without target transformation but with ENERGYSTARScore', size = 22)\n",
    "r2_test12 = r2_score(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred)\n",
    "MAE_test12 = mean_absolute_error(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred)\n",
    "RMSE_test12 = np.sqrt(mean_squared_error(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test12, MAE_test12, RMSE_test12), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ######################################################################################\n",
    "# Transform targets and use same RandomForest model\n",
    "\n",
    "grid_cvrfr_log = GridSearchCV(pipe_rfr_stars,\n",
    "                          param_grid=params_rfr,\n",
    "                          cv=5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit='neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time121 = time.time()\n",
    "stars_rfr_log = grid_cvrfr_log.fit(Xstar_train, Ystar_train['LogGHG'])\n",
    "Ystar_pred = stars_rfr_log.predict(Xstar_test)\n",
    "tm121 = time.time() - start_time121\n",
    "\n",
    "ax1.scatter(np.expm1(Ystar_test['LogGHG']), np.expm1(Ystar_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('RandomForest regression \\n with LOG target transformation & ENERGYSTARScore', size = 22)\n",
    "r2_test121 = r2_score(Ystar_test['LogGHG'], Ystar_pred)\n",
    "MAE_test121 = mean_absolute_error(np.expm1(Ystar_test['LogGHG']), np.expm1(Ystar_pred))\n",
    "RMSE_test121 = np.sqrt(mean_squared_error(np.expm1(Ystar_test['LogGHG']), np.expm1(Ystar_pred)))\n",
    "ax1.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test121, MAE_test121, RMSE_test121), size = 16)\n",
    "ax1.set_xlim([0, 12e3])\n",
    "ax1.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle('GHGEmissions(MetricTonsCO2e)', x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', stars_rfr.best_params_)\n",
    "print('Best parameters log scale:', stars_rfr_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175efda5",
   "metadata": {},
   "source": [
    "#### GHG EMISSIONS with ENERGYSTARScore - XGBoost REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100444d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, (ax0, ax1) = plt.subplots(1, 2, sharey=True)\n",
    "\n",
    "# Use XGBoost model\n",
    "\n",
    "pipe_xgb_stars = Pipeline(steps=[('preprocessor1', preprocessor1),\n",
    "                          ('regressor', xgb.XGBRegressor())])\n",
    "                    \n",
    "grid_cvxgb_stars = GridSearchCV(pipe_xgb_stars,\n",
    "                          param_grid = params_xgb,\n",
    "                          cv = 5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit = 'neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time13 = time.time()\n",
    "stars_xgb = grid_cvxgb_stars.fit(Xstar_train, Ystar_train['GHGEmissions(MetricTonsCO2e)'])\n",
    "tm13 = time.time() - start_time13\n",
    "\n",
    "Ystar_pred = stars_xgb.predict(Xstar_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 20)\n",
    "ax0.set_xlabel('True Target', size = 20)\n",
    "ax0.set_title('XGBoost regression \\n without target transformation but with ENERGYSTARScore', size = 22)\n",
    "r2_test13 = r2_score(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred)\n",
    "MAE_test13 = mean_absolute_error(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred)\n",
    "RMSE_test13 = np.sqrt(mean_squared_error(Ystar_test['GHGEmissions(MetricTonsCO2e)'], Ystar_pred))\n",
    "ax0.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test13, MAE_test13, RMSE_test13), size = 16)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# ################################################################################\n",
    "# Transform targets and use same XGBoost model\n",
    "\n",
    "xgb_grid_cv = GridSearchCV(pipe_xgb_stars,\n",
    "                          param_grid = params_xgb,\n",
    "                          cv = 5,\n",
    "                          scoring=('r2','neg_mean_absolute_error'),\n",
    "                          return_train_score = True,\n",
    "                          refit = 'neg_mean_absolute_error',\n",
    "                          n_jobs = -1)\n",
    "\n",
    "start_time131 = time.time()\n",
    "stars_xgb_log = xgb_grid_cv.fit(Xstar_train, Ystar_train['LogGHG'])\n",
    "tm131 = time.time() - start_time131\n",
    "\n",
    "Ystar_pred = stars_xgb_log.predict(Xstar_test)\n",
    "\n",
    "# Plot results\n",
    "ax1.scatter(np.expm1(Ystar_test['LogGHG']), np.expm1(Ystar_pred))\n",
    "ax1.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax1.set_ylabel('Target predicted', size = 20)\n",
    "ax1.set_xlabel('True Target', size = 20)\n",
    "ax1.set_title('XGBoost regression \\n with LOG target transformation & ENERGYSTARScore', size = 22)\n",
    "r2_test131 = r2_score(Ystar_test['LogGHG'], Ystar_pred)\n",
    "MAE_test131 = mean_absolute_error(np.expm1(Ystar_test['LogGHG']), np.expm1(Ystar_pred))\n",
    "RMSE_test131 = np.sqrt(mean_squared_error(np.expm1(Ystar_test['LogGHG']), np.expm1(Ystar_pred)))\n",
    "ax1.text(1000, 10000, r'$R^2$=%.2f, MAE=%.2f, RMSE=%.2f' % (r2_test131, MAE_test131, RMSE_test131), size = 16)\n",
    "f.suptitle('GHGEmissions(MetricTonsCO2e)', x = 1.25, y=0.005, weight = 'bold', size = 20)\n",
    "f.tight_layout(rect=[0.005, 0.005, 2.5, 1.5])\n",
    "print('Best parameters lin scale:', stars_xgb.best_params_)\n",
    "print('Best parameters log scale:', stars_xgb_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1b8299",
   "metadata": {},
   "source": [
    "__INTEGRATING ENERGYSTARScore INTO LINEAR REGRESSION__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af67fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax0 = plt.subplots()\n",
    "\n",
    "start_time_best = time.time()\n",
    "regr = LinearRegression()\n",
    "\n",
    "# Test fitting best model (RandomForest) on Site Energy Use to GHG Emissions through a simple linear model\n",
    "xgb_SEU_newstar = grid_cvrfr_stars.fit(Xstar, Ystar['SiteEnergyUse(kBtu)'])\n",
    "\n",
    "X_newstar = xgb_SEU_newstar.predict(Xstar)\n",
    "Y_newstar = Ystar['GHGEmissions(MetricTonsCO2e)']\n",
    "\n",
    "X_new_stardf = pd.DataFrame(X_newstar)\n",
    "Y_new_stardf = pd.DataFrame(Y_newstar)\n",
    "\n",
    "X_new_stardf_train, X_new_stardf_test, Y_new_stardf_train, Y_new_stardf_test = train_test_split(X_new_stardf, Y_new_stardf, test_size=0.2, random_state=42)\n",
    "\n",
    "GHG_forecast = regr.fit(X_new_stardf_train, Y_new_stardf_train)\n",
    "Y_pred_newstar = GHG_forecast.predict(X_new_stardf_train)\n",
    "\n",
    "tm_best = time.time() - start_time_best\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_new_stardf_train, Y_pred_newstar)\n",
    "ax0.plot([0, 12e3], [0, 12e3], '--k')\n",
    "ax0.set_ylabel('Target predicted', size = 12)\n",
    "ax0.set_xlabel('True Target', size = 12)\n",
    "r2_train_star = r2_score(Y_new_stardf_train, Y_pred_newstar)\n",
    "MAE_train_star = mean_absolute_error(Y_new_stardf_train, Y_pred_newstar)\n",
    "RMSE_train_star = np.sqrt(mean_squared_error(Y_new_stardf_train, Y_pred_newstar))\n",
    "ax0.text(1000, 11000, r'$R^2$ Train=%.2f, MAE Train=%.2f, RMSE Train=%.2f' % (r2_test, MAE_test, RMSE_test), size = 12)\n",
    "ax0.set_xlim([0, 12e3])\n",
    "ax0.set_ylim([0, 12e3])\n",
    "\n",
    "# #  targets and use same linear model\n",
    "# start_timeb = time.time()\n",
    "\n",
    "Y_pred_newstar_test = GHG_forecast.predict(X_new_stardf_test)\n",
    "\n",
    "# Plot results\n",
    "ax0.scatter(Y_new_stardf_test, Y_pred_newstar_test)\n",
    "#ax0.set_xlabel('True Target', size = 12)\n",
    "ax0.set_title('Linear regression between best Site Energy Use model & GHG Emissions', weight = 'bold', size = 14)\n",
    "r2_test_star = r2_score(Y_new_stardf_test, Y_pred_newstar_test)\n",
    "MAE_test_star = mean_absolute_error(Y_new_stardf_test, Y_pred_newstar_test)\n",
    "RMSE_test_star = np.sqrt(mean_squared_error(Y_new_stardf_test, Y_pred_newstar_test))\n",
    "ax0.text(1000, 10000, r'$R^2$ Test=%.2f, MAE Test=%.2f, RMSE Test=%.2f' % (r2_test, MAE_test, RMSE_test), size = 12)\n",
    "#ax0.set_xlim([0, 12e3])\n",
    "#ax0.set_ylim([0, 12e3])\n",
    "\n",
    "f.suptitle(\"GHG Emissions (MetricTonsCO2e)\", x = 0.5, y=0.005, weight = 'bold', size = 14)\n",
    "f.tight_layout(rect=[0.005, 0.005, 1, 1.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e220651",
   "metadata": {},
   "source": [
    "__RESULTS FOR GHG EMISSIONS WITH ENERGYSTARScore ADDED__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e312a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GHG Emissions\n",
    "metrics_GHG = ['R2 lin', 'R2 log', 'MAE lin', \"MAE log\", 'Running time(s) lin', 'Running time(s) log']\n",
    "GHG_data = {'RandomForest' : pd.Series([r2_test77b, r2_test_77b, MAE_test77b, MAE_test_77b, tm77b, tm_77b],\n",
    "                        index = metrics_GHG),\n",
    "            'RandomForest ENERGYSTAR' : pd.Series([r2_test12, r2_test121, MAE_test12, MAE_test121, tm12, tm121],\n",
    "                        index = metrics_GHG),\n",
    "            'XGBoost' : pd.Series([r2_test88b, r2_test_88b, MAE_test88b, MAE_test_88b, tm88b, tm_88b],\n",
    "                        index = metrics_GHG),\n",
    "            'XGBoost ENERGYSTAR' : pd.Series([r2_test13, r2_test131, MAE_test13, MAE_test131, tm13, tm131],\n",
    "                        index = metrics_GHG)}\n",
    "\n",
    "# Creates Dataframe df_GHG Stars for GHG Emissions\n",
    "\n",
    "df_GHG_stars = pd.DataFrame(GHG_data)\n",
    "index = df_GHG_stars.index\n",
    "index. name = \"Metrics\"\n",
    "df_GHG_stars.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf02a8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_stars = df_GHG_stars.T\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
    "df_stars1 = df_stars[[\"MAE lin\", \"MAE log\"]].plot( y=[\"MAE lin\", \"MAE log\"], kind=\"bar\", rot = 45)\n",
    "plt.xlabel(\"Regressions\", weight = 'bold', size = 12)\n",
    "plt.ylabel(\"Mean Absolute Error\")\n",
    "plt.title(\"Mean absolute error for the different models - GHG Emissions\", weight = 'bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SKLEARN METHOD\n",
    "\n",
    "ohe = (stars_rfr.best_estimator_.named_steps['preprocessor']\n",
    "         .named_transformers_['cat'])\n",
    "feature_names = ohe.get_feature_names(cat_data)\n",
    "feature_names = np.r_[feature_names, num_data]\n",
    "\n",
    "tree_feature_importances = (\n",
    "     stars_rfr.best_estimator_.named_steps['regressor'].feature_importances_)\n",
    "\n",
    "#important_features = np.sort(tree_feature_importances)[:10]\n",
    "#sorted_idx = important_features.argsort()\n",
    "sorted_idx = tree_feature_importances.argsort()\n",
    "\n",
    "y_ticks = np.arange(0, len(feature_names))\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "ax.barh(y_ticks, tree_feature_importances[sorted_idx])\n",
    "ax.set_yticks(y_ticks)\n",
    "ax.set_yticklabels(feature_names[sorted_idx])\n",
    "ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a605cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
