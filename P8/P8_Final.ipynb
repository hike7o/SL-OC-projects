{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06464def",
   "metadata": {},
   "source": [
    "<h1><center>P8 - CLOUD DEPLOYMENT MODEL</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc5eca3",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://res.cloudinary.com/practicaldev/image/fetch/s--keRgJsli--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880/https://dev-to-uploads.s3.amazonaws.com/uploads/articles/jifbx875as0po7ybbryo.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ea9bf",
   "metadata": {},
   "source": [
    "### OVERVIEW\n",
    "\n",
    "As a Data Scientist for \"Fruits!\", a startup from AgriTech, we are looking to propose innovative solutions for fruits harvesting.\n",
    "\n",
    "The company aims to protect fruits biodiversity by enabling specific treatments for each fruits species, made by smart picking robots.\n",
    "\n",
    "\"Fruits!\" is looking to get publicity in developing a web application that would enable users to take the picture of a fruit and get information about it.\n",
    "\n",
    "For our startup, this web app would raise public awareness to fruits biodiversity and would serve as a first version for a classification motor of fruits images.\n",
    "\n",
    "\n",
    "### DATA\n",
    "Our colleague Paul let us know about an existing dataset containing images and labels of fruits, that could be used as a starting point to build part of a data processing chain.\n",
    "\n",
    "\n",
    "### MISSION\n",
    "We are in charge to develop a first data processing chain in a Big Data environment. This chain will be composed of the preprocessing and a dimensionality reduction phase. No need to train the model for the time being.\n",
    "\n",
    "The objective is to put in place the first processing steps which will be later used for upscaling in terms of data volume.\n",
    "\n",
    "\n",
    "### CONSTRAINTS\n",
    "Few constraints are listed:\n",
    "\n",
    "Our work need to take into account the fact that our data volume is going to increase very quickly after this project. Hence we'll develop Pyspark scripts and will use Amazon Web Service to take advantage of a Big Data architecture (EC2, S3, IAM).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d60726",
   "metadata": {},
   "source": [
    "We decided to use SageMaker for this project in order to test it. Amazon SageMaker is a fully managed service that provides every developer and data scientist with the ability to build, train, and deploy machine learning (ML) models quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b6ec50",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://nub8.net/wp-content/uploads/2019/07/amazon_sagemaker-min-300x128.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e7996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries loading\n",
    "import os\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "\n",
    "# Importing AWS libraries: S3, Sagemaker, PySpark\n",
    "# S3\n",
    "import boto3\n",
    "import botocore.session\n",
    "\n",
    "# Sagemaker\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.predictor import csv_serializer\n",
    "import sagemaker_pyspark\n",
    "#from airflow import settings\n",
    "\n",
    "# Pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql.functions import input_file_name\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import monotonically_increasing_id, row_number\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "# Dimension reduction - PCA\n",
    "from pyspark.ml.feature import PCA\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "# Tensorflow\n",
    "#!pip install tensorflow\n",
    "#!pip install apache-airflow\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# Misc\n",
    "import time\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02ab594",
   "metadata": {},
   "source": [
    "SparkContext is the primary point of entry for **Spark** capabilities. A SparkContext represents a Spark clusterâ€™s connection that is useful in building RDDs, accumulators, and broadcast variables on the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaa92bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user\n"
     ]
    }
   ],
   "source": [
    "print(os.environ['HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f45db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc438411",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(\n",
    "    aws_access_key_id=access_key,\n",
    "    aws_secret_access_key=secret_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "798e1239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAXX4UHDZO2H33GH6V\n",
      "vy7K3IO8Ga+sWdfgJBCtiKL8pgvOnpmfPAJCJpvg\n"
     ]
    }
   ],
   "source": [
    "# session = botocore.session.get_session()\n",
    "credentials = session.get_credentials()\n",
    "access_key = credentials.access_key\n",
    "secret_key = credentials.secret_key\n",
    "\n",
    "print(access_key)\n",
    "print(secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3eb40eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASIAXX4UHDZO2H33GH6V\n",
      "vy7K3IO8Ga+sWdfgJBCtiKL8pgvOnpmfPAJCJpvg\n"
     ]
    }
   ],
   "source": [
    "access_key = credentials.access_key\n",
    "secret_key = credentials.secret_key\n",
    "\n",
    "print(access_key)\n",
    "print(secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd7a5062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark session initialization\n",
    "def init_spark_session(bucket=''):\n",
    "    '''Trigger SPARK session\n",
    "    Input:\n",
    "    - bucket : S3 bucket name containing images\n",
    "    \n",
    "    Output:\n",
    "    - SparkContext\n",
    "    - S3 bucket images path\n",
    "    '''\n",
    "    \n",
    "    # Remote access to our S3 bucket from SageMaker\n",
    "    path_img = \"s3a://\"+bucket_name+\"/**\"\n",
    "        \n",
    "    session = botocore.session.get_session()\n",
    "    credentials = session.get_credentials()\n",
    "\n",
    "    # TO HIDE CREDENTIALS\n",
    "    AWS_ACCESS_KEY_ID = 'AKIAXX4UHDZO2WERVDNO'\n",
    "    AWS_SECRET_ACCESS_KEY = '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'\n",
    "    \n",
    "    conf = (SparkConf()\n",
    "        .set(\"spark.driver.extraClassPath\", \":\".join(sagemaker_pyspark.classpath_jars())))\n",
    "        \n",
    "    spark = (\n",
    "        SparkSession\n",
    "        .builder\n",
    "        .config(conf=conf) \\\n",
    "        .config('fs.s3a.access.key', AWS_ACCESS_KEY_ID) \\\n",
    "        .config('fs.s3a.secret.key', AWS_SECRET_ACCESS_KEY) \\\n",
    "        .config(\"spark.driver.memory\", \"16g\")\n",
    "        .config('spark.network.timeout', '900000')\n",
    "        .config('spark.sql.execution.arrow.pyspark.enabled', 'true')\\\n",
    "        .master('local[*]') \\\n",
    "        .appName('P8_Fruits') \\\n",
    "        .getOrCreate()\n",
    "    ) \n",
    "\n",
    "    sc = spark.sparkContext\n",
    "    \n",
    "    return sc, spark, path_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01d7caac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "def load_data(path_img):\n",
    "    '''Dataframes loading: \n",
    "    Input:\n",
    "    - path_image: Directory containing images\n",
    "    \n",
    "    Output:\n",
    "    df_img: Spark dataframe with images and names\n",
    "    '''\n",
    "    # Timer\n",
    "    start = time.time()\n",
    "    \n",
    "    # SPARK dataframe loading\n",
    "    df_img = spark.read.format(\"image\").load(path_img, inferschema=True)\n",
    "    print('Images loaded - DONE')\n",
    "    \n",
    "    df_img = df_img.withColumn(\"fileName\", regexp_replace('image.origin', 'dbfs:/mnt/images/', '')) \n",
    "    split_col =split(df_img['fileName'], '/')\n",
    "    df_img = df_img.withColumn('Category', split_col.getItem(3))\n",
    "    \n",
    "    df_img_see = df_img.select('image', 'image.origin',\"image.height\",\"image.width\",\"image.nChannels\", \"image.mode\", \"image.data\",'Category')\n",
    "    df_img_feat = df_img.select('image.origin',\"image.height\",\"image.width\",\"image.nChannels\", \"image.mode\", \"image.data\",'Category')\n",
    "    \n",
    "    print('Images loaded in: {} secondes'.format(time.strftime('%S', time.gmtime(time.time()-start))))\n",
    "    \n",
    "    return df_img_see, df_img_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15debd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images\n",
    "def display_image(dfs, Category):\n",
    "    '''Display a selected image\n",
    "    Input:\n",
    "    - SPARK dataframe\n",
    "    - Image category\n",
    "      \n",
    "    Output:\n",
    "    - Image array\n",
    "      \n",
    "    '''\n",
    "    filter_cat = dfs.filter(dfs.Category == Category)\n",
    "    list_height = filter_cat.select('height').collect()\n",
    "    list_width = filter_cat.select('width').collect()\n",
    "    height = list_height[0].height\n",
    "    width = list_width[0].width\n",
    "\n",
    "    image_1 = filter_cat.first()\n",
    "\n",
    "    disp_img = np.array(image_1.asDict()['image']['data']).reshape(height,width,3)[:,:,::-1]\n",
    "    \n",
    "    return disp_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df281e79",
   "metadata": {},
   "source": [
    "### Transfer Learning for features extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9503b7c",
   "metadata": {},
   "source": [
    "VGG16 is a convolution neural net (CNN ) architecture which was used to win ILSVR(Imagenet) competition in 2014. It is considered to be one of the excellent vision model architecture till date. Most unique thing about VGG16 is that instead of having a large number of hyper-parameter they focused on having convolution layers of 3x3 filter with a stride 1 and always used same padding and maxpool layer of 2x2 filter of stride 2. It follows this arrangement of convolution and max pool layers consistently throughout the whole architecture. In the end it has 2 FC(fully connected layers) followed by a softmax for output. The 16 in VGG16 refers to it has 16 layers that have weights. This network is a pretty large network and it has about 138 million (approx) parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af289d",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://miro.medium.com/max/940/1*3-TqqkRQ4rWLOMX-gvkYwA.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c1f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features extraction with VGG16\n",
    "def extract_features_vgg16(bucket_name):\n",
    "    \n",
    "    '''Features extraction with VGG16\n",
    "    Input: S3 bucket name\n",
    "    \n",
    "    Output: Images features\n",
    "    \n",
    "    '''\n",
    "    # Timer\n",
    "    start = time.time()\n",
    "    \n",
    "    model = VGG16(include_top=False, weights='imagenet', pooling='max', input_shape=(224, 224, 3))\n",
    "    model.summary()\n",
    "    \n",
    "    # AWS S3 ressources \n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3 = boto3.resource('s3')\n",
    "    bucket = s3.Bucket(bucket_name)\n",
    "    \n",
    "    vgg16_features=[]\n",
    "    \n",
    "    for my_bucket_object in bucket.objects.all():\n",
    "        if my_bucket_object.key.endswith('jpg'):\n",
    "            file_byte_string = s3_client.get_object(Bucket=bucket_name, Key=my_bucket_object.key)['Body'].read()\n",
    "            \n",
    "            # Image loading\n",
    "            img = Image.open(BytesIO(file_byte_string))\n",
    "            \n",
    "            # Image redimensionning in 224*224 px\n",
    "            img_redim = img.resize((224, 224))\n",
    "            \n",
    "            # Image to array\n",
    "            img_array = image.img_to_array(img_redim).reshape((-1,224,224,3))\n",
    "            img_array = np.array(img_array)\n",
    "            \n",
    "            # Images pre-processing \n",
    "            img_array = preprocess_input(img_array)\n",
    "            \n",
    "            # Features extraction for an image\n",
    "            feature = model.predict(img_array).ravel().tolist()\n",
    "            \n",
    "            vgg16_features.append(feature)\n",
    "            \n",
    "    print('Features extraction loading time: {} secondes'.format(time.strftime('%S', time.gmtime(time.time()-start))))\n",
    "    \n",
    "    return vgg16_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a2ace78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features in SPARK dataframe \n",
    "def features_pyspark_df(features, df_img):\n",
    "    \n",
    "    '''Add features to Pyspark dataframe \n",
    "    Input:\n",
    "    - Image features \n",
    "    \n",
    "    Output:\n",
    "    - pyspark dataframe with info about images and features\n",
    "    '''\n",
    "    features_df = spark.createDataFrame([(l,) for l in features], ['features'])\n",
    "    \n",
    "    df_img = df_img.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "    features_df = features_df.withColumn(\"row_idx\", row_number().over(Window.orderBy(monotonically_increasing_id())))\n",
    "\n",
    "    df_img_feat = df_img.join(features_df, df_img.row_idx == features_df.row_idx).drop(\"row_idx\")\n",
    "    \n",
    "    return df_img_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d37ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_pca(dataframe):\n",
    "    \n",
    "    '''\n",
    "     Data preparation:\n",
    "     - Dense vector conversion\n",
    "     - Standardization\n",
    "     Input : dataframe : Images dataframe\n",
    "     Output : dataframe with standardized dense vectors\n",
    "    '''\n",
    "\n",
    "    # Images data to dense vector conversion\n",
    "    transform_dense_vector = udf(lambda r: Vectors.dense(r), VectorUDT())\n",
    "    dataframe = dataframe.select('origin', 'Category','features', transform_dense_vector(\"features\").alias(\"features_vectors\"))\n",
    "    \n",
    "    # Standardization for PCA\n",
    "    scaler_std = StandardScaler(inputCol=\"features_vectors\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n",
    "    \n",
    "    model_std = scaler_std.fit(dataframe)\n",
    "    # Upscaling\n",
    "    dataframe = model_std.transform(dataframe)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1b06f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimal_k_search(dataframe, nb_comp=48):\n",
    "    '''\n",
    "       Search for the optimal k number (90% variance)\n",
    "       param : dataframe : Images dataframe\n",
    "       return : k Number of components explaining 90% of the variance\n",
    "    '''\n",
    "\n",
    "    pca = PCA(k = nb_comp,\n",
    "              inputCol=\"features_scaled\", \n",
    "              outputCol=\"features_pca\")\n",
    "\n",
    "    model_pca = pca.fit(dataframe)\n",
    "    variance = model_pca.explainedVariance\n",
    "\n",
    "    # visuel\n",
    "    plt.plot(np.arange(len(variance)) + 1, variance.cumsum(), c=\"red\", marker='o')\n",
    "    plt.xlabel(\"Nb components\")\n",
    "    plt.ylabel(\"% variance\")\n",
    "    plt.show(block=False)\n",
    "\n",
    "    def nb_comp ():\n",
    "        for i in range(48):\n",
    "          a = variance.cumsum()[i]\n",
    "          if a >= 0.90:\n",
    "              print(\"{} principal components explain 90% of the information\".format(i))\n",
    "              break\n",
    "        return i\n",
    "\n",
    "    k=nb_comp()\n",
    "\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6adcb2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results in csv file on a S3 bucket\n",
    "def save_csv_bucket_s3(pca_matrix, file_name, bucket_name):\n",
    "    \n",
    "    '''Saving results in a csv file in a S3 bucket\n",
    "    Input:\n",
    "    - pca_matrix (psypark dataframe)\n",
    "    - csv file name to save\n",
    "    - bucket_name: S3 bucket name\n",
    "    '''\n",
    "    s3_resource = boto3.resource('s3')\n",
    "    \n",
    "    # Buffer creation\n",
    "    csv_buffer = StringIO()\n",
    "    \n",
    "    # psypark to pandas dataframe conversion\n",
    "    pca_matrix.toPandas().to_csv(csv_buffer)\n",
    "    \n",
    "    # Resulting csv file in S3 bucket\n",
    "    s3_resource.Object(bucket_name, file_name).put(Body=csv_buffer.getvalue())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "886c4674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucket name from AWS S3\n",
    "bucket_name = 'fulldatafruits-bucket'\n",
    "#bucket_name = 'h7obucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2c2442b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Spark session initialization\n",
    "sc, spark, path = init_spark_session(bucket=bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e36c6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-16-55-193.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>P8_Fruits</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=P8_Fruits>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a006606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded - DONE\n",
      "Images loaded in: 05 secondes\n"
     ]
    }
   ],
   "source": [
    "# Dataframe loading\n",
    "images_feat, images_see = load_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6173d8fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|              origin|       Category|\n",
      "+--------------------+---------------+\n",
      "|s3a://fulldatafru...|cabbage_white_1|\n",
      "|s3a://fulldatafru...|cabbage_white_1|\n",
      "|s3a://fulldatafru...|cabbage_white_1|\n",
      "|s3a://fulldatafru...|cabbage_white_1|\n",
      "|s3a://fulldatafru...|cabbage_white_1|\n",
      "+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display first 5 images\n",
    "images_feat['origin', 'Category'].show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98ff8ff",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd38aefa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Features extraction loading time: 18 secondes\n"
     ]
    }
   ],
   "source": [
    "# Features Extraction \n",
    "image_features = extract_features_vgg16(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da097a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+-----+---------+----+--------------------+---------------+--------------------+\n",
      "|               image|              origin|height|width|nChannels|mode|                data|       Category|            features|\n",
      "+--------------------+--------------------+------+-----+---------+----+--------------------+---------------+--------------------+\n",
      "|[s3a://fulldatafr...|s3a://fulldatafru...|   733|  732|        3|  16|[FF FF FF FF FF F...|cabbage_white_1|[91.1162796020507...|\n",
      "|[s3a://fulldatafr...|s3a://fulldatafru...|   728|  763|        3|  16|[FF FF FF FF FF F...|cabbage_white_1|[79.0967254638671...|\n",
      "|[s3a://fulldatafr...|s3a://fulldatafru...|   731|  743|        3|  16|[FF FF FF FF FF F...|cabbage_white_1|[73.1242065429687...|\n",
      "|[s3a://fulldatafr...|s3a://fulldatafru...|   732|  733|        3|  16|[FF FF FF FF FF F...|cabbage_white_1|[90.2788238525390...|\n",
      "|[s3a://fulldatafr...|s3a://fulldatafru...|   728|  766|        3|  16|[FF FF FF FF FF F...|cabbage_white_1|[83.6150741577148...|\n",
      "+--------------------+--------------------+------+-----+---------+----+--------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adding features to pyspark dataframe\n",
    "images_feat_df = features_pyspark_df(image_features, images_feat)\n",
    "images_feat_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca775871",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = preprocess_pca(images_feat_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce633c",
   "metadata": {},
   "source": [
    "Scree plot looking for the principal components that can explain 90% of variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a049a715",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 principal components explain 90% of the information\n"
     ]
    }
   ],
   "source": [
    "# Number of components explaining 90% of the variance\n",
    "n_components = optimal_k_search(pca_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ae155",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4994df17",
   "metadata": {},
   "source": [
    "We then apply dimensionality reduction with our output pca vectors as a result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eb8f2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA implementation with optimal k components\n",
    "pca = PCA(k=n_components, inputCol='features_scaled', outputCol='vectors_pca')\n",
    "model_pca = pca.fit(pca_df)\n",
    "\n",
    "# Transform images \n",
    "df_post_pca = model_pca.transform(pca_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb7642ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|              origin|       Category|            features|    features_vectors|     features_scaled|         vectors_pca|\n",
      "+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|s3a://fulldatafru...|cabbage_white_1|[91.1162796020507...|[91.1162796020507...|[1.46803653653970...|[3.18426635752081...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[79.0967254638671...|[79.0967254638671...|[0.86671687170586...|[4.13922381773607...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[73.1242065429687...|[73.1242065429687...|[0.56792100669792...|[3.94153849795189...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[90.2788238525390...|[90.2788238525390...|[1.42613992333590...|[3.34396060392760...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[83.6150741577148...|[83.6150741577148...|[1.09276285402359...|[4.07033310194057...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[79.4616165161132...|[79.4616165161132...|[0.88497180551746...|[3.46797795126154...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[99.3009796142578...|[99.3009796142578...|[1.87750439296133...|[3.01470829129451...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[83.8331069946289...|[83.8331069946289...|[1.10367069893270...|[4.34458898364592...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[85.1289978027343...|[85.1289978027343...|[1.16850210760499...|[4.30062003709017...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[83.3213806152343...|[83.3213806152343...|[1.07806982127896...|[3.77125202439339...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[70.8579711914062...|[70.8579711914062...|[0.45454476442059...|[3.61644113523703...|\n",
      "|s3a://fulldatafru...|cabbage_white_1|[75.3835525512695...|[75.3835525512695...|[0.68095258580942...|[4.48372572573342...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[86.3655471801757...|[86.3655471801757...|[1.23036475647242...|[-10.418108528435...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[39.1763496398925...|[39.1763496398925...|[-1.1304376595304...|[-12.906291600804...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[55.1709213256835...|[55.1709213256835...|[-0.3302540275347...|[-12.462722480608...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[76.1671447753906...|[76.1671447753906...|[0.72015449031917...|[-11.856195753984...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[88.2614440917968...|[88.2614440917968...|[1.32521354057447...|[-11.750765084979...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[78.3402481079101...|[78.3402481079101...|[0.82887148202594...|[-12.068542350744...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[79.2495193481445...|[79.2495193481445...|[0.87436091292620...|[-11.899070714999...|\n",
      "|s3a://fulldatafru...|     cucumber_1|[63.3233146667480...|[63.3233146667480...|[0.07759757620066...|[-11.221690160367...|\n",
      "+--------------------+---------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_post_pca.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65777093",
   "metadata": {},
   "source": [
    "### Saving results in S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8bfed6",
   "metadata": {},
   "source": [
    "New bucket creation on S3 - \"results-fruits-bucket\" <br>\n",
    "Spark dataframe to pandas dataframe conversion<br>\n",
    "Saving results in csv format<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "333c7d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving results file in new bucket\n",
    "bucket_name_matrix = 'results-fruits-bucket'\n",
    "save_csv_bucket_s3(df_post_pca, 'pca_results.csv', bucket_name_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87ecc8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping Spark session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
