{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbfccb5",
   "metadata": {
    "id": "8dbfccb5"
   },
   "source": [
    "<h1><center>P7 - CREATE & IMPLEMENT A CREDIT SCORING MODEL</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfaf5ed",
   "metadata": {},
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://a57.foxnews.com/static.foxbusiness.com/foxbusiness.com/content/uploads/2020/01/931/506/Credible-credit-card-iStock-1051216104.jpg?ve=1&tl=1\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fb92c",
   "metadata": {
    "id": "531fb92c"
   },
   "source": [
    "### OVERVIEW\n",
    "\n",
    "As a Data Scientist within the financial institution \"Prêt à dépenser\" which give loans to people with insufficient or non-existent credit history.\n",
    "\n",
    "Logo entreprise \n",
    "\n",
    "The company wishes to implement a credit scoring model in order to make good decisions.\n",
    "Two types of risks are associated with the bank’s decision:\n",
    "\n",
    "a. If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n",
    "\n",
    "b. If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company.\n",
    "\n",
    "In addition, customers service are pushed more and more by clients to explain their decision to grant a loan and it's in this mindset that \"Prêt à dépenser\" wants to move forward.\n",
    "\n",
    "\"Prêt à dépenser\" has then decided to develop an interactive dashboard so that not only their customers service team can explain - in the most transparent way - their decisions to give or not the loans to their clients but also to give full access to their own information. \n",
    "\n",
    "### DATA\n",
    "\n",
    "The dataset provided contains a vast number of details about the borrower. It is separated into several relational tables, which contain applicants’ static data such as their gender, age, number of family members, occupation, and other necessary fields, applicant’s previous credit history obtained from the credit bureau department, and the applicant’s past credit history.<br>\n",
    "Data can be found here:<br> https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Impl%C3%A9menter+un+mod%C3%A8le+de+scoring/Projet+Mise+en+prod+-+home-credit-default-risk.zip\n",
    "\n",
    "\n",
    "### OBJECTIVE\n",
    "\n",
    "* Create & implement a credit scoring model which will return automatically a probability for a client to default his loan.\n",
    "* Create an interactive dashboard to later provide to the customers service management team so that they can interpret the model's predictions. It will provide them valuable information in order to improve their knowledge of the clients and to train their staff.\n",
    "\n",
    "In order to mainly focus on the creation, implementation and optimization of our model, Michaël, our manager, encouraged us to carefully choose an existing Kaggle kernel to ease the pre-processing work on this dataset.<br>\n",
    "We decided to opt for the kernel of student Rishabh Rao who did an exhaustive data pre-processing work.\n",
    "\n",
    "https://www.kaggle.com/rishabhrao/home-credit-default-risk-extensive-eda \n",
    "\n",
    "###  Dashboard constraints\n",
    "\n",
    "Michaël provided us specifications for the interactive dashboard. It will at least need to contain the followings features:\n",
    "\n",
    "* Easy viewing of the score and its interpretation for each client (especially for non scientific people).\n",
    "* Easy viewing of the descriptive information of the clients (via a filter system).\n",
    "* Allow the user to compare descriptive informations of one client to the others or to a group of similar clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6c0de",
   "metadata": {},
   "source": [
    "## PART 2 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea7d88",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Dataset Overview](#chapter1)\n",
    "* [2. Input files processing](#chapter2)\n",
    "    * [2.1 application_train/test](#section_2_1)\n",
    "    * [2.2 bureau and bureau balance.csv](#section_2_2)\n",
    "    * [2.3 previous_application.csv](#section_2_3)\n",
    "    * [2.4 installments_payments.csv](#section_2_4)\n",
    "    * [2.5 POS_CASH_balance.csv](#section_2_5)\n",
    "    * [2.6 credit_card_balance.csv](#section_2_6)\n",
    "    * [2.7 Configuration](#section_2_7)\n",
    "* [3. Imputation for Machine Learning algorithms](#chapter3)\n",
    "* [4. BorutaPy feature selection](#chapter4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c062cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1642861496666,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "c6c062cc",
    "outputId": "136f21da-f87b-47fe-e3fe-0ec8bdf54aee"
   },
   "outputs": [],
   "source": [
    "# ! usr/bin/env python 3\n",
    "# coding: utf-8\n",
    "\n",
    "# Most features are created by applying min, max, mean, sum and var functions to grouped tables. \n",
    "# Little feature selection is done and overfitting might be a problem since many features are related.\n",
    "# The following key ideas were used:\n",
    "# - Divide or subtract important features to get rates (like annuity and income)\n",
    "# - In Bureau Data: create specific features for Active credits and Closed credits\n",
    "# - In Previous Applications: create specific features for Approved and Refused applications\n",
    "# - Modularity: one function for each table (except bureau_balance and application_test)\n",
    "# - One-hot encoding for categorical features\n",
    "# All tables are joined with the application DF using the SK_ID_CURR key (except bureau_balance).\n",
    "# You can use LightGBM with KFold or Stratified KFold.\n",
    "\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from contextlib import contextmanager\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "from scipy.stats import kurtosis, iqr, skew\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# from LightGBM7_feateng import*\n",
    "\n",
    "# Features selection\n",
    "from boruta import BorutaPy\n",
    "from BorutaShap import BorutaShap\n",
    "from collections import Counter\n",
    "import warnings\n",
    "\n",
    "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac12d9",
   "metadata": {},
   "source": [
    "All functions run in this notebook can be found at: functions_P7_feat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b3250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rlufWBGQbS0G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 3234210,
     "status": "ok",
     "timestamp": 1642861355543,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "rlufWBGQbS0G",
    "outputId": "21bb68df-cd61-4c7f-b1e2-55f59af4bb60"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f593abaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39335,
     "status": "ok",
     "timestamp": 1642862231385,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "f593abaa",
    "outputId": "66aed406-461e-42af-a7cb-460ea286d26e"
   },
   "outputs": [],
   "source": [
    "# Transforming our csv files into dataframe\n",
    "# %%time\n",
    "homecredit = pd.read_csv('HomeCredit_columns_description.csv', index_col=[0])\n",
    "cash_balance = pd.read_csv('POS_CASH_balance.csv')\n",
    "app_test = pd.read_csv('application_test.csv')\n",
    "app_train = pd.read_csv('application_train.csv')\n",
    "bureau = pd.read_csv('bureau.csv')\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "cc_balance = pd.read_csv('credit_card_balance.csv')\n",
    "inst_payments = pd.read_csv('installments_payments.csv')\n",
    "previous_app = pd.read_csv('previous_application.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bdfc3",
   "metadata": {
    "id": "0a1bdfc3"
   },
   "source": [
    "## 1. Dataset Overview<a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e5613",
   "metadata": {
    "id": "395e5613"
   },
   "source": [
    "<h2><center>Relationship between all tables</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07409bf",
   "metadata": {
    "id": "b07409bf"
   },
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://miro.medium.com/max/875/0*IMyhw8RGEoDhC7t1.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb1467",
   "metadata": {},
   "source": [
    "## 2. Input files processing<a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e096af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- UTILITY FUNCTIONS -------------------------\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(name, time.time() - t0))\n",
    "\n",
    "\n",
    "def group(df_to_agg, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = df_to_agg.groupby(aggregate_by).agg(aggregations)\n",
    "    agg_df.columns = pd.Index(['{}{}_{}'.format(prefix, e[0], e[1].upper())\n",
    "                               for e in agg_df.columns.tolist()])\n",
    "    return agg_df.reset_index()\n",
    "\n",
    "\n",
    "def group_and_merge(df_to_agg, df_to_merge, prefix, aggregations, aggregate_by= 'SK_ID_CURR'):\n",
    "    agg_df = group(df_to_agg, prefix, aggregations, aggregate_by= aggregate_by)\n",
    "    return df_to_merge.merge(agg_df, how='left', on= aggregate_by)\n",
    "\n",
    "\n",
    "def do_mean(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].mean().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_median(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].median().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_std(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].std().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def do_sum(df, group_cols, counted, agg_name):\n",
    "    gp = df[group_cols + [counted]].groupby(group_cols)[counted].sum().reset_index().rename(\n",
    "        columns={counted: agg_name})\n",
    "    df = df.merge(gp, on=group_cols, how='left')\n",
    "    del gp\n",
    "    gc.collect()\n",
    "    return df\n",
    "\n",
    "\n",
    "def one_hot_encoder(df, categorical_columns=None, nan_as_category=True):\n",
    "    \"\"\"Create a new column for each categorical value in categorical columns. \"\"\"\n",
    "    original_columns = list(df.columns)\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns=categorical_columns, dummy_na=nan_as_category)\n",
    "    categorical_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, categorical_columns\n",
    "\n",
    "\n",
    "def label_encoder(df, categorical_columns=None):\n",
    "    \"\"\"Encode categorical values as integers (0,1,2,3...) with pandas.factorize. \"\"\"\n",
    "    if not categorical_columns:\n",
    "        categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    for col in categorical_columns:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "    return df, categorical_columns\n",
    "\n",
    "\n",
    "def add_features(feature_name, aggs, features, feature_names, groupby):\n",
    "    feature_names.extend(['{}_{}'.format(feature_name, agg) for agg in aggs])\n",
    "\n",
    "    for agg in aggs:\n",
    "        if agg == 'kurt':\n",
    "            agg_func = kurtosis\n",
    "        elif agg == 'iqr':\n",
    "            agg_func = iqr\n",
    "        else:\n",
    "            agg_func = agg\n",
    "\n",
    "        g = groupby[feature_name].agg(agg_func).reset_index().rename(index=str,\n",
    "                                                                     columns={feature_name: '{}_{}'.format(feature_name,agg)})\n",
    "        features = features.merge(g, on='SK_ID_CURR', how='left')\n",
    "    return features, feature_names\n",
    "\n",
    "\n",
    "def add_features_in_group(features, gr_, feature_name, aggs, prefix):\n",
    "    for agg in aggs:\n",
    "        if agg == 'sum':\n",
    "            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n",
    "        elif agg == 'mean':\n",
    "            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n",
    "        elif agg == 'max':\n",
    "            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n",
    "        elif agg == 'min':\n",
    "            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n",
    "        elif agg == 'std':\n",
    "            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n",
    "        elif agg == 'count':\n",
    "            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n",
    "        elif agg == 'skew':\n",
    "            features['{}{}_skew'.format(prefix, feature_name)] = skew(gr_[feature_name])\n",
    "        elif agg == 'kurt':\n",
    "            features['{}{}_kurt'.format(prefix, feature_name)] = kurtosis(gr_[feature_name])\n",
    "        elif agg == 'iqr':\n",
    "            features['{}{}_iqr'.format(prefix, feature_name)] = iqr(gr_[feature_name])\n",
    "        elif agg == 'median':\n",
    "            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n",
    "    return features\n",
    "\n",
    "\n",
    "def add_trend_feature(features, gr, feature_name, prefix):\n",
    "    y = gr[feature_name].values\n",
    "    try:\n",
    "        x = np.arange(0, len(y)).reshape(-1, 1)\n",
    "        lr = LinearRegression()\n",
    "        lr.fit(x, y)\n",
    "        trend = lr.coef_[0]\n",
    "    except:\n",
    "        trend = np.nan\n",
    "    features['{}{}'.format(prefix, feature_name)] = trend\n",
    "    return features\n",
    "\n",
    "\n",
    "def parallel_apply(groups, func, index_name='Index', num_workers=0, chunk_size=100000):\n",
    "    if num_workers <= 0: num_workers = NUM_THREADS\n",
    "    #n_chunks = np.ceil(1.0 * groups.ngroups / chunk_size)\n",
    "    indeces, features = [], []\n",
    "    for index_chunk, groups_chunk in chunk_groups(groups, chunk_size):\n",
    "        with mp.pool.Pool(num_workers) as executor:\n",
    "            features_chunk = executor.map(func, groups_chunk)\n",
    "        features.extend(features_chunk)\n",
    "        indeces.extend(index_chunk)\n",
    "\n",
    "    features = pd.DataFrame(features)\n",
    "    features.index = indeces\n",
    "    features.index.name = index_name\n",
    "    return features\n",
    "\n",
    "\n",
    "def chunk_groups(groupby_object, chunk_size):\n",
    "    n_groups = groupby_object.ngroups\n",
    "    group_chunk, index_chunk = [], []\n",
    "    for i, (index, df) in enumerate(groupby_object):\n",
    "        group_chunk.append(df)\n",
    "        index_chunk.append(index)\n",
    "        if (i + 1) % chunk_size == 0 or i + 1 == n_groups:\n",
    "            group_chunk_, index_chunk_ = group_chunk.copy(), index_chunk.copy()\n",
    "            group_chunk, index_chunk = [], []\n",
    "            yield index_chunk_, group_chunk_\n",
    "\n",
    "\n",
    "def reduce_memory(df):\n",
    "    \"\"\"Reduce memory usage of a dataframe by setting data types. \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Initial df memory usage is {:.2f} MB for {} columns'\n",
    "          .format(start_mem, len(df.columns)))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # Can use unsigned int here too\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3788fe6e",
   "metadata": {},
   "source": [
    "#### 2.1 application_{train/test}<a class=\"anchor\" id=\"section_2_1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3158cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Application train/test\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def get_train_test(path, num_rows = None):\n",
    "    \"\"\" Process application_train.csv and application_test.csv and return a pandas dataframe. \"\"\"\n",
    "    train = pd.read_csv(os.path.join(path, 'application_train.csv'), nrows= num_rows)\n",
    "    test = pd.read_csv(os.path.join(path, 'application_test.csv'), nrows= num_rows)\n",
    "    df = train.append(test)\n",
    "    del train, test; gc.collect()\n",
    "    # Data cleaning\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']  # 4 people with XNA code gender\n",
    "    df = df[df['AMT_INCOME_TOTAL'] < 20000000]  # Max income in test is 4M; train has a 117M value\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace=True)\n",
    "    df['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    # Flag_document features - count and kurtosis\n",
    "    docs = [f for f in df.columns if 'FLAG_DOC' in f]\n",
    "    df['DOCUMENT_COUNT'] = df[docs].sum(axis=1)\n",
    "    df['NEW_DOC_KURT'] = df[docs].kurtosis(axis=1)\n",
    "    # Categorical age - based on target=1 plot\n",
    "    df['AGE_RANGE'] = df['DAYS_BIRTH'].apply(lambda x: get_age_label(x))\n",
    "\n",
    "    # New features based on External sources\n",
    "    df['EXT_SOURCES_PROD'] = df['EXT_SOURCE_1'] * df['EXT_SOURCE_2'] * df['EXT_SOURCE_3']\n",
    "    df['EXT_SOURCES_WEIGHTED'] = df.EXT_SOURCE_1 * 2 + df.EXT_SOURCE_2 * 1 + df.EXT_SOURCE_3 * 3\n",
    "    np.warnings.filterwarnings('ignore', r'All-NaN (slice|axis) encountered')\n",
    "    for function_name in ['min', 'max', 'mean', 'nanmedian', 'var']:\n",
    "        feature_name = 'EXT_SOURCES_{}'.format(function_name.upper())\n",
    "        df[feature_name] = eval('np.{}'.format(function_name))(\n",
    "            df[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']], axis=1)\n",
    "\n",
    "    # Credit ratios\n",
    "    df['CREDIT_TO_ANNUITY_RATIO'] = df['AMT_CREDIT'] / df['AMT_ANNUITY']\n",
    "    df['CREDIT_TO_GOODS_RATIO'] = df['AMT_CREDIT'] / df['AMT_GOODS_PRICE']\n",
    "    # Income ratios\n",
    "    df['ANNUITY_TO_INCOME_RATIO'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['CREDIT_TO_INCOME_RATIO'] = df['AMT_CREDIT'] / df['AMT_INCOME_TOTAL']\n",
    "    df['INCOME_TO_EMPLOYED_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_EMPLOYED']\n",
    "    df['INCOME_TO_BIRTH_RATIO'] = df['AMT_INCOME_TOTAL'] / df['DAYS_BIRTH']\n",
    "    # Time ratios\n",
    "    df['EMPLOYED_TO_BIRTH_RATIO'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['ID_TO_BIRTH_RATIO'] = df['DAYS_ID_PUBLISH'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_BIRTH_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_BIRTH']\n",
    "    df['CAR_TO_EMPLOYED_RATIO'] = df['OWN_CAR_AGE'] / df['DAYS_EMPLOYED']\n",
    "    df['PHONE_TO_BIRTH_RATIO'] = df['DAYS_LAST_PHONE_CHANGE'] / df['DAYS_BIRTH']\n",
    "\n",
    "    # Groupby: Statistics for applications in the same group\n",
    "    group = ['ORGANIZATION_TYPE', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'AGE_RANGE', 'CODE_GENDER']\n",
    "    df = do_median(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_MEDIAN')\n",
    "    df = do_std(df, group, 'EXT_SOURCES_MEAN', 'GROUP_EXT_SOURCES_STD')\n",
    "    df = do_mean(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_MEAN')\n",
    "    df = do_std(df, group, 'AMT_INCOME_TOTAL', 'GROUP_INCOME_STD')\n",
    "    df = do_mean(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_MEAN')\n",
    "    df = do_std(df, group, 'CREDIT_TO_ANNUITY_RATIO', 'GROUP_CREDIT_TO_ANNUITY_STD')\n",
    "    df = do_mean(df, group, 'AMT_CREDIT', 'GROUP_CREDIT_MEAN')\n",
    "    df = do_mean(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_MEAN')\n",
    "    df = do_std(df, group, 'AMT_ANNUITY', 'GROUP_ANNUITY_STD')\n",
    "\n",
    "    # Encode categorical features (LabelEncoder)\n",
    "    df, le_encoded_cols = label_encoder(df, None)\n",
    "    df = drop_application_columns(df)\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eda367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_application_columns(df):\n",
    "    \"\"\" Drop features based on permutation feature importance. \"\"\"\n",
    "    drop_list = [\n",
    "        'CNT_CHILDREN', 'CNT_FAM_MEMBERS', 'HOUR_APPR_PROCESS_START',\n",
    "        'FLAG_EMP_PHONE', 'FLAG_MOBIL', 'FLAG_CONT_MOBILE', 'FLAG_EMAIL', 'FLAG_PHONE',\n",
    "        'FLAG_OWN_REALTY', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION',\n",
    "        'REG_CITY_NOT_WORK_CITY', 'OBS_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
    "        'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_YEAR', \n",
    "        'COMMONAREA_MODE', 'NONLIVINGAREA_MODE', 'ELEVATORS_MODE', 'NONLIVINGAREA_AVG',\n",
    "        'FLOORSMIN_MEDI', 'LANDAREA_MODE', 'NONLIVINGAREA_MEDI', 'LIVINGAPARTMENTS_MODE',\n",
    "        'FLOORSMIN_AVG', 'LANDAREA_AVG', 'FLOORSMIN_MODE', 'LANDAREA_MEDI',\n",
    "        'COMMONAREA_MEDI', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'BASEMENTAREA_AVG',\n",
    "        'BASEMENTAREA_MODE', 'NONLIVINGAPARTMENTS_MEDI', 'BASEMENTAREA_MEDI', \n",
    "        'LIVINGAPARTMENTS_AVG', 'ELEVATORS_AVG', 'YEARS_BUILD_MEDI', 'ENTRANCES_MODE',\n",
    "        'NONLIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'LIVINGAPARTMENTS_MEDI',\n",
    "        'YEARS_BUILD_MODE', 'YEARS_BEGINEXPLUATATION_AVG', 'ELEVATORS_MEDI', 'LIVINGAREA_MEDI',\n",
    "        'YEARS_BEGINEXPLUATATION_MODE', 'NONLIVINGAPARTMENTS_AVG', 'HOUSETYPE_MODE',\n",
    "        'FONDKAPREMONT_MODE', 'EMERGENCYSTATE_MODE'\n",
    "    ]\n",
    "    # Drop most flag document columns\n",
    "    for doc_num in [2,4,5,6,7,9,10,11,12,13,14,15,16,17,19,20,21]:\n",
    "        drop_list.append('FLAG_DOCUMENT_{}'.format(doc_num))\n",
    "    df.drop(drop_list, axis=1, inplace=True)\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a864e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_label(days_birth):\n",
    "    \"\"\" Return the age group label (int). \"\"\"\n",
    "    age_years = -days_birth / 365\n",
    "    if age_years < 27: return 1\n",
    "    elif age_years < 40: return 2\n",
    "    elif age_years < 50: return 3\n",
    "    elif age_years < 65: return 4\n",
    "    elif age_years < 99: return 5\n",
    "    else: return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3839fa",
   "metadata": {},
   "source": [
    "#### 2.2 bureau & bureau_balance<a class=\"anchor\" id=\"section_2_2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb2df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Bureau\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def get_bureau(path, num_rows= None):\n",
    "    \"\"\" Process bureau.csv and bureau_balance.csv and return a pandas dataframe. \"\"\"\n",
    "    bureau = pd.read_csv(os.path.join(path, 'bureau.csv'), nrows= num_rows)\n",
    "    # Credit duration and credit/account end date difference\n",
    "    bureau['CREDIT_DURATION'] = -bureau['DAYS_CREDIT'] + bureau['DAYS_CREDIT_ENDDATE']\n",
    "    bureau['ENDDATE_DIF'] = bureau['DAYS_CREDIT_ENDDATE'] - bureau['DAYS_ENDDATE_FACT']\n",
    "    # Credit to debt ratio and difference\n",
    "    bureau['DEBT_PERCENTAGE'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['DEBT_CREDIT_DIFF'] = bureau['AMT_CREDIT_SUM'] - bureau['AMT_CREDIT_SUM_DEBT']\n",
    "    bureau['CREDIT_TO_ANNUITY_RATIO'] = bureau['AMT_CREDIT_SUM'] / bureau['AMT_ANNUITY']\n",
    "\n",
    "    # One-hot encoder\n",
    "    bureau, categorical_cols = one_hot_encoder(bureau, nan_as_category= False)\n",
    "    # Join bureau balance features\n",
    "    bureau = bureau.merge(get_bureau_balance(path, num_rows), how='left', on='SK_ID_BUREAU')\n",
    "    # Flag months with late payments (days past due)\n",
    "    bureau['STATUS_12345'] = 0\n",
    "    for i in range(1,6):\n",
    "        bureau['STATUS_12345'] += bureau['STATUS_{}'.format(i)]\n",
    "\n",
    "    # Aggregate by number of months in balance and merge with bureau (loan length agg)\n",
    "    features = ['AMT_CREDIT_MAX_OVERDUE', 'AMT_CREDIT_SUM_OVERDUE', 'AMT_CREDIT_SUM',\n",
    "        'AMT_CREDIT_SUM_DEBT', 'DEBT_PERCENTAGE', 'DEBT_CREDIT_DIFF', 'STATUS_0', 'STATUS_12345']\n",
    "    agg_length = bureau.groupby('MONTHS_BALANCE_SIZE')[features].mean().reset_index()\n",
    "    agg_length.rename({feat: 'LL_' + feat for feat in features}, axis=1, inplace=True)\n",
    "    bureau = bureau.merge(agg_length, how='left', on='MONTHS_BALANCE_SIZE')\n",
    "    del agg_length; gc.collect()\n",
    "\n",
    "    # General loans aggregations\n",
    "    agg_bureau = group(bureau, 'BUREAU_', BUREAU_AGG)\n",
    "    # Active and closed loans aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    agg_bureau = group_and_merge(active,agg_bureau,'BUREAU_ACTIVE_',BUREAU_ACTIVE_AGG)\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    agg_bureau = group_and_merge(closed,agg_bureau,'BUREAU_CLOSED_',BUREAU_CLOSED_AGG)\n",
    "    del active, closed; gc.collect()\n",
    "    # Aggregations for the main loan types\n",
    "    for credit_type in ['Consumer credit', 'Credit card', 'Mortgage', 'Car loan', 'Microloan']:\n",
    "        type_df = bureau[bureau['CREDIT_TYPE_' + credit_type] == 1]\n",
    "        prefix = 'BUREAU_' + credit_type.split(' ')[0].upper() + '_'\n",
    "        agg_bureau = group_and_merge(type_df, agg_bureau, prefix, BUREAU_LOAN_TYPE_AGG)\n",
    "        del type_df; gc.collect()\n",
    "    # Time based aggregations: last x months\n",
    "    for time_frame in [6, 12]:\n",
    "        prefix = \"BUREAU_LAST{}M_\".format(time_frame)\n",
    "        time_frame_df = bureau[bureau['DAYS_CREDIT'] >= -30*time_frame]\n",
    "        agg_bureau = group_and_merge(time_frame_df, agg_bureau, prefix, BUREAU_TIME_AGG)\n",
    "        del time_frame_df; gc.collect()\n",
    "\n",
    "    # Last loan max overdue\n",
    "    sort_bureau = bureau.sort_values(by=['DAYS_CREDIT'])\n",
    "    gr = sort_bureau.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].last().reset_index()\n",
    "    gr.rename({'AMT_CREDIT_MAX_OVERDUE': 'BUREAU_LAST_LOAN_MAX_OVERDUE'}, inplace=True)\n",
    "    agg_bureau = agg_bureau.merge(gr, on='SK_ID_CURR', how='left')\n",
    "    # Ratios: total debt/total credit and active loans debt/ active loans credit\n",
    "    agg_bureau['BUREAU_DEBT_OVER_CREDIT'] = \\\n",
    "        agg_bureau['BUREAU_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_AMT_CREDIT_SUM_SUM']\n",
    "    agg_bureau['BUREAU_ACTIVE_DEBT_OVER_CREDIT'] = \\\n",
    "        agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_DEBT_SUM']/agg_bureau['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM']\n",
    "    agg_bureau = agg_bureau.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return agg_bureau\n",
    "\n",
    "\n",
    "def get_bureau_balance(path, num_rows= None):\n",
    "    bb = pd.read_csv(os.path.join(path, 'bureau_balance.csv'), nrows= num_rows)\n",
    "    bb, categorical_cols = one_hot_encoder(bb, nan_as_category= False)\n",
    "    # Calculate rate for each category with decay\n",
    "    bb_processed = bb.groupby('SK_ID_BUREAU')[categorical_cols].mean().reset_index()\n",
    "    # Min, Max, Count and mean duration of payments (months)\n",
    "    agg = {'MONTHS_BALANCE': ['min', 'max', 'mean', 'size']}\n",
    "    bb_processed = group_and_merge(bb, bb_processed, '', agg, 'SK_ID_BUREAU')\n",
    "    bb_processed = bb_processed.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del bb; gc.collect()\n",
    "    return bb_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d1ead3",
   "metadata": {},
   "source": [
    "#### 2.3 previous_application<a class=\"anchor\" id=\"section_2_3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969eccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Previous application\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def get_previous_applications(path, num_rows= None):\n",
    "    \"\"\" Process previous_application.csv and return a pandas dataframe. \"\"\"\n",
    "    prev = pd.read_csv(os.path.join(path, 'previous_application.csv'), nrows= num_rows)\n",
    "    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n",
    "\n",
    "    # One-hot encode most important categorical features\n",
    "    ohe_columns = [\n",
    "        'NAME_CONTRACT_STATUS', 'NAME_CONTRACT_TYPE', 'CHANNEL_TYPE',\n",
    "        'NAME_TYPE_SUITE', 'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION',\n",
    "        'NAME_PRODUCT_TYPE', 'NAME_CLIENT_TYPE']\n",
    "    prev, categorical_cols = one_hot_encoder(prev, ohe_columns, nan_as_category= False)\n",
    "\n",
    "    # Feature engineering: ratios and difference\n",
    "    prev['APPLICATION_CREDIT_DIFF'] = prev['AMT_APPLICATION'] - prev['AMT_CREDIT']\n",
    "    prev['APPLICATION_CREDIT_RATIO'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    prev['CREDIT_TO_ANNUITY_RATIO'] = prev['AMT_CREDIT']/prev['AMT_ANNUITY']\n",
    "    prev['DOWN_PAYMENT_TO_CREDIT'] = prev['AMT_DOWN_PAYMENT'] / prev['AMT_CREDIT']\n",
    "    # Interest ratio on previous application (simplified)\n",
    "    total_payment = prev['AMT_ANNUITY'] * prev['CNT_PAYMENT']\n",
    "    prev['SIMPLE_INTERESTS'] = (total_payment/prev['AMT_CREDIT'] - 1)/prev['CNT_PAYMENT']\n",
    "\n",
    "    # Active loans - approved and not complete yet (last_due 365243)\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    active_df = approved[approved['DAYS_LAST_DUE'] == 365243]\n",
    "    # Find how much was already payed in active loans (using installments csv)\n",
    "    active_pay = pay[pay['SK_ID_PREV'].isin(active_df['SK_ID_PREV'])]\n",
    "    active_pay_agg = active_pay.groupby('SK_ID_PREV')[['AMT_INSTALMENT', 'AMT_PAYMENT']].sum()\n",
    "    active_pay_agg.reset_index(inplace= True)\n",
    "    # Active loans: difference of what was payed and installments\n",
    "    active_pay_agg['INSTALMENT_PAYMENT_DIFF'] = active_pay_agg['AMT_INSTALMENT'] - active_pay_agg['AMT_PAYMENT']\n",
    "    # Merge with active_df\n",
    "    active_df = active_df.merge(active_pay_agg, on= 'SK_ID_PREV', how= 'left')\n",
    "    active_df['REMAINING_DEBT'] = active_df['AMT_CREDIT'] - active_df['AMT_PAYMENT']\n",
    "    active_df['REPAYMENT_RATIO'] = active_df['AMT_PAYMENT'] / active_df['AMT_CREDIT']\n",
    "    # Perform aggregations for active applications\n",
    "    active_agg_df = group(active_df, 'PREV_ACTIVE_', PREVIOUS_ACTIVE_AGG)\n",
    "    active_agg_df['TOTAL_REPAYMENT_RATIO'] = active_agg_df['PREV_ACTIVE_AMT_PAYMENT_SUM']/\\\n",
    "                                             active_agg_df['PREV_ACTIVE_AMT_CREDIT_SUM']\n",
    "    del active_pay, active_pay_agg, active_df; gc.collect()\n",
    "\n",
    "    # Change 365.243 values to nan (missing)\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Days last due difference (scheduled x done)\n",
    "    prev['DAYS_LAST_DUE_DIFF'] = prev['DAYS_LAST_DUE_1ST_VERSION'] - prev['DAYS_LAST_DUE']\n",
    "    approved['DAYS_LAST_DUE_DIFF'] = approved['DAYS_LAST_DUE_1ST_VERSION'] - approved['DAYS_LAST_DUE']\n",
    "\n",
    "    # Categorical features\n",
    "    categorical_agg = {key: ['mean'] for key in categorical_cols}\n",
    "    # Perform general aggregations\n",
    "    agg_prev = group(prev, 'PREV_', {**PREVIOUS_AGG, **categorical_agg})\n",
    "    # Merge active loans dataframe on agg_prev\n",
    "    agg_prev = agg_prev.merge(active_agg_df, how='left', on='SK_ID_CURR')\n",
    "    del active_agg_df; gc.collect()\n",
    "    # Aggregations for approved and refused loans\n",
    "    agg_prev = group_and_merge(approved, agg_prev, 'APPROVED_', PREVIOUS_APPROVED_AGG)\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    agg_prev = group_and_merge(refused, agg_prev, 'REFUSED_', PREVIOUS_REFUSED_AGG)\n",
    "    del approved, refused; gc.collect()\n",
    "    # Aggregations for Consumer loans and Cash loans\n",
    "    for loan_type in ['Consumer loans', 'Cash loans']:\n",
    "        type_df = prev[prev['NAME_CONTRACT_TYPE_{}'.format(loan_type)] == 1]\n",
    "        prefix = 'PREV_' + loan_type.split(\" \")[0] + '_'\n",
    "        agg_prev = group_and_merge(type_df, agg_prev, prefix, PREVIOUS_LOAN_TYPE_AGG)\n",
    "        del type_df; gc.collect()\n",
    "\n",
    "    # Get the SK_ID_PREV for loans with late payments (days past due)\n",
    "    pay['LATE_PAYMENT'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "    pay['LATE_PAYMENT'] = pay['LATE_PAYMENT'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    dpd_id = pay[pay['LATE_PAYMENT'] > 0]['SK_ID_PREV'].unique()\n",
    "    # Aggregations for loans with late payments\n",
    "    agg_dpd = group_and_merge(prev[prev['SK_ID_PREV'].isin(dpd_id)], agg_prev,\n",
    "                                    'PREV_LATE_', PREVIOUS_LATE_PAYMENTS_AGG)\n",
    "    del agg_dpd, dpd_id; gc.collect()\n",
    "    # Aggregations for loans in the last x months\n",
    "    for time_frame in [12, 24]:\n",
    "        time_frame_df = prev[prev['DAYS_DECISION'] >= -30*time_frame]\n",
    "        prefix = 'PREV_LAST{}M_'.format(time_frame)\n",
    "        agg_prev = group_and_merge(time_frame_df, agg_prev, prefix, PREVIOUS_TIME_AGG)\n",
    "        del time_frame_df; gc.collect()\n",
    "        agg_prev = agg_prev.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del prev; gc.collect()\n",
    "    return agg_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e679e0d6",
   "metadata": {},
   "source": [
    "#### 2.4 POS-CASH balance<a class=\"anchor\" id=\"section_2_4\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b63eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- POS-CASH\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def get_pos_cash(path, num_rows= None):\n",
    "    \"\"\" Process POS_CASH_balance.csv and return a pandas dataframe. \"\"\"\n",
    "    pos = pd.read_csv(os.path.join(path, 'POS_CASH_balance.csv'), nrows= num_rows)\n",
    "    pos, categorical_cols = one_hot_encoder(pos, nan_as_category= False)\n",
    "    # Flag months with late payment\n",
    "    pos['LATE_PAYMENT'] = pos['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # Aggregate by SK_ID_CURR\n",
    "    categorical_agg = {key: ['mean'] for key in categorical_cols}\n",
    "    pos_agg = group(pos, 'POS_', {**POS_CASH_AGG, **categorical_agg})\n",
    "    # Sort and group by SK_ID_PREV\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.groupby('SK_ID_PREV')\n",
    "    df = pd.DataFrame()\n",
    "    df['SK_ID_CURR'] = gp['SK_ID_CURR'].first()\n",
    "    df['MONTHS_BALANCE_MAX'] = gp['MONTHS_BALANCE'].max()\n",
    "    # Percentage of previous loans completed and completed before initial term\n",
    "    df['POS_LOAN_COMPLETED_MEAN'] = gp['NAME_CONTRACT_STATUS_Completed'].mean()\n",
    "    df['POS_COMPLETED_BEFORE_MEAN'] = gp['CNT_INSTALMENT'].first() - gp['CNT_INSTALMENT'].last()\n",
    "    df['POS_COMPLETED_BEFORE_MEAN'] = df.apply(lambda x: 1 if x['POS_COMPLETED_BEFORE_MEAN'] > 0\n",
    "                                                and x['POS_LOAN_COMPLETED_MEAN'] > 0 else 0, axis=1)\n",
    "    # Number of remaining installments (future installments) and percentage from total\n",
    "    df['POS_REMAINING_INSTALMENTS'] = gp['CNT_INSTALMENT_FUTURE'].last()\n",
    "    df['POS_REMAINING_INSTALMENTS_RATIO'] = gp['CNT_INSTALMENT_FUTURE'].last()/gp['CNT_INSTALMENT'].last()\n",
    "    # Group by SK_ID_CURR and merge\n",
    "    df_gp = df.groupby('SK_ID_CURR').sum().reset_index()\n",
    "    df_gp.drop(['MONTHS_BALANCE_MAX'], axis=1, inplace= True)\n",
    "    pos_agg = pd.merge(pos_agg, df_gp, on= 'SK_ID_CURR', how= 'left')\n",
    "    del df, gp, df_gp, sort_pos; gc.collect()\n",
    "\n",
    "    # Percentage of late payments for the 3 most recent applications\n",
    "    pos = do_sum(pos, ['SK_ID_PREV'], 'LATE_PAYMENT', 'LATE_PAYMENT_SUM')\n",
    "    # Last month of each application\n",
    "    last_month_df = pos.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    # Most recent applications (last 3)\n",
    "    sort_pos = pos.sort_values(by=['SK_ID_PREV', 'MONTHS_BALANCE'])\n",
    "    gp = sort_pos.iloc[last_month_df].groupby('SK_ID_CURR').tail(3)\n",
    "    gp_mean = gp.groupby('SK_ID_CURR').mean().reset_index()\n",
    "    pos_agg = pd.merge(pos_agg, gp_mean[['SK_ID_CURR','LATE_PAYMENT_SUM']], on='SK_ID_CURR', how='left')\n",
    "\n",
    "    # Drop some useless categorical features\n",
    "    drop_features = [\n",
    "        'POS_NAME_CONTRACT_STATUS_Canceled_MEAN', 'POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN',\n",
    "        'POS_NAME_CONTRACT_STATUS_XNA_MEAN']\n",
    "    pos_agg.drop(drop_features, axis=1, inplace=True)\n",
    "    pos_agg = pos_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return pos_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb4817b",
   "metadata": {},
   "source": [
    "#### 2.5 instalments_payments<a class=\"anchor\" id=\"section_2_5\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fba176de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Instalments payments\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def get_installment_payments(path, num_rows= None):\n",
    "    \"\"\" Process installments_payments.csv and return a pandas dataframe. \"\"\"\n",
    "    pay = pd.read_csv(os.path.join(path, 'installments_payments.csv'), nrows= num_rows)\n",
    "    # Group payments and get Payment difference\n",
    "    pay = do_sum(pay, ['SK_ID_PREV', 'NUM_INSTALMENT_NUMBER'], 'AMT_PAYMENT', 'AMT_PAYMENT_GROUPED')\n",
    "    pay['PAYMENT_DIFFERENCE'] = pay['AMT_INSTALMENT'] - pay['AMT_PAYMENT_GROUPED']\n",
    "    pay['PAYMENT_RATIO'] = pay['AMT_INSTALMENT'] / pay['AMT_PAYMENT_GROUPED']\n",
    "    pay['PAID_OVER_AMOUNT'] = pay['AMT_PAYMENT'] - pay['AMT_INSTALMENT']\n",
    "    pay['PAID_OVER'] = (pay['PAID_OVER_AMOUNT'] > 0).astype(int)\n",
    "    # Payment Entry: Days past due and Days before due\n",
    "    pay['DPD'] = pay['DAYS_ENTRY_PAYMENT'] - pay['DAYS_INSTALMENT']\n",
    "    pay['DPD'] = pay['DPD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "    pay['DBD'] = pay['DAYS_INSTALMENT'] - pay['DAYS_ENTRY_PAYMENT']\n",
    "    pay['DBD'] = pay['DBD'].apply(lambda x: 0 if x <= 0 else x)\n",
    "    # Flag late payment\n",
    "    pay['LATE_PAYMENT'] = pay['DBD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # Percentage of payments that were late\n",
    "    pay['INSTALMENT_PAYMENT_RATIO'] = pay['AMT_PAYMENT'] / pay['AMT_INSTALMENT']\n",
    "    pay['LATE_PAYMENT_RATIO'] = pay.apply(lambda x: x['INSTALMENT_PAYMENT_RATIO'] if x['LATE_PAYMENT'] == 1 else 0, axis=1)\n",
    "    # Flag late payments that have a significant amount\n",
    "    pay['SIGNIFICANT_LATE_PAYMENT'] = pay['LATE_PAYMENT_RATIO'].apply(lambda x: 1 if x > 0.05 else 0)\n",
    "    # Flag k threshold late payments\n",
    "    pay['DPD_7'] = pay['DPD'].apply(lambda x: 1 if x >= 7 else 0)\n",
    "    pay['DPD_15'] = pay['DPD'].apply(lambda x: 1 if x >= 15 else 0)\n",
    "    # Aggregations by SK_ID_CURR\n",
    "    pay_agg = group(pay, 'INS_', INSTALLMENTS_AGG)\n",
    "\n",
    "    # Installments in the last x months\n",
    "    for months in [36, 60]:\n",
    "        recent_prev_id = pay[pay['DAYS_INSTALMENT'] >= -30*months]['SK_ID_PREV'].unique()\n",
    "        pay_recent = pay[pay['SK_ID_PREV'].isin(recent_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        pay_agg = group_and_merge(pay_recent, pay_agg, prefix, INSTALLMENTS_TIME_AGG)\n",
    "\n",
    "\n",
    "    return pay_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25abab69",
   "metadata": {},
   "source": [
    "#### 2.6 credit_card_balance<a class=\"anchor\" id=\"section_2_6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b163869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Credit Card \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def get_credit_card(path, num_rows= None):\n",
    "    \"\"\" Process credit_card_balance.csv and return a pandas dataframe. \"\"\"\n",
    "    cc = pd.read_csv(os.path.join(path, 'credit_card_balance.csv'), nrows= num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category=False)\n",
    "    cc.rename(columns={'AMT_RECIVABLE': 'AMT_RECEIVABLE'}, inplace=True)\n",
    "    # Amount used from limit\n",
    "    cc['LIMIT_USE'] = cc['AMT_BALANCE'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # Current payment / Min payment\n",
    "    cc['PAYMENT_DIV_MIN'] = cc['AMT_PAYMENT_CURRENT'] / cc['AMT_INST_MIN_REGULARITY']\n",
    "    # Late payment\n",
    "    cc['LATE_PAYMENT'] = cc['SK_DPD'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    # How much drawing of limit\n",
    "    cc['DRAWING_LIMIT_RATIO'] = cc['AMT_DRAWINGS_ATM_CURRENT'] / cc['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "    # Aggregations by SK_ID_CURR\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(CREDIT_CARD_AGG)\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    cc_agg.reset_index(inplace= True)\n",
    "\n",
    "    # Last month balance of each credit card application\n",
    "    last_ids = cc.groupby('SK_ID_PREV')['MONTHS_BALANCE'].idxmax()\n",
    "    last_months_df = cc[cc.index.isin(last_ids)]\n",
    "    cc_agg = group_and_merge(last_months_df,cc_agg,'CC_LAST_', {'AMT_BALANCE': ['mean', 'max']})\n",
    "\n",
    "    # Aggregations for last x months\n",
    "    for months in [12, 24, 48]:\n",
    "        cc_prev_id = cc[cc['MONTHS_BALANCE'] >= -months]['SK_ID_PREV'].unique()\n",
    "        cc_recent = cc[cc['SK_ID_PREV'].isin(cc_prev_id)]\n",
    "        prefix = 'INS_{}M_'.format(months)\n",
    "        cc_agg = group_and_merge(cc_recent, cc_agg, prefix, CREDIT_CARD_TIME_AGG)\n",
    "        cc_agg = cc_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return cc_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19caffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ratios_features(df):\n",
    "    # CREDIT TO INCOME RATIO\n",
    "    df['BUREAU_INCOME_CREDIT_RATIO'] = df['BUREAU_AMT_CREDIT_SUM_MEAN'] / df['AMT_INCOME_TOTAL']\n",
    "    df['BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO'] = df['BUREAU_ACTIVE_AMT_CREDIT_SUM_SUM'] / df['AMT_INCOME_TOTAL']\n",
    "    # PREVIOUS TO CURRENT CREDIT RATIO\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MIN_RATIO'] = df['APPROVED_AMT_CREDIT_MIN'] / df['AMT_CREDIT']\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MAX_RATIO'] = df['APPROVED_AMT_CREDIT_MAX'] / df['AMT_CREDIT']\n",
    "    df['CURRENT_TO_APPROVED_CREDIT_MEAN_RATIO'] = df['APPROVED_AMT_CREDIT_MEAN'] / df['AMT_CREDIT']\n",
    "    \n",
    "    # PREVIOUS TO CURRENT CREDIT TO ANNUITY RATIO\n",
    "    df['CTA_CREDIT_TO_ANNUITY_MAX_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MAX'] / df[\n",
    "        'CREDIT_TO_ANNUITY_RATIO']\n",
    "    df['CTA_CREDIT_TO_ANNUITY_MEAN_RATIO'] = df['APPROVED_CREDIT_TO_ANNUITY_RATIO_MEAN'] / df[\n",
    "        'CREDIT_TO_ANNUITY_RATIO']\n",
    "    # DAYS DIFFERENCES AND RATIOS\n",
    "    df['DAYS_DECISION_MEAN_TO_BIRTH'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_BIRTH']\n",
    "    df['DAYS_CREDIT_MEAN_TO_BIRTH'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_BIRTH']\n",
    "    df['DAYS_DECISION_MEAN_TO_EMPLOYED'] = df['APPROVED_DAYS_DECISION_MEAN'] / df['DAYS_EMPLOYED']\n",
    "    df['DAYS_CREDIT_MEAN_TO_EMPLOYED'] = df['BUREAU_DAYS_CREDIT_MEAN'] / df['DAYS_EMPLOYED']\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e5106f",
   "metadata": {},
   "source": [
    "#### 2.7 Configurations<a class=\"anchor\" id=\"section_2_7\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fc3cb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CONFIGURATIONS -------------------------\n",
    "\n",
    "# GENERAL CONFIGURATIONS\n",
    "NUM_THREADS = 4\n",
    "DATA_DIRECTORY = \"\"\n",
    "SUBMISSION_SUFIX = \"_model2_04\"\n",
    "\n",
    "# INSTALLMENTS TREND PERIODS\n",
    "INSTALLMENTS_LAST_K_TREND_PERIODS =  [12, 24, 60, 120]\n",
    "\n",
    "# AGGREGATIONS\n",
    "BUREAU_AGG = {\n",
    "    'SK_ID_BUREAU': ['nunique'],\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean', 'sum'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "    # Categorical\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_1': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "    'STATUS_C': ['mean'],\n",
    "    'STATUS_X': ['mean'],\n",
    "    'CREDIT_ACTIVE_Active': ['mean'],\n",
    "    'CREDIT_ACTIVE_Closed': ['mean'],\n",
    "    'CREDIT_ACTIVE_Sold': ['mean'],\n",
    "    'CREDIT_TYPE_Consumer credit': ['mean'],\n",
    "    'CREDIT_TYPE_Credit card': ['mean'],\n",
    "    'CREDIT_TYPE_Car loan': ['mean'],\n",
    "    'CREDIT_TYPE_Mortgage': ['mean'],\n",
    "    'CREDIT_TYPE_Microloan': ['mean'],\n",
    "    # Group by loan duration features (months)\n",
    "    'LL_AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'LL_DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'LL_STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_ACTIVE_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['max', 'mean'],\n",
    "    'DAYS_CREDIT_UPDATE': ['min', 'mean'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean'],\n",
    "    'MONTHS_BALANCE_MEAN': ['mean', 'var'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "BUREAU_CLOSED_AGG = {\n",
    "    'DAYS_CREDIT': ['max', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'sum'],\n",
    "    'DAYS_CREDIT_UPDATE': ['max'],\n",
    "    'ENDDATE_DIF': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "BUREAU_LOAN_TYPE_AGG = {\n",
    "    'DAYS_CREDIT': ['mean', 'max'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM': ['mean', 'max'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'max'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['max'],\n",
    "}\n",
    "\n",
    "BUREAU_TIME_AGG = {\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['mean', 'sum'],\n",
    "    'DEBT_PERCENTAGE': ['mean'],\n",
    "    'DEBT_CREDIT_DIFF': ['mean'],\n",
    "    'STATUS_0': ['mean'],\n",
    "    'STATUS_12345': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['max'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean', 'var'],\n",
    "    'DOWN_PAYMENT_TO_CREDIT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_ACTIVE_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'SIMPLE_INTERESTS': ['mean'],\n",
    "    'AMT_ANNUITY': ['max', 'sum'],\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_DOWN_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'AMT_PAYMENT': ['sum'],\n",
    "    'INSTALMENT_PAYMENT_DIFF': ['mean', 'max'],\n",
    "    'REMAINING_DEBT': ['max', 'mean', 'sum'],\n",
    "    'REPAYMENT_RATIO': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_APPROVED_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'AMT_DOWN_PAYMENT': ['max'],\n",
    "    'AMT_GOODS_PRICE': ['max'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    'DAYS_TERMINATION': ['mean'],\n",
    "    # Engineered features\n",
    "    'CREDIT_TO_ANNUITY_RATIO': ['mean', 'max'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['max'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    # The following features are only for approved applications\n",
    "    'DAYS_FIRST_DRAWING': ['max', 'mean'],\n",
    "    'DAYS_FIRST_DUE': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE': ['max', 'mean'],\n",
    "    'DAYS_LAST_DUE_DIFF': ['min', 'max', 'mean'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'max', 'mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_REFUSED_AGG = {\n",
    "    'AMT_APPLICATION': ['max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'max', 'mean', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LATE_PAYMENTS_AGG = {\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_LOAN_TYPE_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['min', 'mean', 'max', 'var'],\n",
    "    'APPLICATION_CREDIT_DIFF': ['min', 'var'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['max'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean'],\n",
    "}\n",
    "\n",
    "PREVIOUS_TIME_AGG = {\n",
    "    'AMT_CREDIT': ['sum'],\n",
    "    'AMT_ANNUITY': ['mean', 'max'],\n",
    "    'SIMPLE_INTERESTS': ['mean', 'max'],\n",
    "    'DAYS_DECISION': ['min', 'mean'],\n",
    "    'DAYS_LAST_DUE_1ST_VERSION': ['min', 'max', 'mean'],\n",
    "    # Engineered features\n",
    "    'APPLICATION_CREDIT_DIFF': ['min'],\n",
    "    'APPLICATION_CREDIT_RATIO': ['min', 'max', 'mean'],\n",
    "    'NAME_CONTRACT_TYPE_Consumer loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Cash loans': ['mean'],\n",
    "    'NAME_CONTRACT_TYPE_Revolving loans': ['mean'],\n",
    "}\n",
    "\n",
    "POS_CASH_AGG = {\n",
    "    'SK_ID_PREV': ['nunique'],\n",
    "    'MONTHS_BALANCE': ['min', 'max', 'size'],\n",
    "    'SK_DPD': ['max', 'mean', 'sum', 'var'],\n",
    "    'SK_DPD_DEF': ['max', 'mean', 'sum'],\n",
    "    'LATE_PAYMENT': ['mean']\n",
    "}\n",
    "\n",
    "INSTALLMENTS_AGG = {\n",
    "    'SK_ID_PREV': ['size', 'nunique'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DPD': ['max', 'mean', 'var'],\n",
    "    'DBD': ['max', 'mean', 'var'],\n",
    "    'PAYMENT_DIFFERENCE': ['mean'],\n",
    "    'PAYMENT_RATIO': ['mean'],\n",
    "    'LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'SIGNIFICANT_LATE_PAYMENT': ['mean', 'sum'],\n",
    "    'LATE_PAYMENT_RATIO': ['mean'],\n",
    "    'DPD_7': ['mean'],\n",
    "    'DPD_15': ['mean'],\n",
    "    'PAID_OVER': ['mean']\n",
    "}\n",
    "\n",
    "INSTALLMENTS_TIME_AGG = {\n",
    "    'SK_ID_PREV': ['size'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_INSTALMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DPD': ['max', 'mean', 'var'],\n",
    "    'DBD': ['max', 'mean', 'var'],\n",
    "    'PAYMENT_DIFFERENCE': ['mean'],\n",
    "    'PAYMENT_RATIO': ['mean'],\n",
    "    'LATE_PAYMENT': ['mean'],\n",
    "    'SIGNIFICANT_LATE_PAYMENT': ['mean'],\n",
    "    'LATE_PAYMENT_RATIO': ['mean'],\n",
    "    'DPD_7': ['mean'],\n",
    "    'DPD_15': ['mean'],\n",
    "}\n",
    "\n",
    "CREDIT_CARD_AGG = {\n",
    "    'MONTHS_BALANCE': ['min'],\n",
    "    'AMT_BALANCE': ['max'],\n",
    "    'AMT_CREDIT_LIMIT_ACTUAL': ['max'],\n",
    "    'AMT_DRAWINGS_ATM_CURRENT': ['max', 'sum'],\n",
    "    'AMT_DRAWINGS_CURRENT': ['max', 'sum'],\n",
    "    'AMT_DRAWINGS_POS_CURRENT': ['max', 'sum'],\n",
    "    'AMT_INST_MIN_REGULARITY': ['max', 'mean'],\n",
    "    'AMT_PAYMENT_TOTAL_CURRENT': ['max', 'mean', 'sum', 'var'],\n",
    "    'AMT_TOTAL_RECEIVABLE': ['max', 'mean'],\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'CNT_DRAWINGS_CURRENT': ['max', 'mean', 'sum'],\n",
    "    'CNT_DRAWINGS_POS_CURRENT': ['mean'],\n",
    "    'SK_DPD': ['mean', 'max', 'sum'],\n",
    "    'SK_DPD_DEF': ['max', 'sum'],\n",
    "    'LIMIT_USE': ['max', 'mean'],\n",
    "    'PAYMENT_DIV_MIN': ['min', 'mean'],\n",
    "    'LATE_PAYMENT': ['max', 'sum'],\n",
    "}\n",
    "\n",
    "CREDIT_CARD_TIME_AGG = {\n",
    "    'CNT_DRAWINGS_ATM_CURRENT': ['mean'],\n",
    "    'SK_DPD': ['max', 'sum'],\n",
    "    'AMT_BALANCE': ['mean', 'max'],\n",
    "    'LIMIT_USE': ['max', 'mean']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59852f",
   "metadata": {},
   "source": [
    "#### 2.8 Dataframe creation<a class=\"anchor\" id=\"section_2_8\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee080da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Main function\n",
    "# --------------------------------------------------------------------\n",
    "    \n",
    "def main(debug= False):\n",
    "    num_rows = 30000 if debug else None\n",
    "    with timer(\"application_train and application_test\"):\n",
    "        df = get_train_test(DATA_DIRECTORY, num_rows= num_rows)\n",
    "        print(\"Application dataframe shape: \", df.shape)\n",
    "    with timer(\"Bureau and bureau_balance data\"):\n",
    "        bureau_df = get_bureau(DATA_DIRECTORY, num_rows= num_rows)\n",
    "        df = pd.merge(df, bureau_df, on='SK_ID_CURR', how='left')\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Bureau dataframe shape: \", bureau_df.shape)\n",
    "        del bureau_df; gc.collect()\n",
    "    with timer(\"previous_application\"):\n",
    "        prev_df = get_previous_applications(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, prev_df, on='SK_ID_CURR', how='left')\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Previous dataframe shape: \", prev_df.shape)\n",
    "        del prev_df; gc.collect()\n",
    "    with timer(\"previous applications balances\"):\n",
    "        pos = get_pos_cash(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, pos, on='SK_ID_CURR', how='left')\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Pos-cash dataframe shape: \", pos.shape)\n",
    "        del pos; gc.collect()\n",
    "    with timer(\"credit_card_balance\"):\n",
    "        cc = get_credit_card(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, cc, on='SK_ID_CURR', how='left')\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Credit card dataframe shape: \", cc.shape)\n",
    "        del cc; gc.collect()\n",
    "    with timer(\"installment_payments\"):\n",
    "        ins = get_installment_payments(DATA_DIRECTORY, num_rows)\n",
    "        df = pd.merge(df, ins, on='SK_ID_CURR', how='left')\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Installments dataframe shape: \", ins.shape)\n",
    "        del ins; gc.collect()\n",
    "\n",
    "    # Add ratios and groupby between different tables\n",
    "    df = add_ratios_features(df)\n",
    "    print(\"-------------------------------\")\n",
    "    print(\"Ratios features added\")\n",
    "    print(\"-------------------------------\")\n",
    "    df = reduce_memory(df)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfaaa1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application dataframe shape:  (356250, 83)\n",
      "application_train and application_test - done in 35s\n",
      "-------------------------------\n",
      "Bureau dataframe shape:  (305811, 156)\n",
      "Bureau and bureau_balance data - done in 38s\n",
      "-------------------------------\n",
      "Previous dataframe shape:  (338857, 225)\n",
      "previous_application - done in 50s\n",
      "-------------------------------\n",
      "Pos-cash dataframe shape:  (337252, 24)\n",
      "previous applications balances - done in 111s\n",
      "-------------------------------\n",
      "Credit card dataframe shape:  (103558, 59)\n",
      "credit_card_balance - done in 22s\n",
      "-------------------------------\n",
      "Installments dataframe shape:  (339587, 80)\n",
      "installment_payments - done in 225s\n",
      "-------------------------------\n",
      "Ratios features added\n",
      "-------------------------------\n",
      "Initial df memory usage is 1723.19 MB for 633 columns\n",
      "Final memory usage is: 688.67 MB - decreased by 60.0%\n",
      "Final dataset shape: (356250, 633)\n"
     ]
    }
   ],
   "source": [
    "df = main()\n",
    "print('Final dataset shape:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea4396",
   "metadata": {},
   "source": [
    "### 3. Imputation for Machine Learning algorithms<a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87b2420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape for train_df: (307506, 633)\n",
      "Final shape for test_df: (48744, 632)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "test_df.drop(['TARGET'], axis=1, inplace=True)\n",
    "print('Final shape for train_df:', train_df.shape)\n",
    "print('Final shape for test_df:', test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b79e9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of NaN before imputation by median for train_set: 64829943\n",
      "Nb of NaN after imputation by median for train_set: 0\n",
      "Nb of NaN before imputation by median for test_set: 9117362\n",
      "Nb of NaN after imputation by median for test_set: 0\n"
     ]
    }
   ],
   "source": [
    "train_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Numerical features - Median imputation\n",
    "nb_nan = train_df.isna().sum().sum()\n",
    "print(f'Nb of NaN before imputation by median for train_set: {nb_nan}')\n",
    "train_df = train_df.fillna(train_df.median())\n",
    "# Checking\n",
    "nb_nan = train_df.isna().sum().sum()\n",
    "print(f'Nb of NaN after imputation by median for train_set: {nb_nan}')\n",
    "# Numerical features - Median imputation\n",
    "nb_nan = test_df.isna().sum().sum()\n",
    "print(f'Nb of NaN before imputation by median for test_set: {nb_nan}')\n",
    "test_df = test_df.fillna(test_df.median())\n",
    "# Checking\n",
    "nb_nan = test_df.isna().sum().sum()\n",
    "print(f'Nb of NaN after imputation by median for test_set: {nb_nan}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bed35765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape for train_df: (307506, 633)\n",
      "Final shape for test_df: (48744, 632)\n",
      "Final shape for df: (356250, 633)\n"
     ]
    }
   ],
   "source": [
    "# Saving for modeling before recursive feature selection\n",
    "train_df.to_pickle('./train_data.pkl')\n",
    "test_df.to_pickle('./test_data.pkl')\n",
    "df.to_pickle('./data_full.pkl')\n",
    "print('Final shape for train_df:', train_df.shape)\n",
    "print('Final shape for test_df:', test_df.shape)\n",
    "print('Final shape for df:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af97f45f",
   "metadata": {},
   "source": [
    "### 4. BorutaPy feature selection<a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbbde5",
   "metadata": {},
   "source": [
    "Given an external estimator that assigns weights to features (e.g., the coefficients of a linear model), the goal of Boruta feature selection is to select features by recursively considering smaller and smaller sets of features. A number of randomly shuffled shadow attributes are created to establish the baseline performance. A hypothesis test is then used to determine whether a variable is only randomly correlated or carries significant information. Variables that fail to reject this hypothesis are discarded. As Boruta iteratively removes uninformative variables, the feature importance of the remaining relevant variables will improve. The comparatively noisier variables will see larger improvements. This happens because the random variables that the comparatively noisier relevant variables were correlated with have been discarded from the dataset because the noise, the random variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01fa3eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df : (307506, 633)\n",
      "test_df : (48744, 632)\n"
     ]
    }
   ],
   "source": [
    "# Labels saving\n",
    "train_df_rec = train_df.copy()\n",
    "test_df_rec = test_df.copy()\n",
    "train_df_labels = train_df_rec['TARGET']\n",
    "\n",
    "# Ids dropped \n",
    "train_df_rec_noid = train_df_rec.drop(columns=['SK_ID_CURR'])\n",
    "train_df_rec_noid = train_df_rec_noid.drop(columns=['TARGET'])\n",
    "# test_df_rec = test_df_rec.drop(columns=['SK_ID_CURR'])\n",
    "\n",
    "print(f'train_df : {train_df.shape}')\n",
    "print(f'test_df : {test_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7a18c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "X = train_df_rec_noid.values\n",
    "y = train_df_labels.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acaf7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model with several hyperparameters\n",
    "lgbm = lgb.LGBMClassifier(objective='binary',\n",
    "                          boosting_type='goss',\n",
    "                          n_estimators=10000,\n",
    "                          is_unbalance=True,\n",
    "                          num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42892e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] num_iterations is set=100, num_boost_round=100 will be ignored. Current value: num_iterations=100\n",
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t631\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t55\n",
      "Tentative: \t117\n",
      "Rejected: \t459\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t55\n",
      "Tentative: \t117\n",
      "Rejected: \t459\n",
      "Iteration: \t10 / 100\n",
      "Confirmed: \t55\n",
      "Tentative: \t117\n",
      "Rejected: \t459\n",
      "Iteration: \t11 / 100\n",
      "Confirmed: \t55\n",
      "Tentative: \t117\n",
      "Rejected: \t459\n",
      "Iteration: \t12 / 100\n",
      "Confirmed: \t60\n",
      "Tentative: \t101\n",
      "Rejected: \t470\n",
      "Iteration: \t13 / 100\n",
      "Confirmed: \t60\n",
      "Tentative: \t101\n",
      "Rejected: \t470\n",
      "Iteration: \t14 / 100\n",
      "Confirmed: \t60\n",
      "Tentative: \t101\n",
      "Rejected: \t470\n",
      "Iteration: \t15 / 100\n",
      "Confirmed: \t60\n",
      "Tentative: \t101\n",
      "Rejected: \t470\n",
      "Iteration: \t16 / 100\n",
      "Confirmed: \t61\n",
      "Tentative: \t89\n",
      "Rejected: \t481\n",
      "Iteration: \t17 / 100\n",
      "Confirmed: \t61\n",
      "Tentative: \t89\n",
      "Rejected: \t481\n",
      "Iteration: \t18 / 100\n",
      "Confirmed: \t61\n",
      "Tentative: \t89\n",
      "Rejected: \t481\n",
      "Iteration: \t19 / 100\n",
      "Confirmed: \t64\n",
      "Tentative: \t79\n",
      "Rejected: \t488\n",
      "Iteration: \t20 / 100\n",
      "Confirmed: \t64\n",
      "Tentative: \t79\n",
      "Rejected: \t488\n",
      "Iteration: \t21 / 100\n",
      "Confirmed: \t64\n",
      "Tentative: \t79\n",
      "Rejected: \t488\n",
      "Iteration: \t22 / 100\n",
      "Confirmed: \t66\n",
      "Tentative: \t77\n",
      "Rejected: \t488\n",
      "Iteration: \t23 / 100\n",
      "Confirmed: \t66\n",
      "Tentative: \t77\n",
      "Rejected: \t488\n",
      "Iteration: \t24 / 100\n",
      "Confirmed: \t66\n",
      "Tentative: \t77\n",
      "Rejected: \t488\n",
      "Iteration: \t25 / 100\n",
      "Confirmed: \t66\n",
      "Tentative: \t75\n",
      "Rejected: \t490\n",
      "Iteration: \t26 / 100\n",
      "Confirmed: \t70\n",
      "Tentative: \t71\n",
      "Rejected: \t490\n",
      "Iteration: \t27 / 100\n",
      "Confirmed: \t70\n",
      "Tentative: \t71\n",
      "Rejected: \t490\n",
      "Iteration: \t28 / 100\n",
      "Confirmed: \t70\n",
      "Tentative: \t69\n",
      "Rejected: \t492\n",
      "Iteration: \t29 / 100\n",
      "Confirmed: \t71\n",
      "Tentative: \t68\n",
      "Rejected: \t492\n",
      "Iteration: \t30 / 100\n",
      "Confirmed: \t71\n",
      "Tentative: \t68\n",
      "Rejected: \t492\n",
      "Iteration: \t31 / 100\n",
      "Confirmed: \t71\n",
      "Tentative: \t68\n",
      "Rejected: \t492\n",
      "Iteration: \t32 / 100\n",
      "Confirmed: \t71\n",
      "Tentative: \t67\n",
      "Rejected: \t493\n",
      "Iteration: \t33 / 100\n",
      "Confirmed: \t71\n",
      "Tentative: \t67\n",
      "Rejected: \t493\n",
      "Iteration: \t34 / 100\n",
      "Confirmed: \t73\n",
      "Tentative: \t65\n",
      "Rejected: \t493\n",
      "Iteration: \t35 / 100\n",
      "Confirmed: \t73\n",
      "Tentative: \t62\n",
      "Rejected: \t496\n",
      "Iteration: \t36 / 100\n",
      "Confirmed: \t73\n",
      "Tentative: \t62\n",
      "Rejected: \t496\n",
      "Iteration: \t37 / 100\n",
      "Confirmed: \t75\n",
      "Tentative: \t60\n",
      "Rejected: \t496\n",
      "Iteration: \t38 / 100\n",
      "Confirmed: \t75\n",
      "Tentative: \t60\n",
      "Rejected: \t496\n",
      "Iteration: \t39 / 100\n",
      "Confirmed: \t75\n",
      "Tentative: \t60\n",
      "Rejected: \t496\n",
      "Iteration: \t40 / 100\n",
      "Confirmed: \t75\n",
      "Tentative: \t59\n",
      "Rejected: \t497\n",
      "Iteration: \t41 / 100\n",
      "Confirmed: \t75\n",
      "Tentative: \t59\n",
      "Rejected: \t497\n",
      "Iteration: \t42 / 100\n",
      "Confirmed: \t75\n",
      "Tentative: \t59\n",
      "Rejected: \t497\n",
      "Iteration: \t43 / 100\n",
      "Confirmed: \t76\n",
      "Tentative: \t58\n",
      "Rejected: \t497\n",
      "Iteration: \t44 / 100\n",
      "Confirmed: \t76\n",
      "Tentative: \t58\n",
      "Rejected: \t497\n",
      "Iteration: \t45 / 100\n",
      "Confirmed: \t76\n",
      "Tentative: \t58\n",
      "Rejected: \t497\n",
      "Iteration: \t46 / 100\n",
      "Confirmed: \t77\n",
      "Tentative: \t57\n",
      "Rejected: \t497\n",
      "Iteration: \t47 / 100\n",
      "Confirmed: \t77\n",
      "Tentative: \t57\n",
      "Rejected: \t497\n",
      "Iteration: \t48 / 100\n",
      "Confirmed: \t77\n",
      "Tentative: \t57\n",
      "Rejected: \t497\n",
      "Iteration: \t49 / 100\n",
      "Confirmed: \t78\n",
      "Tentative: \t56\n",
      "Rejected: \t497\n",
      "Iteration: \t50 / 100\n",
      "Confirmed: \t78\n",
      "Tentative: \t56\n",
      "Rejected: \t497\n",
      "Iteration: \t51 / 100\n",
      "Confirmed: \t79\n",
      "Tentative: \t54\n",
      "Rejected: \t498\n",
      "Iteration: \t52 / 100\n",
      "Confirmed: \t79\n",
      "Tentative: \t54\n",
      "Rejected: \t498\n",
      "Iteration: \t53 / 100\n",
      "Confirmed: \t79\n",
      "Tentative: \t54\n",
      "Rejected: \t498\n",
      "Iteration: \t54 / 100\n",
      "Confirmed: \t80\n",
      "Tentative: \t52\n",
      "Rejected: \t499\n",
      "Iteration: \t55 / 100\n",
      "Confirmed: \t80\n",
      "Tentative: \t52\n",
      "Rejected: \t499\n",
      "Iteration: \t56 / 100\n",
      "Confirmed: \t80\n",
      "Tentative: \t52\n",
      "Rejected: \t499\n",
      "Iteration: \t57 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t49\n",
      "Rejected: \t499\n",
      "Iteration: \t58 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t49\n",
      "Rejected: \t499\n",
      "Iteration: \t59 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t46\n",
      "Rejected: \t502\n",
      "Iteration: \t60 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t46\n",
      "Rejected: \t502\n",
      "Iteration: \t61 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t46\n",
      "Rejected: \t502\n",
      "Iteration: \t62 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t46\n",
      "Rejected: \t502\n",
      "Iteration: \t63 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t46\n",
      "Rejected: \t502\n",
      "Iteration: \t64 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t46\n",
      "Rejected: \t502\n",
      "Iteration: \t65 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t44\n",
      "Rejected: \t504\n",
      "Iteration: \t66 / 100\n",
      "Confirmed: \t83\n",
      "Tentative: \t44\n",
      "Rejected: \t504\n",
      "Iteration: \t67 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t68 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t69 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t70 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t71 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t72 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t73 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t74 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t75 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t76 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t77 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t78 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t79 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t80 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t81 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t82 / 100\n",
      "Confirmed: \t84\n",
      "Tentative: \t43\n",
      "Rejected: \t504\n",
      "Iteration: \t83 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t84 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t85 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t86 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t87 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t88 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t89 / 100\n",
      "Confirmed: \t85\n",
      "Tentative: \t42\n",
      "Rejected: \t504\n",
      "Iteration: \t90 / 100\n",
      "Confirmed: \t86\n",
      "Tentative: \t41\n",
      "Rejected: \t504\n",
      "Iteration: \t91 / 100\n",
      "Confirmed: \t86\n",
      "Tentative: \t41\n",
      "Rejected: \t504\n",
      "Iteration: \t92 / 100\n",
      "Confirmed: \t86\n",
      "Tentative: \t41\n",
      "Rejected: \t504\n",
      "Iteration: \t93 / 100\n",
      "Confirmed: \t86\n",
      "Tentative: \t41\n",
      "Rejected: \t504\n",
      "Iteration: \t94 / 100\n",
      "Confirmed: \t86\n",
      "Tentative: \t40\n",
      "Rejected: \t505\n",
      "Iteration: \t95 / 100\n",
      "Confirmed: \t87\n",
      "Tentative: \t39\n",
      "Rejected: \t505\n",
      "Iteration: \t96 / 100\n",
      "Confirmed: \t87\n",
      "Tentative: \t39\n",
      "Rejected: \t505\n",
      "Iteration: \t97 / 100\n",
      "Confirmed: \t87\n",
      "Tentative: \t39\n",
      "Rejected: \t505\n",
      "Iteration: \t98 / 100\n",
      "Confirmed: \t87\n",
      "Tentative: \t39\n",
      "Rejected: \t505\n",
      "Iteration: \t99 / 100\n",
      "Confirmed: \t87\n",
      "Tentative: \t39\n",
      "Rejected: \t505\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t100 / 100\n",
      "Confirmed: \t87\n",
      "Tentative: \t25\n",
      "Rejected: \t505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BorutaPy(estimator=LGBMClassifier(boosting_type='goss', is_unbalance=True,\n",
       "                                  n_estimators=-1587, num_boost_round=100,\n",
       "                                  objective='binary',\n",
       "                                  random_state=RandomState(MT19937) at 0x1E98842B240),\n",
       "         n_estimators='auto',\n",
       "         random_state=RandomState(MT19937) at 0x1E98842B240, verbose=2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Boruta initialization\n",
    "boruta_feature_selector = BorutaPy(lgbm,\n",
    "                                   n_estimators='auto',\n",
    "                                   verbose=2,\n",
    "                                   random_state=42,\n",
    "                                   max_iter=100, perc=100)\n",
    "                                   \n",
    "# Training\n",
    "boruta_feature_selector.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "401b900d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307506, 87)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply model on dataset\n",
    "X_bor_lgbm100 = boruta_feature_selector.transform(X)\n",
    "X_bor_lgbm100.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851bb7da",
   "metadata": {},
   "source": [
    "87 features over 633 can explained 100% of the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b5c78f5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"col_boruta_lgbm : ['TARGET', 'NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'OCCUPATION_TYPE', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'FLOORSMAX_MODE', 'TOTALAREA_MODE', 'AMT_REQ_CREDIT_BUREAU_QRT', 'NEW_DOC_KURT', 'EXT_SOURCES_PROD', 'EXT_SOURCES_MIN', 'EXT_SOURCES_MAX', 'EXT_SOURCES_NANMEDIAN', 'EXT_SOURCES_VAR', 'CREDIT_TO_ANNUITY_RATIO', 'ANNUITY_TO_INCOME_RATIO', 'INCOME_TO_EMPLOYED_RATIO', 'INCOME_TO_BIRTH_RATIO', 'ID_TO_BIRTH_RATIO', 'CAR_TO_BIRTH_RATIO', 'PHONE_TO_BIRTH_RATIO', 'GROUP_EXT_SOURCES_MEDIAN', 'GROUP_INCOME_MEAN', 'BUREAU_AMT_CREDIT_SUM_OVERDUE_SUM', 'BUREAU_LL_DEBT_CREDIT_DIFF_MEAN', 'BUREAU_ACTIVE_DAYS_CREDIT_ENDDATE_MIN', 'BUREAU_ACTIVE_AMT_CREDIT_MAX_OVERDUE_MEAN', 'BUREAU_ACTIVE_DAYS_CREDIT_UPDATE_MIN', 'BUREAU_ACTIVE_DAYS_CREDIT_UPDATE_MEAN', 'BUREAU_CLOSED_AMT_CREDIT_SUM_DEBT_MAX', 'BUREAU_CONSUMER_DEBT_PERCENTAGE_MEAN', 'BUREAU_CONSUMER_DAYS_CREDIT_ENDDATE_MAX', 'BUREAU_CREDIT_AMT_CREDIT_SUM_MAX', 'BUREAU_CREDIT_AMT_CREDIT_SUM_DEBT_MEAN', 'BUREAU_CREDIT_AMT_CREDIT_SUM_DEBT_MAX', 'BUREAU_LAST6M_AMT_CREDIT_SUM_DEBT_MEAN', 'BUREAU_LAST12M_AMT_CREDIT_MAX_OVERDUE_MEAN', 'BUREAU_LAST12M_AMT_CREDIT_SUM_DEBT_MEAN', 'BUREAU_LAST12M_AMT_CREDIT_SUM_DEBT_SUM', 'PREV_DAYS_DECISION_MEAN', 'PREV_CNT_PAYMENT_MAX', 'PREV_APPLICATION_CREDIT_RATIO_MIN', 'PREV_NAME_CONTRACT_STATUS_Approved_MEAN', 'PREV_ACTIVE_CNT_PAYMENT_MEAN', 'PREV_ACTIVE_DAYS_LAST_DUE_1ST_VERSION_MEAN', 'PREV_ACTIVE_INSTALMENT_PAYMENT_DIFF_MEAN', 'PREV_ACTIVE_REMAINING_DEBT_MAX', 'APPROVED_CREDIT_TO_ANNUITY_RATIO_MEAN', 'APPROVED_DAYS_LAST_DUE_DIFF_MAX', 'PREV_Consumer_AMT_CREDIT_SUM', 'PREV_Cash_AMT_ANNUITY_MEAN', 'PREV_Cash_AMT_ANNUITY_MAX', 'PREV_Cash_SIMPLE_INTERESTS_MIN', 'PREV_Cash_APPLICATION_CREDIT_RATIO_MEAN', 'PREV_Cash_DAYS_LAST_DUE_1ST_VERSION_MAX', 'PREV_LAST24M_AMT_ANNUITY_MAX', 'PREV_LAST24M_DAYS_LAST_DUE_1ST_VERSION_MIN', 'PREV_LAST24M_DAYS_LAST_DUE_1ST_VERSION_MEAN', 'POS_SK_DPD_VAR', 'CC_AMT_TOTAL_RECEIVABLE_MEAN', 'CC_CNT_DRAWINGS_ATM_CURRENT_SUM', 'CC_SK_DPD_DEF_MAX', 'CC_LATE_PAYMENT_SUM', 'INS_SK_ID_PREV_SIZE', 'INS_SK_ID_PREV_NUNIQUE', 'INS_AMT_PAYMENT_MAX', 'INS_DBD_MEAN', 'INS_LATE_PAYMENT_SUM', 'INS_36M_DAYS_ENTRY_PAYMENT_MIN', 'INS_36M_AMT_INSTALMENT_MEAN', 'INS_36M_AMT_PAYMENT_SUM', 'INS_36M_SIGNIFICANT_LATE_PAYMENT_MEAN', 'INS_60M_LATE_PAYMENT_MEAN', 'INS_60M_SIGNIFICANT_LATE_PAYMENT_MEAN', 'BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO', 'CURRENT_TO_APPROVED_CREDIT_MIN_RATIO']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col_boruta_lgbm100 = list()\n",
    "features_lgbm = [f for f in train_df.columns]\n",
    "indexes_lgbm = np.where(boruta_feature_selector.support_ == True)\n",
    "for x in np.nditer(indexes_lgbm):\n",
    "    col_boruta_lgbm100.append(features_lgbm[x])\n",
    "display(f'col_boruta_lgbm : {col_boruta_lgbm100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bae0e69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(356250, 88)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>NAME_TYPE_SUITE</th>\n",
       "      <th>NAME_INCOME_TYPE</th>\n",
       "      <th>NAME_FAMILY_STATUS</th>\n",
       "      <th>NAME_HOUSING_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>INS_DBD_MEAN</th>\n",
       "      <th>INS_LATE_PAYMENT_SUM</th>\n",
       "      <th>INS_36M_DAYS_ENTRY_PAYMENT_MIN</th>\n",
       "      <th>INS_36M_AMT_INSTALMENT_MEAN</th>\n",
       "      <th>INS_36M_AMT_PAYMENT_SUM</th>\n",
       "      <th>INS_36M_SIGNIFICANT_LATE_PAYMENT_MEAN</th>\n",
       "      <th>INS_60M_LATE_PAYMENT_MEAN</th>\n",
       "      <th>INS_60M_SIGNIFICANT_LATE_PAYMENT_MEAN</th>\n",
       "      <th>BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO</th>\n",
       "      <th>CURRENT_TO_APPROVED_CREDIT_MIN_RATIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.421875</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-587.0</td>\n",
       "      <td>11559.247070</td>\n",
       "      <td>2.196257e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.380859</td>\n",
       "      <td>0.440430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.160156</td>\n",
       "      <td>25.0</td>\n",
       "      <td>-806.0</td>\n",
       "      <td>118314.710938</td>\n",
       "      <td>1.538091e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.052612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.667969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-795.0</td>\n",
       "      <td>7096.154785</td>\n",
       "      <td>2.128846e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.375000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-575.0</td>\n",
       "      <td>62947.089844</td>\n",
       "      <td>1.007153e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.589844</td>\n",
       "      <td>41.0</td>\n",
       "      <td>-1106.0</td>\n",
       "      <td>18268.630859</td>\n",
       "      <td>7.446037e+05</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.731934</td>\n",
       "      <td>0.678711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356245</th>\n",
       "      <td>456221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>412560.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.332031</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-661.0</td>\n",
       "      <td>91036.453125</td>\n",
       "      <td>2.731094e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.898438</td>\n",
       "      <td>0.617188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356246</th>\n",
       "      <td>456222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>622413.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-815.0</td>\n",
       "      <td>10101.311523</td>\n",
       "      <td>4.803925e+05</td>\n",
       "      <td>0.836914</td>\n",
       "      <td>0.836914</td>\n",
       "      <td>0.836914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356247</th>\n",
       "      <td>456223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.625000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-818.0</td>\n",
       "      <td>23158.992188</td>\n",
       "      <td>1.852719e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.249634</td>\n",
       "      <td>0.353271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356248</th>\n",
       "      <td>456224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.277344</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-559.0</td>\n",
       "      <td>23451.705078</td>\n",
       "      <td>4.455824e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.625000</td>\n",
       "      <td>0.089905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356249</th>\n",
       "      <td>456250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312768.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.601562</td>\n",
       "      <td>32.0</td>\n",
       "      <td>-1052.0</td>\n",
       "      <td>13238.063477</td>\n",
       "      <td>6.522492e+05</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>0.640137</td>\n",
       "      <td>19.281250</td>\n",
       "      <td>0.211304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356250 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  NAME_CONTRACT_TYPE  FLAG_OWN_CAR  \\\n",
       "0           100002     1.0                   0             0   \n",
       "1           100003     0.0                   0             0   \n",
       "2           100004     0.0                   1             1   \n",
       "3           100006     0.0                   0             0   \n",
       "4           100007     0.0                   0             0   \n",
       "...            ...     ...                 ...           ...   \n",
       "356245      456221     NaN                   0             0   \n",
       "356246      456222     NaN                   0             0   \n",
       "356247      456223     NaN                   0             1   \n",
       "356248      456224     NaN                   0             0   \n",
       "356249      456250     NaN                   0             1   \n",
       "\n",
       "        AMT_INCOME_TOTAL  AMT_CREDIT  NAME_TYPE_SUITE  NAME_INCOME_TYPE  \\\n",
       "0               202500.0    406597.5                0                 0   \n",
       "1               270000.0   1293502.5                1                 1   \n",
       "2                67500.0    135000.0                0                 0   \n",
       "3               135000.0    312682.5                0                 0   \n",
       "4               121500.0    513000.0                0                 0   \n",
       "...                  ...         ...              ...               ...   \n",
       "356245          121500.0    412560.0                0                 0   \n",
       "356246          157500.0    622413.0                0                 2   \n",
       "356247          202500.0    315000.0                0                 2   \n",
       "356248          225000.0    450000.0                1                 2   \n",
       "356249          135000.0    312768.0                0                 0   \n",
       "\n",
       "        NAME_FAMILY_STATUS  NAME_HOUSING_TYPE  ...  INS_DBD_MEAN  \\\n",
       "0                        0                  0  ...     20.421875   \n",
       "1                        1                  0  ...      7.160156   \n",
       "2                        0                  0  ...      7.667969   \n",
       "3                        2                  0  ...     19.375000   \n",
       "4                        0                  0  ...      4.589844   \n",
       "...                    ...                ...  ...           ...   \n",
       "356245                   3                  0  ...      7.332031   \n",
       "356246                   1                  0  ...      6.000000   \n",
       "356247                   1                  0  ...     31.625000   \n",
       "356248                   1                  0  ...      7.277344   \n",
       "356249                   1                  0  ...      8.601562   \n",
       "\n",
       "        INS_LATE_PAYMENT_SUM  INS_36M_DAYS_ENTRY_PAYMENT_MIN  \\\n",
       "0                       19.0                          -587.0   \n",
       "1                       25.0                          -806.0   \n",
       "2                        3.0                          -795.0   \n",
       "3                       16.0                          -575.0   \n",
       "4                       41.0                         -1106.0   \n",
       "...                      ...                             ...   \n",
       "356245                   3.0                          -661.0   \n",
       "356246                  62.0                          -815.0   \n",
       "356247                   8.0                          -818.0   \n",
       "356248                  26.0                          -559.0   \n",
       "356249                  32.0                         -1052.0   \n",
       "\n",
       "        INS_36M_AMT_INSTALMENT_MEAN  INS_36M_AMT_PAYMENT_SUM  \\\n",
       "0                      11559.247070             2.196257e+05   \n",
       "1                     118314.710938             1.538091e+06   \n",
       "2                       7096.154785             2.128846e+04   \n",
       "3                      62947.089844             1.007153e+06   \n",
       "4                      18268.630859             7.446037e+05   \n",
       "...                             ...                      ...   \n",
       "356245                 91036.453125             2.731094e+05   \n",
       "356246                 10101.311523             4.803925e+05   \n",
       "356247                 23158.992188             1.852719e+05   \n",
       "356248                 23451.705078             4.455824e+05   \n",
       "356249                 13238.063477             6.522492e+05   \n",
       "\n",
       "        INS_36M_SIGNIFICANT_LATE_PAYMENT_MEAN  INS_60M_LATE_PAYMENT_MEAN  \\\n",
       "0                                    1.000000                   1.000000   \n",
       "1                                    1.000000                   1.000000   \n",
       "2                                    1.000000                   1.000000   \n",
       "3                                    1.000000                   1.000000   \n",
       "4                                    0.761719                   0.731934   \n",
       "...                                       ...                        ...   \n",
       "356245                               1.000000                   1.000000   \n",
       "356246                               0.836914                   0.836914   \n",
       "356247                               1.000000                   1.000000   \n",
       "356248                               1.000000                   1.000000   \n",
       "356249                               0.640137                   0.640137   \n",
       "\n",
       "        INS_60M_SIGNIFICANT_LATE_PAYMENT_MEAN  \\\n",
       "0                                    1.000000   \n",
       "1                                    1.000000   \n",
       "2                                    1.000000   \n",
       "3                                    1.000000   \n",
       "4                                    0.678711   \n",
       "...                                       ...   \n",
       "356245                               1.000000   \n",
       "356246                               0.836914   \n",
       "356247                               1.000000   \n",
       "356248                               1.000000   \n",
       "356249                               0.640137   \n",
       "\n",
       "        BUREAU_ACTIVE_CREDIT_TO_INCOME_RATIO  \\\n",
       "0                                   2.380859   \n",
       "1                                   3.000000   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "...                                      ...   \n",
       "356245                              6.898438   \n",
       "356246                                   NaN   \n",
       "356247                              0.249634   \n",
       "356248                              9.625000   \n",
       "356249                             19.281250   \n",
       "\n",
       "        CURRENT_TO_APPROVED_CREDIT_MIN_RATIO  \n",
       "0                                   0.440430  \n",
       "1                                   0.052612  \n",
       "2                                   0.148926  \n",
       "3                                   0.077454  \n",
       "4                                   0.028488  \n",
       "...                                      ...  \n",
       "356245                              0.617188  \n",
       "356246                              0.043030  \n",
       "356247                              0.353271  \n",
       "356248                              0.089905  \n",
       "356249                              0.211304  \n",
       "\n",
       "[356250 rows x 88 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_cust = ['SK_ID_CURR']\n",
    "ids_cust.extend(col_boruta_lgbm100)\n",
    "\n",
    "df_boruta_feat = df[df.columns.intersection(ids_cust)]\n",
    "# Customer SK_ID added\n",
    "\n",
    "print(f'{df_boruta_feat.shape}')\n",
    "df_boruta_feat.to_pickle('df_boruta_feat.pkl')\n",
    "df_boruta_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc410971",
   "metadata": {},
   "source": [
    "### Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "858f959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape for train_df_boruta: (307506, 88)\n",
      "Final shape for test_df_boruta: (48744, 87)\n"
     ]
    }
   ],
   "source": [
    "train_df_boruta = df_boruta_feat[df_boruta_feat['TARGET'].notnull()]\n",
    "test_df_boruta = df_boruta_feat[df_boruta_feat['TARGET'].isnull()]\n",
    "test_df_boruta.drop(['TARGET'], axis=1, inplace=True)\n",
    "print('Final shape for train_df_boruta:', train_df_boruta.shape)\n",
    "print('Final shape for test_df_boruta:', test_df_boruta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f154475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of NaN before imputation by median for train_set_boruta: 6895611\n",
      "Nb of NaN after imputation by median for train_set_boruta: 0\n",
      "Nb of NaN before imputation by median for test_set_boruta: 994794\n",
      "Nb of NaN after imputation by median for test_set_boruta: 0\n"
     ]
    }
   ],
   "source": [
    "train_df_boruta.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "test_df_boruta.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# Numerical features - Median imputation\n",
    "nb_nan = train_df_boruta.isna().sum().sum()\n",
    "print(f'Nb of NaN before imputation by median for train_set_boruta: {nb_nan}')\n",
    "train_df_boruta = train_df_boruta.fillna(train_df_boruta.median())\n",
    "# Checking\n",
    "nb_nan = train_df_boruta.isna().sum().sum()\n",
    "print(f'Nb of NaN after imputation by median for train_set_boruta: {nb_nan}')\n",
    "# Numerical features - Median imputation\n",
    "nb_nan = test_df_boruta.isna().sum().sum()\n",
    "print(f'Nb of NaN before imputation by median for test_set_boruta: {nb_nan}')\n",
    "test_df_boruta = test_df_boruta.fillna(test_df_boruta.median())\n",
    "# Checking\n",
    "nb_nan = test_df_boruta.isna().sum().sum()\n",
    "print(f'Nb of NaN after imputation by median for test_set_boruta: {nb_nan}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bf37649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape for train_df_boruta: (307506, 88)\n",
      "Final shape for test_df_boruta: (48744, 87)\n"
     ]
    }
   ],
   "source": [
    "# Saving for modeling after recursive feature selection\n",
    "train_df_boruta.to_pickle('./train_data_boruta.pkl')\n",
    "test_df_boruta.to_pickle('./test_data_boruta.pkl')\n",
    "print('Final shape for train_df_boruta:', train_df_boruta.shape)\n",
    "print('Final shape for test_df_boruta:', test_df_boruta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ca51fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time (min) of Feature Engineering: 0:48:22.112183\n"
     ]
    }
   ],
   "source": [
    "elapsed = datetime.now() - start_time\n",
    "print(f'Running time (min) of Feature Engineering: {elapsed}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be1a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "395e5613",
    "62b6a53f",
    "df181c53",
    "8815ec3c",
    "3bf9a049",
    "4ee5b4bf",
    "b11b1ada",
    "cc7dd57c",
    "31a08eb7",
    "32ce1842",
    "d5e729b1",
    "95f9b594",
    "4dda1276",
    "b787e9eb",
    "ad78df31",
    "01cb708e",
    "9cde0240",
    "ef98c14f",
    "e291995e",
    "13388627"
   ],
   "name": "1_scoring_eda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
