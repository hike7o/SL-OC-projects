{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbfccb5",
   "metadata": {
    "id": "8dbfccb5"
   },
   "source": [
    "<h1><center>P7 - CREATE & IMPLEMENT A CREDIT SCORING MODEL</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fb92c",
   "metadata": {
    "id": "531fb92c"
   },
   "source": [
    "### OVERVIEW\n",
    "\n",
    "As a Data Scientist within the financial institution \"Prêt à dépenser\" which give loans to people with insufficient or non-existent credit history.\n",
    "\n",
    "Logo entreprise \n",
    "\n",
    "The company wishes to implement a credit scoring model in order to make good decisions.\n",
    "Two types of risks are associated with the bank’s decision:\n",
    "\n",
    "a. If the applicant is likely to repay the loan, then not approving the loan results in a loss of business to the company\n",
    "\n",
    "b. If the applicant is not likely to repay the loan, i.e. he/she is likely to default, then approving the loan may lead to a financial loss for the company.\n",
    "\n",
    "In addition, customers service are pushed more and more by clients to explain their decision to grant a loan and it's in this mindset that \"Prêt à dépenser\" wants to move forward.\n",
    "\n",
    "\"Prêt à dépenser\" has then decided to develop an interactive dashboard so that not only their customers service team can explain - in the most transparent way - their decisions to give or not the loans to their clients but also to give full access to their own information. \n",
    "\n",
    "### DATA\n",
    "\n",
    "The dataset provided contains a vast number of details about the borrower. It is separated into several relational tables, which contain applicants’ static data such as their gender, age, number of family members, occupation, and other necessary fields, applicant’s previous credit history obtained from the credit bureau department, and the applicant’s past credit history.<br>\n",
    "Data can be found here:<br> https://s3-eu-west-1.amazonaws.com/static.oc-static.com/prod/courses/files/Parcours_data_scientist/Projet+-+Impl%C3%A9menter+un+mod%C3%A8le+de+scoring/Projet+Mise+en+prod+-+home-credit-default-risk.zip\n",
    "\n",
    "\n",
    "### OBJECTIVE\n",
    "\n",
    "* Create & implement a credit scoring model which will return automatically a probability for a client to default his loan.\n",
    "* Create an interactive dashboard to later provide to the customers service management team so that they can interpret the model's predictions. It will provide them valuable information in order to improve their knowledge of the clients and to train their staff.\n",
    "\n",
    "In order to mainly focus on the creation, implementation and optimization of our model, Michaël, our manager, encouraged us to carefully choose an existing Kaggle kernel to ease the pre-processing work on this dataset.<br>\n",
    "We decided to opt for the kernel of student Rishabh Rao who did an exhaustive data pre-processing work.\n",
    "\n",
    "https://www.kaggle.com/rishabhrao/home-credit-default-risk-extensive-eda \n",
    "\n",
    "###  Dashboard constraints\n",
    "\n",
    "Michaël provided us specifications for the interactive dashboard. It will at least need to contain the followings features:\n",
    "\n",
    "* Easy viewing of the score and its interpretation for each client (especially for non scientific people).\n",
    "* Easy viewing of the descriptive information of the clients (via a filter system).\n",
    "* Allow the user to compare descriptive informations of one client to the others or to a group of similar clients.\n",
    "\n",
    "### Livrables \n",
    "\n",
    "Le dashboard interactif répondant aux spécifications ci-dessus et l’API de prédiction du score, déployées chacunes sur le cloud.\n",
    "Un dossier sur un outil de versioning de code contenant :\n",
    "Le code de la modélisation (du prétraitement à la prédiction)\n",
    "Le code générant le dashboard\n",
    "Le code permettant de déployer le modèle sous forme d'API\n",
    "Une note méthodologique décrivant :\n",
    "La méthodologie d'entraînement du modèle (2 pages maximum)\n",
    "La fonction coût métier, l'algorithme d'optimisation et la métrique d'évaluation (1 page maximum)\n",
    "L’interprétabilité globale et locale du modèle (1 page maximum)\n",
    "Les limites et les améliorations possibles (1 page maximum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d6c0de",
   "metadata": {},
   "source": [
    "## PART 2 - Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ea7d88",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "* [1. Dataset Overview](#chapter1)\n",
    "* [2. EDA of input files](#chapter2)\n",
    "    * [2.1 application_train/test](#section_2_1)\n",
    "    * [2.2 bureau.csv](#section_2_2)\n",
    "    * [2.3 bureau_balance.csv](#section_2_3)\n",
    "    * [2.4 previous_application.csv](#section_2_4)\n",
    "    * [2.5 installments_payments.csv](#section_2_5)\n",
    "    * [2.6 POS_CASH_balance.csv](#section_2_6)\n",
    "    * [2.7 credit_card_balance.csv](#section_2_7)\n",
    "* [3. EDA Conclusions](#chapter3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c062cc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1642861496666,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "c6c062cc",
    "outputId": "136f21da-f87b-47fe-e3fe-0ec8bdf54aee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# ! usr/bin/env python 3\n",
    "# coding: utf-8\n",
    "\n",
    "# Most features are created by applying min, max, mean, sum and var functions to grouped tables. \n",
    "# Little feature selection is done and overfitting might be a problem since many features are related.\n",
    "# The following key ideas were used:\n",
    "# - Divide or subtract important features to get rates (like annuity and income)\n",
    "# - In Bureau Data: create specific features for Active credits and Closed credits\n",
    "# - In Previous Applications: create specific features for Approved and Refused applications\n",
    "# - Modularity: one function for each table (except bureau_balance and application_test)\n",
    "# - One-hot encoding for categorical features\n",
    "# All tables are joined with the application DF using the SK_ID_CURR key (except bureau_balance).\n",
    "# You can use LightGBM with KFold or Stratified KFold.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from contextlib import contextmanager\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from functions_P7_feat import*\n",
    "# from LightGBM import*\n",
    "# from LightGBM_extra import*\n",
    "palette = sns.color_palette(\"bright\", 10)\n",
    "plot_kwds = {'alpha' : 1, 's' : 60, 'linewidths':0}\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac12d9",
   "metadata": {},
   "source": [
    "All functions run in this notebook can be found at: functions_P7_feat.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b3250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rlufWBGQbS0G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 56,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "executionInfo": {
     "elapsed": 3234210,
     "status": "ok",
     "timestamp": 1642861355543,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "rlufWBGQbS0G",
    "outputId": "21bb68df-cd61-4c7f-b1e2-55f59af4bb60"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f593abaa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39335,
     "status": "ok",
     "timestamp": 1642862231385,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "f593abaa",
    "outputId": "66aed406-461e-42af-a7cb-460ea286d26e"
   },
   "outputs": [],
   "source": [
    "# Transforming our csv files into dataframe\n",
    "# %%time\n",
    "homecredit = pd.read_csv('HomeCredit_columns_description.csv', index_col=[0])\n",
    "cash_balance = pd.read_csv('POS_CASH_balance.csv')\n",
    "app_test = pd.read_csv('application_test.csv')\n",
    "app_train = pd.read_csv('application_train.csv')\n",
    "bureau = pd.read_csv('bureau.csv')\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "cc_balance = pd.read_csv('credit_card_balance.csv')\n",
    "inst_payments = pd.read_csv('installments_payments.csv')\n",
    "previous_app = pd.read_csv('previous_application.csv')\n",
    "sample_submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bdfc3",
   "metadata": {
    "id": "0a1bdfc3"
   },
   "source": [
    "## 1. Dataset Overview<a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0083e6ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 40207,
     "status": "ok",
     "timestamp": 1642862284018,
     "user": {
      "displayName": "Stephane Lanchec",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "09839169314289564092"
     },
     "user_tz": -60
    },
    "id": "0083e6ea",
    "outputId": "9da74731-3f3b-4d7a-b676-f758747a3fca",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total rows</th>\n",
       "      <th>Total columns</th>\n",
       "      <th>Total duplicates</th>\n",
       "      <th>Total NaN values</th>\n",
       "      <th>NaN values (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input File Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HomeCredit_columns_description.csv</th>\n",
       "      <td>219</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>15.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS_CASH_balance.csv</th>\n",
       "      <td>10001358</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>52158</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_test.csv</th>\n",
       "      <td>48744</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>1404419</td>\n",
       "      <td>23.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>application_train.csv</th>\n",
       "      <td>307511</td>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>9152465</td>\n",
       "      <td>24.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau.csv</th>\n",
       "      <td>1716428</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3939947</td>\n",
       "      <td>13.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bureau_balance.csv</th>\n",
       "      <td>27299925</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credit_card_balance.csv</th>\n",
       "      <td>3840312</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5877356</td>\n",
       "      <td>6.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>installments_payments.csv</th>\n",
       "      <td>13605401</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5810</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_application.csv</th>\n",
       "      <td>1670214</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>11109336</td>\n",
       "      <td>17.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_submission.csv</th>\n",
       "      <td>48744</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Total rows  Total columns  \\\n",
       "Input File Name                                                 \n",
       "HomeCredit_columns_description.csv         219              4   \n",
       "POS_CASH_balance.csv                  10001358              8   \n",
       "application_test.csv                     48744            121   \n",
       "application_train.csv                   307511            122   \n",
       "bureau.csv                             1716428             17   \n",
       "bureau_balance.csv                    27299925              3   \n",
       "credit_card_balance.csv                3840312             23   \n",
       "installments_payments.csv             13605401              8   \n",
       "previous_application.csv               1670214             37   \n",
       "sample_submission.csv                    48744              2   \n",
       "\n",
       "                                    Total duplicates  Total NaN values  \\\n",
       "Input File Name                                                          \n",
       "HomeCredit_columns_description.csv                 0               133   \n",
       "POS_CASH_balance.csv                               0             52158   \n",
       "application_test.csv                               0           1404419   \n",
       "application_train.csv                              0           9152465   \n",
       "bureau.csv                                         0           3939947   \n",
       "bureau_balance.csv                                 0                 0   \n",
       "credit_card_balance.csv                            0           5877356   \n",
       "installments_payments.csv                          0              5810   \n",
       "previous_application.csv                           0          11109336   \n",
       "sample_submission.csv                              0                 0   \n",
       "\n",
       "                                    NaN values (%)  \n",
       "Input File Name                                     \n",
       "HomeCredit_columns_description.csv           15.18  \n",
       "POS_CASH_balance.csv                          0.07  \n",
       "application_test.csv                         23.81  \n",
       "application_train.csv                        24.40  \n",
       "bureau.csv                                   13.50  \n",
       "bureau_balance.csv                            0.00  \n",
       "credit_card_balance.csv                       6.65  \n",
       "installments_payments.csv                     0.01  \n",
       "previous_application.csv                     17.98  \n",
       "sample_submission.csv                         0.00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INITIALISE FILES_SPEC TO SERIES DICTIONARY\n",
    "\n",
    "list_files = [\"HomeCredit_columns_description.csv\",\n",
    "              \"POS_CASH_balance.csv\",\n",
    "              \"application_test.csv\",\n",
    "              \"application_train.csv\",\n",
    "              \"bureau.csv\",\n",
    "              \"bureau_balance.csv\",\n",
    "              \"credit_card_balance.csv\",\n",
    "              \"installments_payments.csv\",\n",
    "              \"previous_application.csv\",\n",
    "              \"sample_submission.csv\"]\n",
    "\n",
    "files_spec = {\n",
    "             'Total rows': pd.Series([len(homecredit),\n",
    "                                       len(cash_balance),\n",
    "                                       len(app_test),\n",
    "                                       len(app_train),\n",
    "                                       len(bureau),\n",
    "                                       len(bureau_balance),\n",
    "                                       len(cc_balance),\n",
    "                                       len(inst_payments),\n",
    "                                       len(previous_app),\n",
    "                                       len(sample_submission)],\n",
    "                                      index=list_files),\n",
    "              'Total columns': pd.Series([len(homecredit.columns),\n",
    "                                          len(cash_balance.columns),\n",
    "                                          len(app_test.columns),\n",
    "                                          len(app_train.columns),\n",
    "                                          len(bureau.columns),\n",
    "                                          len(bureau_balance.columns),\n",
    "                                          len(cc_balance.columns),\n",
    "                                          len(inst_payments.columns),\n",
    "                                          len(previous_app.columns),\n",
    "                                          len(sample_submission.columns)],\n",
    "                                         index=list_files),\n",
    "              'Total duplicates': pd.Series([duplicates(homecredit),\n",
    "                                             duplicates(cash_balance),\n",
    "                                             duplicates(app_test),\n",
    "                                             duplicates(app_train),\n",
    "                                             duplicates(bureau),\n",
    "                                             duplicates(bureau_balance),\n",
    "                                             duplicates(cc_balance),\n",
    "                                             duplicates(inst_payments),\n",
    "                                             duplicates(previous_app),\n",
    "                                             duplicates(sample_submission)],\n",
    "                                            index=list_files),\n",
    "              'Total NaN values': pd.Series([missing_cells(homecredit),\n",
    "                                                missing_cells(cash_balance),\n",
    "                                                missing_cells(app_test),\n",
    "                                                missing_cells(app_train),\n",
    "                                                missing_cells(bureau),\n",
    "                                                missing_cells(bureau_balance),\n",
    "                                                missing_cells(cc_balance),\n",
    "                                                missing_cells(inst_payments),\n",
    "                                                missing_cells(previous_app),\n",
    "                                                missing_cells(sample_submission)],\n",
    "                                               index=list_files),\n",
    "               'NaN values (%)': pd.Series([missing_cells_percent(homecredit),\n",
    "                                            missing_cells_percent(cash_balance),\n",
    "                                            missing_cells_percent(app_test),\n",
    "                                            missing_cells_percent(app_train),\n",
    "                                            missing_cells_percent(bureau),\n",
    "                                            missing_cells_percent(bureau_balance),\n",
    "                                            missing_cells_percent(cc_balance),\n",
    "                                            missing_cells_percent(inst_payments),\n",
    "                                            missing_cells_percent(previous_app),\n",
    "                                            missing_cells_percent(sample_submission)],\n",
    "                                           index=list_files)}\n",
    "\n",
    "# Creates Dataframe df_files_spec\n",
    "\n",
    "df_files_spec = pd.DataFrame(files_spec)\n",
    "index = df_files_spec.index\n",
    "index.name = \"Input File Name\"\n",
    "round(df_files_spec, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e5613",
   "metadata": {
    "id": "395e5613"
   },
   "source": [
    "<h2><center>Relationship between all tables</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07409bf",
   "metadata": {
    "id": "b07409bf"
   },
   "source": [
    "<div style=\"width:100%;text-align: center;\"> <img align=middle src=\"https://miro.medium.com/max/875/0*IMyhw8RGEoDhC7t1.png\" alt=\"Heat beating\" style=\"height:400px;margin-top:3rem;\"> </div><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb1467",
   "metadata": {},
   "source": [
    "## 2. Input files processing<a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3966931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 1 \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffc0ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 2 \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def reduce_memory(df):\n",
    "    \"\"\"Reduce memory usage of a dataframe by setting data types. \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Initial df memory usage is {:.2f} MB for {} columns'\n",
    "          .format(start_mem, len(df.columns)))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type != object:\n",
    "            cmin = df[col].min()\n",
    "            cmax = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                # Can use unsigned int here too\n",
    "                if cmin > np.iinfo(np.int8).min and cmax < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif cmin > np.iinfo(np.int16).min and cmax < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif cmin > np.iinfo(np.int32).min and cmax < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif cmin > np.iinfo(np.int64).min and cmax < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if cmin > np.finfo(np.float16).min and cmax < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif cmin > np.finfo(np.float32).min and cmax < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    memory_reduction = 100 * (start_mem - end_mem) / start_mem\n",
    "    print('Final memory usage is: {:.2f} MB - decreased by {:.1f}%'.format(end_mem, memory_reduction))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec305560",
   "metadata": {},
   "source": [
    "#### 2.1 application_{train/test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3158cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 3 \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Preprocess application_train.csv and application_test.csv\n",
    "def application_train_test(num_rows = None, nan_as_category = False):\n",
    "    # Read data and merge\n",
    "    df = pd.read_csv('application_train.csv', nrows= num_rows)\n",
    "    test_df = pd.read_csv('application_test.csv', nrows= num_rows)\n",
    "    print(\"Train samples: {}, test samples: {}\".format(len(df), len(test_df)))\n",
    "    df = df.append(test_df).reset_index()\n",
    "    # Optional: Remove 4 applications with XNA CODE_GENDER (train set)\n",
    "    df = df[df['CODE_GENDER'] != 'XNA']\n",
    "    \n",
    "    # Categorical features with Binary encode (0 or 1; two categories)\n",
    "    for bin_feature in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "        df[bin_feature], uniques = pd.factorize(df[bin_feature])\n",
    "    # Categorical features with One-Hot encode\n",
    "    df, cat_cols = one_hot_encoder(df, nan_as_category)\n",
    "    \n",
    "    # NaN values for DAYS_EMPLOYED: 365.243 -> nan\n",
    "    df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "    # Some simple new features (percentages)\n",
    "    df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "    df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "    df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "    df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "    df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']\n",
    "    del test_df\n",
    "    gc.collect()\n",
    "    return reduce_memory(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d49c6",
   "metadata": {},
   "source": [
    "#### 2.2 bureau & bureau_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb2df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 3 \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Preprocess bureau.csv and bureau_balance.csv\n",
    "def bureau_and_balance(num_rows = None, nan_as_category = True):\n",
    "    bureau = pd.read_csv('bureau.csv', nrows = num_rows)\n",
    "    bb = pd.read_csv('bureau_balance.csv', nrows = num_rows)\n",
    "    bb, bb_cat = one_hot_encoder(bb, nan_as_category)\n",
    "    bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category)\n",
    "    \n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "    for col in bb_cat:\n",
    "        bb_aggregations[col] = ['mean']\n",
    "    bb_agg = bb.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bb, bb_agg\n",
    "    gc.collect()\n",
    "    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'MONTHS_BALANCE_MIN': ['min'], # bureau_balance\n",
    "        'MONTHS_BALANCE_MAX': ['max'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum'], \n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'], # bureau\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "        'CNT_CREDIT_PROLONG': ['sum'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean'],\n",
    "        'AMT_ANNUITY': ['max', 'mean']\n",
    "    }\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "    for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "    \n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    \n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    bureau_agg = bureau_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "    return reduce_memory(bureau_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969eccd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 3\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Preprocess previous_applications.csv\n",
    "def previous_applications(num_rows = None, nan_as_category = True):\n",
    "    prev = pd.read_csv('previous_application.csv', nrows = num_rows)\n",
    "    prev, cat_cols = one_hot_encoder(prev, nan_as_category= True)\n",
    "    # Days 365.243 values -> nan\n",
    "    prev['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "    prev['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "    # Add feature: value ask / value received percentage\n",
    "    prev['APP_CREDIT_PERC'] = prev['AMT_APPLICATION'] / prev['AMT_CREDIT']\n",
    "    # Previous applications numeric features\n",
    "    num_aggregations = {\n",
    "        'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "        'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "        'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "        'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "        'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "        'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "        'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "        'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "        'CNT_PAYMENT': ['mean', 'sum'],\n",
    "    }\n",
    "    # Previous applications categorical features\n",
    "    cat_aggregations = {}\n",
    "    for cat in cat_cols:\n",
    "        cat_aggregations[cat] = ['mean']\n",
    "    \n",
    "    prev_agg = prev.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "    # Previous Applications: Approved Applications - only numerical features\n",
    "    approved = prev[prev['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "    # Previous Applications: Refused Applications - only numerical features\n",
    "    refused = prev[prev['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    prev_agg = prev_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del refused, refused_agg, approved, approved_agg, prev\n",
    "    gc.collect()\n",
    "    return reduce_memory(prev_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29b63eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 4\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Preprocess POS_CASH_balance.csv\n",
    "def pos_cash(num_rows = None, nan_as_category = True):\n",
    "    pos = pd.read_csv('POS_CASH_balance.csv', nrows = num_rows)\n",
    "    pos, cat_cols = one_hot_encoder(pos, nan_as_category= True)\n",
    "    # Features\n",
    "    aggregations = {\n",
    "        'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "        'SK_DPD': ['max', 'mean'],\n",
    "        'SK_DPD_DEF': ['max', 'mean']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    \n",
    "    pos_agg = pos.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pos.groupby('SK_ID_CURR').size()\n",
    "    pos_agg = pos_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del pos\n",
    "    gc.collect()\n",
    "    return reduce_memory(pos_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba176de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 5 \n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# Preprocess installments_payments.csv\n",
    "def installments_payments(num_rows = None, nan_as_category = True):\n",
    "    ins = pd.read_csv('installments_payments.csv', nrows = num_rows)\n",
    "    ins, cat_cols = one_hot_encoder(ins, nan_as_category= True)\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    ins['PAYMENT_PERC'] = ins['AMT_PAYMENT'] / ins['AMT_INSTALMENT']\n",
    "    ins['PAYMENT_DIFF'] = ins['AMT_INSTALMENT'] - ins['AMT_PAYMENT']\n",
    "    # Days past due and days before due (no negative values)\n",
    "    ins['DPD'] = ins['DAYS_ENTRY_PAYMENT'] - ins['DAYS_INSTALMENT']\n",
    "    ins['DBD'] = ins['DAYS_INSTALMENT'] - ins['DAYS_ENTRY_PAYMENT']\n",
    "    ins['DPD'] = ins['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "    ins['DBD'] = ins['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "    # Features: Perform aggregations\n",
    "    aggregations = {\n",
    "        'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "        'DPD': ['max', 'mean', 'sum'],\n",
    "        'DBD': ['max', 'mean', 'sum'],\n",
    "        'PAYMENT_PERC': ['max', 'mean', 'sum', 'var'],\n",
    "        'PAYMENT_DIFF': ['max', 'mean', 'sum', 'var'],\n",
    "        'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "        'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "        'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "    }\n",
    "    for cat in cat_cols:\n",
    "        aggregations[cat] = ['mean']\n",
    "    ins_agg = ins.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = ins.groupby('SK_ID_CURR').size()\n",
    "    ins_agg = ins_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del ins\n",
    "    gc.collect()\n",
    "    return reduce_memory(ins_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b163869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 6 \n",
    "# --------------------------------------------------------------------\n",
    "# Preprocess credit_card_balance.csv\n",
    "def credit_card_balance(num_rows = None, nan_as_category = True):\n",
    "    cc = pd.read_csv('credit_card_balance.csv', nrows = num_rows)\n",
    "    cc, cat_cols = one_hot_encoder(cc, nan_as_category= True)\n",
    "    # General aggregations\n",
    "    cc.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "    cc_agg = cc.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = cc.groupby('SK_ID_CURR').size()\n",
    "    cc_agg = cc_agg.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    del cc\n",
    "    gc.collect()\n",
    "    return reduce_memory(cc_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ed8f35b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 10000, test samples: 10000\n",
      "Initial df memory usage is 20.20 MB for 246 columns\n",
      "Final memory usage is: 9.02 MB - decreased by 55.3%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>WALLSMATERIAL_MODE_Panel</th>\n",
       "      <th>WALLSMATERIAL_MODE_Stone, brick</th>\n",
       "      <th>WALLSMATERIAL_MODE_Wooden</th>\n",
       "      <th>EMERGENCYSTATE_MODE_No</th>\n",
       "      <th>EMERGENCYSTATE_MODE_Yes</th>\n",
       "      <th>DAYS_EMPLOYED_PERC</th>\n",
       "      <th>INCOME_CREDIT_PERC</th>\n",
       "      <th>INCOME_PER_PERSON</th>\n",
       "      <th>ANNUITY_INCOME_PERC</th>\n",
       "      <th>PAYMENT_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067322</td>\n",
       "      <td>0.498047</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.121948</td>\n",
       "      <td>0.060760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070862</td>\n",
       "      <td>0.208740</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.132202</td>\n",
       "      <td>0.027603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.049988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159912</td>\n",
       "      <td>0.431641</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>0.219849</td>\n",
       "      <td>0.094971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.152466</td>\n",
       "      <td>0.236816</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>0.179932</td>\n",
       "      <td>0.042633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>9995</td>\n",
       "      <td>172551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>454500.0</td>\n",
       "      <td>29173.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614258</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.216064</td>\n",
       "      <td>0.064209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>9996</td>\n",
       "      <td>172556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>500490.0</td>\n",
       "      <td>52555.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141235</td>\n",
       "      <td>0.359619</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0.291992</td>\n",
       "      <td>0.104980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>9997</td>\n",
       "      <td>172562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>523152.0</td>\n",
       "      <td>37336.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>0.184326</td>\n",
       "      <td>0.071350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>9998</td>\n",
       "      <td>172570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>382500.0</td>\n",
       "      <td>967500.0</td>\n",
       "      <td>31338.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056488</td>\n",
       "      <td>0.395264</td>\n",
       "      <td>127500.0</td>\n",
       "      <td>0.081909</td>\n",
       "      <td>0.032379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>9999</td>\n",
       "      <td>172574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>539100.0</td>\n",
       "      <td>22837.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012840</td>\n",
       "      <td>0.208740</td>\n",
       "      <td>37500.0</td>\n",
       "      <td>0.203003</td>\n",
       "      <td>0.042358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 246 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0          0      100002     1.0            0             0                0   \n",
       "1          1      100003     0.0            1             0                1   \n",
       "2          2      100004     0.0            0             1                0   \n",
       "3          3      100006     0.0            1             0                0   \n",
       "4          4      100007     0.0            0             0                0   \n",
       "...      ...         ...     ...          ...           ...              ...   \n",
       "19995   9995      172551     NaN            1             0                0   \n",
       "19996   9996      172556     NaN            0             1                1   \n",
       "19997   9997      172562     NaN            1             0                0   \n",
       "19998   9998      172570     NaN            0             0                0   \n",
       "19999   9999      172574     NaN            1             0                1   \n",
       "\n",
       "       CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  ...  \\\n",
       "0                 0          202500.0    406597.5      24700.5  ...   \n",
       "1                 0          270000.0   1293502.5      35698.5  ...   \n",
       "2                 0           67500.0    135000.0       6750.0  ...   \n",
       "3                 0          135000.0    312682.5      29686.5  ...   \n",
       "4                 0          121500.0    513000.0      21865.5  ...   \n",
       "...             ...               ...         ...          ...  ...   \n",
       "19995             0          135000.0    454500.0      29173.5  ...   \n",
       "19996             1          180000.0    500490.0      52555.5  ...   \n",
       "19997             0          202500.0    523152.0      37336.5  ...   \n",
       "19998             1          382500.0    967500.0      31338.0  ...   \n",
       "19999             1          112500.0    539100.0      22837.5  ...   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Panel  WALLSMATERIAL_MODE_Stone, brick  \\\n",
       "0                           0.0                              1.0   \n",
       "1                           0.0                              0.0   \n",
       "2                           0.0                              0.0   \n",
       "3                           0.0                              0.0   \n",
       "4                           0.0                              0.0   \n",
       "...                         ...                              ...   \n",
       "19995                       0.0                              1.0   \n",
       "19996                       0.0                              0.0   \n",
       "19997                       1.0                              0.0   \n",
       "19998                       0.0                              1.0   \n",
       "19999                       0.0                              1.0   \n",
       "\n",
       "       WALLSMATERIAL_MODE_Wooden  EMERGENCYSTATE_MODE_No  \\\n",
       "0                            0.0                     1.0   \n",
       "1                            0.0                     1.0   \n",
       "2                            0.0                     0.0   \n",
       "3                            0.0                     0.0   \n",
       "4                            0.0                     0.0   \n",
       "...                          ...                     ...   \n",
       "19995                        0.0                     1.0   \n",
       "19996                        0.0                     1.0   \n",
       "19997                        0.0                     1.0   \n",
       "19998                        0.0                     1.0   \n",
       "19999                        0.0                     1.0   \n",
       "\n",
       "       EMERGENCYSTATE_MODE_Yes  DAYS_EMPLOYED_PERC  INCOME_CREDIT_PERC  \\\n",
       "0                          0.0            0.067322            0.498047   \n",
       "1                          0.0            0.070862            0.208740   \n",
       "2                          0.0            0.011810            0.500000   \n",
       "3                          0.0            0.159912            0.431641   \n",
       "4                          0.0            0.152466            0.236816   \n",
       "...                        ...                 ...                 ...   \n",
       "19995                      0.0            0.614258            0.297119   \n",
       "19996                      0.0            0.141235            0.359619   \n",
       "19997                      0.0            0.006618            0.386963   \n",
       "19998                      0.0            0.056488            0.395264   \n",
       "19999                      0.0            0.012840            0.208740   \n",
       "\n",
       "       INCOME_PER_PERSON  ANNUITY_INCOME_PERC  PAYMENT_RATE  \n",
       "0               202500.0             0.121948      0.060760  \n",
       "1               135000.0             0.132202      0.027603  \n",
       "2                67500.0             0.099976      0.049988  \n",
       "3                67500.0             0.219849      0.094971  \n",
       "4               121500.0             0.179932      0.042633  \n",
       "...                  ...                  ...           ...  \n",
       "19995           135000.0             0.216064      0.064209  \n",
       "19996            60000.0             0.291992      0.104980  \n",
       "19997           202500.0             0.184326      0.071350  \n",
       "19998           127500.0             0.081909      0.032379  \n",
       "19999            37500.0             0.203003      0.042358  \n",
       "\n",
       "[20000 rows x 246 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_train_test(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dee080da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 307511, test samples: 48744\n",
      "Initial df memory usage is 360.47 MB for 248 columns\n",
      "Final memory usage is: 162.74 MB - decreased by 54.9%\n",
      "Initial df memory usage is 266.85 MB for 116 columns\n",
      "Final memory usage is: 92.45 MB - decreased by 65.4%\n",
      "-------------------------------\n",
      "Bureau df shape: (305811, 116)\n",
      "Process bureau and bureau_balance - done in 23s\n",
      "Initial df memory usage is 614.65 MB for 249 columns\n",
      "Final memory usage is: 199.71 MB - decreased by 67.5%\n",
      "-------------------------------\n",
      "Previous applications df shape: (338857, 249)\n",
      "Process previous_applications - done in 35s\n",
      "Initial df memory usage is 46.64 MB for 18 columns\n",
      "Final memory usage is: 13.83 MB - decreased by 70.3%\n",
      "-------------------------------\n",
      "Pos-cash balance df shape: (337252, 18)\n",
      "Process POS-CASH balance - done in 16s\n",
      "Initial df memory usage is 69.95 MB for 26 columns\n",
      "Final memory usage is: 34.00 MB - decreased by 51.4%\n",
      "-------------------------------\n",
      "Installments payments df shape: (339587, 26)\n",
      "Process installments payments - done in 30s\n",
      "Initial df memory usage is 94.91 MB for 141 columns\n",
      "Final memory usage is: 40.59 MB - decreased by 57.2%\n",
      "-------------------------------\n",
      "Credit card balance df shape: (103558, 141)\n",
      "Process credit card balance - done in 15s\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------\n",
    "# -- Function 9 \n",
    "# --------------------------------------------------------------------\n",
    "    \n",
    "def merged_all(debug = False):\n",
    "    num_rows = 10000 if debug else None\n",
    "    df = application_train_test(num_rows)\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    with timer(\"Process bureau and bureau_balance\"):\n",
    "        bureau = bureau_and_balance(num_rows)\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Bureau df shape:\", bureau.shape)\n",
    "        df = df.join(bureau, how='left', on='SK_ID_CURR')\n",
    "        del bureau\n",
    "        gc.collect()\n",
    "    with timer(\"Process previous_applications\"):\n",
    "        prev = previous_applications(num_rows)\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Previous applications df shape:\", prev.shape)\n",
    "        df = df.join(prev, how='left', on='SK_ID_CURR')\n",
    "        del prev\n",
    "        gc.collect()\n",
    "        \n",
    "    with timer(\"Process POS-CASH balance\"):\n",
    "        pos = pos_cash(num_rows)\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Pos-cash balance df shape:\", pos.shape)\n",
    "        df = df.join(pos, how='left', on='SK_ID_CURR')\n",
    "        del pos\n",
    "        gc.collect()\n",
    "    with timer(\"Process installments payments\"):\n",
    "        ins = installments_payments(num_rows)\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Installments payments df shape:\", ins.shape)\n",
    "        df = df.join(ins, how='left', on='SK_ID_CURR')\n",
    "        del ins\n",
    "        gc.collect()\n",
    "\n",
    "    with timer(\"Process credit card balance\"):\n",
    "        cc = credit_card_balance(num_rows)\n",
    "        print(\"-------------------------------\")\n",
    "        print(\"Credit card balance df shape:\", cc.shape)\n",
    "        df = df.join(cc, how='left', on='SK_ID_CURR')\n",
    "        del cc\n",
    "        gc.collect()\n",
    "        \n",
    "        return df\n",
    "df = merged_all()\n",
    "print('Final dataset shape:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bed35765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape for train_df: (307507, 798)\n",
      "Final shape for test_df: (48744, 798)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "test_df = df[df['TARGET'].isnull()]\n",
    "print('Final shape for train_df:', train_df.shape)\n",
    "print('Final shape for test_df:', test_df.shape)\n",
    "train_df.to_pickle('./train_data2.pkl')\n",
    "test_df.to_pickle('./test_data2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ca51fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time (min) of EDA: 0:04:01.590449\n"
     ]
    }
   ],
   "source": [
    "elapsed = datetime.now() - start_time\n",
    "print(f'Running time (min) of EDA: {elapsed}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "395e5613",
    "62b6a53f",
    "df181c53",
    "8815ec3c",
    "3bf9a049",
    "4ee5b4bf",
    "b11b1ada",
    "cc7dd57c",
    "31a08eb7",
    "32ce1842",
    "d5e729b1",
    "95f9b594",
    "4dda1276",
    "b787e9eb",
    "ad78df31",
    "01cb708e",
    "9cde0240",
    "ef98c14f",
    "e291995e",
    "13388627"
   ],
   "name": "1_scoring_eda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
